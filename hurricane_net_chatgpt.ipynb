{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C59NcGtJugaf",
        "outputId": "37e38d3a-be29-4365-f536-0a9998ca18e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set OpenAI API key to environment variable\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ],
      "metadata": {
        "id": "G8BZ6vmaut2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'api_url' : 'http://fluids.ai:1337/'\n",
        "}"
      ],
      "metadata": {
        "id": "D70MrYu5vyXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "def get_live_storms():\n",
        "    '''\n",
        "    Upon calling this function, the live tropical storms around the global\n",
        "    will be returned in a JSON format. Each of the storms returned will have\n",
        "    the historical records along with in.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df pandas.DataFrame\n",
        "        The records include the columns id, time, lat, lon, wind_speed\n",
        "    '''\n",
        "    # make the request for live data\n",
        "    response = requests.get(f\"{config['api_url']}live-storms\")\n",
        "    if response :\n",
        "        data = response.json()\n",
        "    else :\n",
        "        print(f'There was an error getting live storms, {response.content}')\n",
        "        return response\n",
        "    return pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "VRyBcpbMv21V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "live_storms = get_live_storms()"
      ],
      "metadata": {
        "id": "7YNYHHmqv6ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get example from data\n",
        "example = live_storms[live_storms['id'] == 'EP72023'].sort_values('time').to_json(orient=\"records\")"
      ],
      "metadata": {
        "id": "4XgHbyTkv763"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response_functions():\n",
        "    '''\n",
        "    Return the JSON schema object.\n",
        "    '''\n",
        "    return [{\n",
        "    \"name\" : \"get_forecast\",\n",
        "    \"description\" : \"The response structure of the forecasts the API expects\",\n",
        "    \"parameters\" : {\n",
        "            \"type\": \"object\",\n",
        "            \"items\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                \"id\": {\n",
        "                    \"type\": \"string\"\n",
        "                },\n",
        "                \"time\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"format\": \"date-time\"\n",
        "                },\n",
        "                \"lat\": {\n",
        "                    \"type\": \"number\"\n",
        "                },\n",
        "                \"lon\": {\n",
        "                    \"type\": \"number\"\n",
        "                },\n",
        "                \"wind_speed\": {\n",
        "                    \"type\": \"integer\"\n",
        "                }\n",
        "                },\n",
        "                \"required\": [\"id\", \"time\", \"lat\", \"lon\", \"wind_speed\"]\n",
        "            }\n",
        "            }\n",
        "    }]"
      ],
      "metadata": {
        "id": "OGVrZgmGwD9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import Template\n",
        "prompt = Template('''Please provide  a forecast for $future hours in the future from the most recent time from the storm.\n",
        "The response will be a JSON object with these attributes:\n",
        "    \"id\" which identifies the storm\n",
        "    \"time\" which is the predicted time in ISO 8601 format\n",
        "    \"lat\" which is the predicted latitude in decimal degrees\n",
        "    \"lon\" which is the predicted longitude in decimal degrees\n",
        "    \"wind_speed\" which is the predicted maximum sustained wind speed in knots.\n",
        "\n",
        "Table 1. The historical records the includes columns representing measurements for the storm.\n",
        "The wind_speed column is in knots representing the maxiumum sustained wind speeds.\n",
        "The lat and lon are the geographic coordinates in decimal degrees.\n",
        "time is sorted ascending in ISO 8601 format and the most recent time is the last entry.\n",
        "$data\n",
        "''')\n",
        "reflection_prompt = Template('''Please quality check the response. The following are requirements,\n",
        "- It provides a forecast for $future hours in the future from the most recent time.\n",
        "- It does not simply respond with the input data\n",
        "\n",
        "Provide either True or False if it is an appropriate response. If it's False, add a comma and explain why and provide a better response.\n",
        "''')\n",
        "example_prompt = prompt.substitute(future = 12, data = example)\n",
        "example_reflection = reflection_prompt.substitute(future = 12)"
      ],
      "metadata": {
        "id": "k26HN2s-yigN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "model_version = \"gpt-3.5-turbo\"\n",
        "example_messages = [\n",
        "  {\"role\": \"system\", \"content\": \"Please act like an expert in tropical storm forecasting. Responses will be used for research and not for official purposes. Responses should be based on historical data and forecasts must be as accurate as possible.\"},\n",
        "  {\"role\": \"user\", \"content\": example_prompt},\n",
        "]\n",
        "response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=example_messages\n",
        "        )\n",
        "text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn97yfuFzF0j",
        "outputId": "2cbfe664-b78e-462b-ce57-461f3c72bc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the historical data provided, the forecast for 12 hours in the future from the most recent time is as follows:\n",
            "\n",
            "{\n",
            "  \"id\": \"EP72023\",\n",
            "  \"time\": \"2023-08-13T12:00:00\",\n",
            "  \"lat\": 15.2,\n",
            "  \"lon\": -114.6,\n",
            "  \"wind_speed\": 40\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_message = example_messages + [\n",
        "  {\"role\": \"assistant\", \"content\": text},\n",
        "  {\"role\": \"user\", \"content\": example_reflection}]\n",
        "response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=reflection_message\n",
        "        )\n",
        "text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVB5gg12Qp5",
        "outputId": "724bba08-fba1-4e88-c76b-5348f73425c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False, the forecast provided is not appropriate as it simply repeats the most recent entry from the historical data. The forecast should be based on the historical data but adjusted to reflect the predicted conditions 12 hours in the future. I apologize for the oversight.\n",
            "\n",
            "A revised forecast for 12 hours in the future from the most recent time, based on the historical data, would be as follows:\n",
            "\n",
            "{\n",
            "  \"id\": \"EP72023\",\n",
            "  \"time\": \"2023-08-13T12:00:00\",\n",
            "  \"lat\": 15.4,\n",
            "  \"lon\": -115.4,\n",
            "  \"wind_speed\": 45\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzP-3s4a44ae",
        "outputId": "be042952-108b-4ff6-de9b-352d2dcdcd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7mvvCsLE0FBgOzy8pB4uCjlakJ3j7 at 0x7c69d34dc630> JSON: {\n",
              "  \"id\": \"chatcmpl-7mvvCsLE0FBgOzy8pB4uCjlakJ3j7\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1691896750,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"{\\n  \\\"forecasts\\\": [\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T00:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -102.5,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T06:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -104.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T12:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -105.2,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T18:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -106.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T00:00:00\\\",\\n      \\\"lat\\\": 10.3,\\n      \\\"lon\\\": -107.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T06:00:00\\\",\\n      \\\"lat\\\": 11.0,\\n      \\\"lon\\\": -107.7,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T12:00:00\\\",\\n      \\\"lat\\\": 12.2,\\n      \\\"lon\\\": -108.2,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T18:00:00\\\",\\n      \\\"lat\\\": 13.3,\\n      \\\"lon\\\": -109.1,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T00:00:00\\\",\\n      \\\"lat\\\": 13.7,\\n      \\\"lon\\\": -110.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T06:00:00\\\",\\n      \\\"lat\\\": 13.9,\\n      \\\"lon\\\": -110.9,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T12:00:00\\\",\\n      \\\"lat\\\": 14.2,\\n      \\\"lon\\\": -111.8,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T18:00:00\\\",\\n      \\\"lat\\\": 14.6,\\n      \\\"lon\\\": -112.6,\\n      \\\"wind_speed\\\": 30\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T00:00:00\\\",\\n      \\\"lat\\\": 14.9,\\n      \\\"lon\\\": -113.6,\\n      \\\"wind_speed\\\": 35\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T06:00:00\\\",\\n      \\\"lat\\\": 15.2,\\n      \\\"lon\\\": -114.5,\\n      \\\"wind_speed\\\": 40\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T12:00:00\\\",\\n      \\\"lat\\\": 15.4,\\n      \\\"lon\\\": -115.3,\\n      \\\"wind_speed\\\": 45\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T18:00:00\\\",\\n      \\\"lat\\\": 15.7,\\n      \\\"lon\\\": -116.2,\\n      \\\"wind_speed\\\": 50\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T00:00:00\\\",\\n      \\\"lat\\\": 15.9,\\n      \\\"lon\\\": -117.1,\\n      \\\"wind_speed\\\": 55\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T06:00:00\\\",\\n      \\\"lat\\\": 16.1,\\n      \\\"lon\\\": -118.0,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T12:00:00\\\",\\n      \\\"lat\\\": 16.3,\\n      \\\"lon\\\": -118.9,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T18:00:00\\\",\\n      \\\"lat\\\": 16.5,\\n      \\\"lon\\\": -119.8,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-15T00:00:00\\\",\\n      \\\"lat\\\": 16.7,\\n      \\\"lon\\\": -120.7,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-15T06:00:00\\\",\\n      \\\"lat\\\": 16.9,\\n      \\\"lon\\\": -121.7,\\n      \\\"wind_speed\\\": 60\\n    }\\n  ]\\n}\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 1796,\n",
              "    \"completion_tokens\": 1264,\n",
              "    \"total_tokens\": 3060\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjRUp67a76iP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}