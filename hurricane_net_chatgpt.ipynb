{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4nD13bfxAVzXx/YKsxkS7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hammad93/hurricane-net/blob/main/hurricane_net_chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C59NcGtJugaf",
        "outputId": "ce9d86eb-5fa2-4c88-ec8a-b77983942f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set OpenAI API key to environment variable\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = ''"
      ],
      "metadata": {
        "id": "G8BZ6vmaut2Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is just a copy and paste of hurricane_net_chatgpt.py from github.com/hammad93/hurricane-net"
      ],
      "metadata": {
        "id": "tDXQ8o4YSwQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'api_url' : 'http://fluids.ai:1337/'\n",
        "}\n",
        "threads = {}\n",
        "from string import Template\n",
        "import requests\n",
        "import pandas as pd\n",
        "import openai\n",
        "import json\n",
        "import os\n",
        "\n",
        "def storm_forecast_prompts_sequentially(data):\n",
        "  hours = [6, 12, 24, 48, 72, 96, 120]\n",
        "  prompt = Template('''Please provide  a forecast for $future hours in the future from the most recent time from the storm.\n",
        "  The response will be a JSON object with these attributes:\n",
        "      \"time\" which is the predicted time in ISO 8601 format\n",
        "      \"lat\" which is the predicted latitude in decimal degrees\n",
        "      \"lon\" which is the predicted longitude in decimal degrees\n",
        "      \"wind_speed\" which is the predicted maximum sustained wind speed in knots.\n",
        "\n",
        "  Table 1. The historical records the includes columns representing measurements for the storm.\n",
        "  The wind_speed column is in knots representing the maxiumum sustained wind speeds.\n",
        "  The lat and lon are the geographic coordinates in decimal degrees.\n",
        "  time is sorted ascending in ISO 8601 format and the most recent time is the last entry.\n",
        "  $data\n",
        "  ''')\n",
        "  reflection_prompt = Template('''Please quality check the response. The following are requirements,\n",
        "  - It provides a forecast for $future hours in the future from the most recent time.\n",
        "  - It does not simply respond with the input data\n",
        "\n",
        "  Provide either True or False if it is an appropriate response. If it's False, add a comma and explain why and provide a better response.\n",
        "  ''')\n",
        "  return [\n",
        "    {\n",
        "      \"forecast_hour\" : hour,\n",
        "      \"prompt\" : prompt.substitute(future = hour, data = data),\n",
        "      \"reflection\" : reflection_prompt.substitute(future = hour)\n",
        "    }\n",
        "        for hour in hours\n",
        "  ]\n",
        "\n",
        "def chatgpt(prompt, model_version = \"gpt-3.5-turbo\", id = None):\n",
        "    '''\n",
        "    Given the prompt, this will pass it to the version of ChatGPT defined.\n",
        "    It's meant for forecasts of global tropical storms but can have a range of options.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    prompt String\n",
        "        The initial message to pass to ChatGPT\n",
        "    system String\n",
        "        The system message based on the current OpenAI API\n",
        "    model_version String\n",
        "        Which model to use\n",
        "    id String\n",
        "        The thread id, will be created if none exist.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "    '''\n",
        "    global threads\n",
        "    openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "\n",
        "    # generate thread or message\n",
        "    basic = [{\"role\": \"system\", \"content\": \"Please act as a forecaster and a helpful assistant. Responses should be based on historical data and forecasts must be as accurate as possible.\"},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    if id :\n",
        "      print(id)\n",
        "      # create id if it doesn't exist\n",
        "      if not threads.get(id, False) :\n",
        "        print(f'Adding id, {id} to threads.')\n",
        "        threads[id] = basic\n",
        "      thread = threads[id]\n",
        "    else :\n",
        "      thread = basic\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=thread\n",
        "    )\n",
        "    text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    print(text)\n",
        "    if id and threads.get(id, False) :\n",
        "      print(f\"Adding response to thread {id}.\")\n",
        "      threads[id] += [{\"role\": \"user\", \"content\": prompt},\n",
        "       {\"role\": \"assistant\", \"content\": text}]\n",
        "\n",
        "    # Find the indices of the first and last curly braces in the text\n",
        "    start_index = text.find('{')\n",
        "    end_index = text.rfind('}')\n",
        "\n",
        "    # Extract the JSON string from the text\n",
        "    json_string = text[start_index:end_index+1]\n",
        "    print(json_string)\n",
        "    # Parse the JSON string into a Python object\n",
        "    json_object = None\n",
        "    try :\n",
        "      json_object = json.loads(json_string)\n",
        "    except Exception as e :\n",
        "      print(f\"Couldn't parse the JSON in the response, {e}\")\n",
        "\n",
        "    return {\n",
        "        \"text\" : text,\n",
        "        \"json\" : json_object\n",
        "    }\n",
        "\n",
        "\n",
        "def chatgpt_forecast_live(model_version = \"gpt-3.5-turbo\"):\n",
        "    '''\n",
        "    This will pull in the live storms across the globe and engineer\n",
        "    prompts that will allow us to ingest forecasts from ChatGPT\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list(pd.DataFrame) A list of DataFrames that have the columns\n",
        "        id, time, lat, lon, and wind_speed\n",
        "    '''\n",
        "    # get the current live tropical storms around the globe\n",
        "    live_storms = get_live_storms()\n",
        "    prompts = get_prompts(live_storms)\n",
        "    # capture the forecast from ChatGPT\n",
        "    forecasts = []\n",
        "    for prompt in prompts:\n",
        "        forecasts.append(chatgpt_forecast(prompt, model_version))\n",
        "    return forecasts\n",
        "\n",
        "def chatgpt_forecast(prompt, model_version = \"gpt-3.5-turbo\"):\n",
        "    '''\n",
        "    Given the prompt, this will pass it to the version of ChatGPT defined.\n",
        "    It's meant for forecasts of global tropical storms but can have a range of options.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    prompt String\n",
        "        The initial message to pass to ChatGPT\n",
        "    system String\n",
        "        The system message based on the current OpenAI API\n",
        "    model_version String\n",
        "        Which model to use\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "    '''\n",
        "    openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Please act as a forecaster and a helpful assistant. Responses should be based on historical data and forecasts must be as accurate as possible.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt},\n",
        "            ]\n",
        "        )\n",
        "    text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    print(text)\n",
        "    # Find the indices of the first and last curly braces in the text\n",
        "    start_index = text.find('{')\n",
        "    end_index = text.rfind('}')\n",
        "\n",
        "    # Extract the JSON string from the text\n",
        "    json_string = text[start_index:end_index+1]\n",
        "\n",
        "    # Parse the JSON string into a Python object\n",
        "    json_object = json.loads(json_string)\n",
        "\n",
        "    # Extract the relevant information from the object\n",
        "    forecasts = json_object['forecasts']\n",
        "\n",
        "    return pd.DataFrame(forecasts)\n",
        "\n",
        "def get_live_storms():\n",
        "    '''\n",
        "    Upon calling this function, the live tropical storms around the global\n",
        "    will be returned in a JSON format. Each of the storms returned will have\n",
        "    the historical records along with in.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    df pandas.DataFrame\n",
        "        The records include the columns id, time, lat, lon, wind_speed\n",
        "    '''\n",
        "    # make the request for live data\n",
        "    response = requests.get(f\"{config['api_url']}live-storms\")\n",
        "    if response :\n",
        "        data = response.json()\n",
        "    else :\n",
        "        print(f'There was an error getting live storms, {response.content}')\n",
        "        return response\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def get_prompts(df):\n",
        "    '''\n",
        "    Utilizing the current global tropical storms, we will generate prompts\n",
        "    for a LLM such as ChatGPT to provide forecasts. This function will\n",
        "    generate prompts for each storm\n",
        "\n",
        "    Intput\n",
        "    ------\n",
        "    df pd.DataFrame\n",
        "        The records include the columns id, time, lat, lon, wind_speed.\n",
        "    '''\n",
        "    unique_storms = set(df['id'])\n",
        "    prompts = []\n",
        "    # apply each storm to the prompt template\n",
        "    for storm in unique_storms:\n",
        "        prompt = f'''\n",
        "I want you to act like a forecaster that gives a general idea of the future of the storm even though it will not be an official forecast.\n",
        "Please provide forecasts for 12, 24, 36, 48, 72, 96, 120 hours in the future from the most recent time in Figure 1.\n",
        "The response will be JSON formatted with \"forecasts\" as the only key. The value of the key is a list of forecast objects.\n",
        "Each forecast object has five attributes:\n",
        "    \"id\" which identifies the storm\n",
        "    \"time\" which is the predicted time in ISO 8601 format\n",
        "    \"lat\" which is the predicted latitude in decimal degrees\n",
        "    \"lon\" which is the predicted longitude in decimal degrees\n",
        "    \"wind_speed\" which is the predicted maximum sustained wind speed in knots.\n",
        "The response must be in JSON format, and the JSON characters must be at the beginning of the response.\n",
        "If you wish to add additional comments, it must be after the JSON data.\n",
        "\n",
        "Figure 1. The historical records the includes columns representing measurements for storm {storm}.\n",
        "The wind_speed column is in knots representing the maxiumum sustained wind speeds.\n",
        "The lat and lon are the geographic coordinates in decimal degrees.\n",
        "\n",
        "In JSON,\n",
        "{df[df['id'] == storm].to_json()}\n",
        "        '''\n",
        "        prompts.append(prompt)\n",
        "        print(prompt)\n",
        "    return prompts\n"
      ],
      "metadata": {
        "id": "D70MrYu5vyXU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "live_storms = get_live_storms()\n",
        "live_storms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "P7suEHVuSpa9",
        "outputId": "099839c5-31aa-48b6-cac0-d3e9fba7c999"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                 time   lat    lon  wind_speed  wind_speed_mph  \\\n",
              "0    WP982023  2023-08-17 12:00:00  28.0  148.9          15           27.78   \n",
              "1    WP982023  2023-08-17 18:00:00  28.1  148.8          15           27.78   \n",
              "2    WP982023  2023-08-18 00:00:00  28.2  148.6          15           27.78   \n",
              "3    WP982023  2023-08-18 06:00:00  28.2  148.4          15           27.78   \n",
              "4    WP982023  2023-08-18 12:00:00  28.1  148.1          15           27.78   \n",
              "..        ...                  ...   ...    ...         ...             ...   \n",
              "191  AL992023  2023-08-18 18:00:00  14.0  -45.2          25           46.30   \n",
              "192  AL992023  2023-08-19 00:00:00  14.7  -46.6          30           55.56   \n",
              "193  AL992023  2023-08-19 06:00:00  15.4  -47.8          30           55.56   \n",
              "194  AL992023  2023-08-19 12:00:00  16.1  -48.8          30           55.56   \n",
              "195  AL992023  2023-08-19 18:00:00  16.6  -49.9          30           55.56   \n",
              "\n",
              "     wind_speed_kph  \n",
              "0           17.2617  \n",
              "1           17.2617  \n",
              "2           17.2617  \n",
              "3           17.2617  \n",
              "4           17.2617  \n",
              "..              ...  \n",
              "191         28.7695  \n",
              "192         34.5234  \n",
              "193         34.5234  \n",
              "194         34.5234  \n",
              "195         34.5234  \n",
              "\n",
              "[196 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d6a81ef-cb07-47bc-897b-7c928f273a42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>time</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>wind_speed_mph</th>\n",
              "      <th>wind_speed_kph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WP982023</td>\n",
              "      <td>2023-08-17 12:00:00</td>\n",
              "      <td>28.0</td>\n",
              "      <td>148.9</td>\n",
              "      <td>15</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.2617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WP982023</td>\n",
              "      <td>2023-08-17 18:00:00</td>\n",
              "      <td>28.1</td>\n",
              "      <td>148.8</td>\n",
              "      <td>15</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.2617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WP982023</td>\n",
              "      <td>2023-08-18 00:00:00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>148.6</td>\n",
              "      <td>15</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.2617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WP982023</td>\n",
              "      <td>2023-08-18 06:00:00</td>\n",
              "      <td>28.2</td>\n",
              "      <td>148.4</td>\n",
              "      <td>15</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.2617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WP982023</td>\n",
              "      <td>2023-08-18 12:00:00</td>\n",
              "      <td>28.1</td>\n",
              "      <td>148.1</td>\n",
              "      <td>15</td>\n",
              "      <td>27.78</td>\n",
              "      <td>17.2617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>AL992023</td>\n",
              "      <td>2023-08-18 18:00:00</td>\n",
              "      <td>14.0</td>\n",
              "      <td>-45.2</td>\n",
              "      <td>25</td>\n",
              "      <td>46.30</td>\n",
              "      <td>28.7695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>AL992023</td>\n",
              "      <td>2023-08-19 00:00:00</td>\n",
              "      <td>14.7</td>\n",
              "      <td>-46.6</td>\n",
              "      <td>30</td>\n",
              "      <td>55.56</td>\n",
              "      <td>34.5234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>AL992023</td>\n",
              "      <td>2023-08-19 06:00:00</td>\n",
              "      <td>15.4</td>\n",
              "      <td>-47.8</td>\n",
              "      <td>30</td>\n",
              "      <td>55.56</td>\n",
              "      <td>34.5234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>AL992023</td>\n",
              "      <td>2023-08-19 12:00:00</td>\n",
              "      <td>16.1</td>\n",
              "      <td>-48.8</td>\n",
              "      <td>30</td>\n",
              "      <td>55.56</td>\n",
              "      <td>34.5234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>AL992023</td>\n",
              "      <td>2023-08-19 18:00:00</td>\n",
              "      <td>16.6</td>\n",
              "      <td>-49.9</td>\n",
              "      <td>30</td>\n",
              "      <td>55.56</td>\n",
              "      <td>34.5234</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>196 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d6a81ef-cb07-47bc-897b-7c928f273a42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d6a81ef-cb07-47bc-897b-7c928f273a42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d6a81ef-cb07-47bc-897b-7c928f273a42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-322db041-2073-46e8-b249-ded4b8ad4314\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-322db041-2073-46e8-b249-ded4b8ad4314')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-322db041-2073-46e8-b249-ded4b8ad4314 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate prompts for one of the storms\n",
        "max_historical_track = 4 * 3 # days, approx if 6 hour interval\n",
        "example_id = 'AL992023'\n",
        "example_data = live_storms.query(f\"id == '{example_id}'\").sort_values(by='time', ascending=False).iloc[:max_historical_track]\n",
        "example_data_input = example_data.drop(columns=['id', 'wind_speed_mph', 'wind_speed_kph']).to_json(indent=2, orient='records')\n",
        "print(example_data_input)\n",
        "prompts = storm_forecast_prompts_sequentially(example_data_input)"
      ],
      "metadata": {
        "id": "fvbKs_e8TFif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts"
      ],
      "metadata": {
        "id": "sIdsr5ExZV28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    random_prefix = '1432143'\n",
        "    results = list(executor.map(lambda p: chatgpt(*p),\n",
        "     [(prompt[\"prompt\"], 'gpt-3.5-turbo', f\"{random_prefix}_{index}\") for index, prompt in enumerate(prompts)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsHN6PJKXPoQ",
        "outputId": "d90add84-ce8e-436a-9fc7-4d0eef91cfd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1432143_01432143_1\n",
            "Adding id, 1432143_1 to threads.\n",
            "\n",
            "Adding id, 1432143_0 to threads.\n",
            "1432143_2\n",
            "Adding id, 1432143_2 to threads.\n",
            "1432143_3\n",
            "Adding id, 1432143_3 to threads.\n",
            "1432143_41432143_5\n",
            "Adding id, 1432143_5 to threads.\n",
            "\n",
            "Adding id, 1432143_4 to threads.\n",
            "Based on the historical data provided, the forecast for 6 hours in the future from the most recent time of the storm would be:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-19T18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Adding response to thread 1432143_0.\n",
            "{\n",
            "  \"time\": \"2023-08-19T18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "1432143_6\n",
            "Adding id, 1432143_6 to threads.\n",
            "Based on the provided historical data, we can make a forecast for the storm 72 hours in the future. The wind speeds have been consistent at 30 knots for the last four measurements. Assuming this pattern continues, we can forecast a maximum sustained wind speed of 30 knots for the next 72 hours.\n",
            "\n",
            "Let's also assume that the storm's path remains consistent, with a gradual movement towards the west. Based on the lat and lon data, we can predict the storm's position as follows:\n",
            "\n",
            "- 72 hours from the most recent time, the storm's position will be at approximately lat 16.6, lon -49.9.\n",
            "Adding response to thread 1432143_4.\n",
            "\n",
            "Couldn't parse the JSON in the response, Expecting value: line 1 column 1 (char 0)\n",
            "Based on the provided historical data, the forecast for 48 hours in the future from the most recent time of the storm is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast assumes that the storm's movement and intensity will remain consistent based on historical patterns.\n",
            "Adding response to thread 1432143_3.\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Based on the historical data provided, we can observe that the storm has maintained a consistent wind speed of 30 knots for the past four recordings. Therefore, it is likely that the storm will maintain the same wind speed in the next 96 hours. However, the storm has been moving in a west-southwest direction, so we can approximate the future position based on that trend.\n",
            "\n",
            "Assuming the storm continues on the same path and maintains a wind speed of 30 knots, the forecast for 96 hours in the future is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-23 00:00:00\",\n",
            "  \"lat\": 14.7,\n",
            "  \"lon\": -49.6,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based solely on the historical data provided and assumes no major changes in the storm's behavior.\n",
            "Adding response to thread 1432143_5.\n",
            "{\n",
            "  \"time\": \"2023-08-23 00:00:00\",\n",
            "  \"lat\": 14.7,\n",
            "  \"lon\": -49.6,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Based on the historical data provided, we can forecast the storm conditions for 24 hours in the future from the most recent time. The most recent time in the data is \"2023-08-19 18:00:00\".\n",
            "\n",
            "However, since the wind speed has remained constant at 30 knots for the past 4 data points, it is reasonable to assume that the wind speed 24 hours from now will also be 30 knots. \n",
            "\n",
            "Based on this assumption, the forecast for 24 hours in the future from the most recent time is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based on the assumption that the wind speed will remain constant. We recommend monitoring the storm closely for any updates or changes in the forecast.\n",
            "Adding response to thread 1432143_2.\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Based on the provided historical data, we can observe that the storm has been moving in a westward direction along the latitudes between 11.1 and 16.6. The maximum sustained wind speed has remained consistent at 30 knots for the past four observations.\n",
            "\n",
            "Assuming the storm continues to follow this westward trajectory and maintains its current intensity, we can forecast the storm's position and maximum sustained wind speed for 120 hours in the future, based on historical data.\n",
            "\n",
            "Here is the forecast for 120 hours in the future from the most recent time:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast assumes the storm's track and intensity remain unchanged. However, weather systems can be unpredictable, and it is recommended to consult local meteorological authorities for the most up-to-date and accurate information.\n",
            "Adding response to thread 1432143_6.\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Based on the provided historical data, we can analyze the trend in wind speed and location of the storm to make a forecast for the storm's conditions 12 hours in the future.\n",
            "\n",
            "As per the historical data, the storm has been moving in a northwest direction with a consistent wind speed of 30 knots. Assuming this trend continues, we can predict the storm's location and wind speed 12 hours from the most recent record.\n",
            "\n",
            "The most recent record in the data is for \"2023-08-19 18:00:00\" with a latitude of 16.6 degrees and a longitude of -49.9 degrees. The wind speed is 30 knots.\n",
            "\n",
            "Based on this information and considering the storm's northwest movement, we can forecast that 12 hours from the most recent time, the storm will be at a latitude of approximately 16.8 degrees and a longitude of -50.1 degrees. The forecasted wind speed would likely remain at 30 knots.\n",
            "\n",
            "Therefore, the forecast for 12 hours in the future from the most recent time of the storm is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-20 06:00:00\",\n",
            "  \"lat\": 16.8,\n",
            "  \"lon\": -50.1,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based solely on historical data and assumes the storm's movement and wind speed remain consistent. Actual conditions may vary.\n",
            "Adding response to thread 1432143_1.\n",
            "{\n",
            "  \"time\": \"2023-08-20 06:00:00\",\n",
            "  \"lat\": 16.8,\n",
            "  \"lon\": -50.1,\n",
            "  \"wind_speed\": 30\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add reflection step here\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    random_prefix = '1432143'\n",
        "    results_reflection = list(executor.map(lambda p: chatgpt(*p),\n",
        "     [(prompt[\"reflection\"], 'gpt-3.5-turbo', f\"{random_prefix}_{index}\") for index, prompt in enumerate(prompts)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55bvVMd4cbAA",
        "outputId": "f87a2ece-7fd9-4e9c-d736-1d1858a8f71f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1432143_0\n",
            "1432143_1\n",
            "1432143_2\n",
            "1432143_3\n",
            "1432143_4\n",
            "1432143_5\n",
            "{\n",
            "  \"time\": \"2023-08-22T18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Adding response to thread 1432143_4.\n",
            "{\n",
            "  \"time\": \"2023-08-22T18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "1432143_6\n",
            "Apologies for the error in the previous response. Based on the provided historical data, the forecast for 48 hours in the future from the most recent time of the storm is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-21 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast assumes that the storm's movement and intensity will remain consistent based on historical patterns.\n",
            "Adding response to thread 1432143_3.\n",
            "{\n",
            "  \"time\": \"2023-08-21 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "I apologize for the confusion, it seems I made a mistake in the calculation. Let me recalculate the forecast using the correct data.\n",
            "\n",
            "Based on the historical data provided, the storm has been maintaining a consistent wind speed of 30 knots for the past four recordings. Therefore, it is likely that the storm will maintain the same wind speed in the next 96 hours.\n",
            "\n",
            "Considering the storm's previous movement in a west-southwest direction, we can estimate the future position based on that trend.\n",
            "\n",
            "Assuming the storm continues on the same path and maintains a wind speed of 30 knots, the forecast for 96 hours in the future is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 14.3,\n",
            "  \"lon\": -53.2,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based solely on the historical data provided, and it assumes no major changes in the storm's behavior.\n",
            "Adding response to thread 1432143_5.\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 14.3,\n",
            "  \"lon\": -53.2,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "Based on the provided historical data, the storm has been moving in a consistent northwest direction with a wind speed of 30 knots.\n",
            "\n",
            "To make a forecast for 12 hours in the future from the most recent time, we can assume that the storm will continue its northwest path and maintain its current wind speed.\n",
            "\n",
            "The most recent record in the data is for \"2023-08-19 18:00:00\" with a latitude of 16.6 degrees and a longitude of -49.9 degrees. The wind speed is 30 knots.\n",
            "\n",
            "Based on this information and assuming that the storm's movement and wind speed remain constant, we can forecast the following:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-20 06:00:00\",\n",
            "  \"lat\": 17.0,\n",
            "  \"lon\": -50.3,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based solely on the historical data and assumes that the storm will maintain its current path and intensity. Actual conditions may vary, and it is important to monitor official forecasts and advisories from meteorological agencies for the most up-to-date information.\n",
            "Adding response to thread 1432143_1.\n",
            "{\n",
            "  \"time\": \"2023-08-20 06:00:00\",\n",
            "  \"lat\": 17.0,\n",
            "  \"lon\": -50.3,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "I apologize, I made a mistake in the forecast. Let me correct it based on the historical data.\n",
            "\n",
            "Based on the historical data provided, the wind speed for the past 4 data points has been constant at 30 knots. Therefore, it is reasonable to assume that the wind speed will remain at 30 knots for the next 24 hours.\n",
            "\n",
            "The most recent time in the data is \"2023-08-19 18:00:00\". Adding 24 hours to this time gives us \"2023-08-20 18:00:00\".\n",
            "\n",
            "Based on this, the forecast for 24 hours in the future from the most recent time is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this forecast is based on the assumption that the wind speed will remain constant. It is always recommended to monitor the storm closely for any updates or changes in the forecast.\n",
            "Adding response to thread 1432143_2.\n",
            "{\n",
            "  \"time\": \"2023-08-20 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "I apologize for the incorrect response. Let me recalculate the forecast for you based on the provided historical data.\n",
            "\n",
            "The most recent record in the historical data is at 2023-08-19 18:00:00, with a latitude of 16.6 and a longitude of -49.9, and a wind speed of 30 knots.\n",
            "\n",
            "Assuming the storm has been moving at a constant speed and direction, we can make an estimation for 6 hours in the future. Given that the storm has been moving at an average speed of 0.2 degrees per hour (latitudinally) and -1.1 degrees per hour (longitudinally), we can estimate the position of the storm 6 hours from now.\n",
            "\n",
            "The forecast for 6 hours in the future from the most recent time of the storm is:\n",
            "{\n",
            "  \"time\": \"2023-08-20T00:00:00\",\n",
            "  \"lat\": 14.6,\n",
            "  \"lon\": -56.5,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "Please note that this is an estimation based on historical data and assumptions about the storm's movement. Actual conditions may vary.\n",
            "Adding response to thread 1432143_0.\n",
            "{\n",
            "  \"time\": \"2023-08-20T00:00:00\",\n",
            "  \"lat\": 14.6,\n",
            "  \"lon\": -56.5,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "I apologize, it seems my previous response was incorrect. I mistakenly provided the forecast for the same location and wind speed as the most recent observation. Let me recalculate the forecast based on the historical data provided.\n",
            "\n",
            "Considering the storm's westward movement and sustained wind speed of 30 knots in the most recent observation, I will assume the storm maintains its current track and intensity for the next 120 hours. However, please note that this is a simplified forecast and actual conditions may vary.\n",
            "\n",
            "Based on this assumption, the forecast for 120 hours in the future from the most recent time is as follows:\n",
            "\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n",
            "\n",
            "However, it is important to note that weather conditions are subject to change, and it is always recommended to consult official weather forecasts and local authorities for the most accurate and up-to-date information.\n",
            "Adding response to thread 1432143_6.\n",
            "{\n",
            "  \"time\": \"2023-08-23 18:00:00\",\n",
            "  \"lat\": 16.6,\n",
            "  \"lon\": -49.9,\n",
            "  \"wind_speed\": 30\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "model_version = \"gpt-3.5-turbo\"\n",
        "example_messages = [\n",
        "  {\"role\": \"system\", \"content\": \"Please act like an expert in tropical storm forecasting. Responses will be used for research and not for official purposes. Responses should be based on historical data and forecasts must be as accurate as possible.\"},\n",
        "  {\"role\": \"user\", \"content\": example_prompt},\n",
        "]\n",
        "response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=example_messages\n",
        "        )\n",
        "text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn97yfuFzF0j",
        "outputId": "2cbfe664-b78e-462b-ce57-461f3c72bc10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the historical data provided, the forecast for 12 hours in the future from the most recent time is as follows:\n",
            "\n",
            "{\n",
            "  \"id\": \"EP72023\",\n",
            "  \"time\": \"2023-08-13T12:00:00\",\n",
            "  \"lat\": 15.2,\n",
            "  \"lon\": -114.6,\n",
            "  \"wind_speed\": 40\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_message = example_messages + [\n",
        "  {\"role\": \"assistant\", \"content\": text},\n",
        "  {\"role\": \"user\", \"content\": example_reflection}]\n",
        "response = openai.ChatCompletion.create(\n",
        "        model=model_version,\n",
        "        messages=reflection_message\n",
        "        )\n",
        "text = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIVB5gg12Qp5",
        "outputId": "724bba08-fba1-4e88-c76b-5348f73425c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False, the forecast provided is not appropriate as it simply repeats the most recent entry from the historical data. The forecast should be based on the historical data but adjusted to reflect the predicted conditions 12 hours in the future. I apologize for the oversight.\n",
            "\n",
            "A revised forecast for 12 hours in the future from the most recent time, based on the historical data, would be as follows:\n",
            "\n",
            "{\n",
            "  \"id\": \"EP72023\",\n",
            "  \"time\": \"2023-08-13T12:00:00\",\n",
            "  \"lat\": 15.4,\n",
            "  \"lon\": -115.4,\n",
            "  \"wind_speed\": 45\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzP-3s4a44ae",
        "outputId": "be042952-108b-4ff6-de9b-352d2dcdcd1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7mvvCsLE0FBgOzy8pB4uCjlakJ3j7 at 0x7c69d34dc630> JSON: {\n",
              "  \"id\": \"chatcmpl-7mvvCsLE0FBgOzy8pB4uCjlakJ3j7\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1691896750,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"{\\n  \\\"forecasts\\\": [\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T00:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -102.5,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T06:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -104.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T12:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -105.2,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-10T18:00:00\\\",\\n      \\\"lat\\\": 10.0,\\n      \\\"lon\\\": -106.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T00:00:00\\\",\\n      \\\"lat\\\": 10.3,\\n      \\\"lon\\\": -107.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T06:00:00\\\",\\n      \\\"lat\\\": 11.0,\\n      \\\"lon\\\": -107.7,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T12:00:00\\\",\\n      \\\"lat\\\": 12.2,\\n      \\\"lon\\\": -108.2,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-11T18:00:00\\\",\\n      \\\"lat\\\": 13.3,\\n      \\\"lon\\\": -109.1,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T00:00:00\\\",\\n      \\\"lat\\\": 13.7,\\n      \\\"lon\\\": -110.0,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T06:00:00\\\",\\n      \\\"lat\\\": 13.9,\\n      \\\"lon\\\": -110.9,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T12:00:00\\\",\\n      \\\"lat\\\": 14.2,\\n      \\\"lon\\\": -111.8,\\n      \\\"wind_speed\\\": 25\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-12T18:00:00\\\",\\n      \\\"lat\\\": 14.6,\\n      \\\"lon\\\": -112.6,\\n      \\\"wind_speed\\\": 30\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T00:00:00\\\",\\n      \\\"lat\\\": 14.9,\\n      \\\"lon\\\": -113.6,\\n      \\\"wind_speed\\\": 35\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T06:00:00\\\",\\n      \\\"lat\\\": 15.2,\\n      \\\"lon\\\": -114.5,\\n      \\\"wind_speed\\\": 40\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T12:00:00\\\",\\n      \\\"lat\\\": 15.4,\\n      \\\"lon\\\": -115.3,\\n      \\\"wind_speed\\\": 45\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-13T18:00:00\\\",\\n      \\\"lat\\\": 15.7,\\n      \\\"lon\\\": -116.2,\\n      \\\"wind_speed\\\": 50\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T00:00:00\\\",\\n      \\\"lat\\\": 15.9,\\n      \\\"lon\\\": -117.1,\\n      \\\"wind_speed\\\": 55\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T06:00:00\\\",\\n      \\\"lat\\\": 16.1,\\n      \\\"lon\\\": -118.0,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T12:00:00\\\",\\n      \\\"lat\\\": 16.3,\\n      \\\"lon\\\": -118.9,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-14T18:00:00\\\",\\n      \\\"lat\\\": 16.5,\\n      \\\"lon\\\": -119.8,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-15T00:00:00\\\",\\n      \\\"lat\\\": 16.7,\\n      \\\"lon\\\": -120.7,\\n      \\\"wind_speed\\\": 60\\n    },\\n    {\\n      \\\"id\\\": \\\"EP72023\\\",\\n      \\\"time\\\": \\\"2023-08-15T06:00:00\\\",\\n      \\\"lat\\\": 16.9,\\n      \\\"lon\\\": -121.7,\\n      \\\"wind_speed\\\": 60\\n    }\\n  ]\\n}\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 1796,\n",
              "    \"completion_tokens\": 1264,\n",
              "    \"total_tokens\": 3060\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IjRUp67a76iP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}