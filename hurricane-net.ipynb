{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hurricane-net\n",
    "Hammad Usmani\n",
    "### A machine learning algorithm to forecast the intensity and trajectory of Atlantic tropical storms\n",
    "[https://github.com/hammad93/hurricane-net](https://github.com/hammad93/hurricane-net)\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "2. [Problem](#Problem)\n",
    "3. [Datasets](#Datasets)\n",
    "4. [Workflow Diagram](#Workflow)\n",
    "5. [Data Extraction](#Extract)\n",
    "6. [Data Transformation](#Transform)\n",
    "7. [Data Loading](#Load)\n",
    "8. [Feature Engineering](#FeatureEngineering)\n",
    "9. [Model Architecture](#ModelArchitecture)\n",
    "11. [Model Selection](#ModelSelection)\n",
    "12. [Paramater Optimization](#Optimization)\n",
    "13. [Model Evaluation & Benchmarks](#Benchmarks)\n",
    "14. [Visualizations](#Visualizations)\n",
    "\n",
    "![Hurricane Maria 2017](img/hurricane-maria.png \"Hurricane Maria. Source: NOAA\")\n",
    "\n",
    "## Background<a id=\"Background\"></a>\n",
    "\n",
    "The National Hurricane Center (NHC) and National Oceanic and Atmospheric Administration (NOAA) provide predictions for storms trajectories, intensity, and size. They create these predictions based on models that can be classified into 3 groups: dynamical, statistical, and ensemble [1]. The most accurate models are based on computational fluid dynamics and achieve more precision than their statistical and ensemble counterparts [1][4]. The current statistical models (OCD5) are based on multiple regression methods that can explain a significant amount of variance [1]. In this project, we research and implement the domain of machine learning and deep learning into predictive hurricane models for both trajectory and intensity and evaluate them against the NHC standards. \n",
    "Previous research into machine learning to forecast tropical Atlantic storms include a sparse recurrent neural network (Kordmahalleh, Sefidmazgi, & Homaifar, 2016) and an artificial neural network (Jung & Das, 2013); both achieved favorable results. The hurricane models created can be utilized to develop more precise emergency planning. There is a necessity for more accurate and timely models that can help reduce the amount of loss caused by hurricanes. \n",
    "\n",
    "## Problem<a id=\"Problem\"></a>\n",
    "\n",
    "The NOAA and NHC have several different classifications for Atlantic hurricane models that describe feature prediction and model architecture. The 3 main classifications for hurricane model architecture include dynamical, statistical, and ensemble. Classifications also include relative compute time required to create an output grouped as either early or late and forecast parameters such as trajectory, intensity, and wind radii. The most accurate models are late models that take upwards of 6 hours to produce an output whereas models that can produce an output in seconds to minutes are called early. Early models tend to be statistical which include the baseline model for trajectory named CLIPER5 Climatology and Persistence (CLP5) utilizing multivariate regression. The performance for these methods can be augmented by incorporating more advanced statistical methods from deep learning such as recurrent neural networks. Kordmahalleh et al., 2016 created a sparse recurrent neural network augmented by a genetic algorithm but there are factors requiring improvement. The training set utilized an older version of the NHC Hurricane Database format known as HURDAT while a new format has been released called HURDAT2 with additional information on wind radii. Kordmahalleh et al., 2016 also utilized benchmarks different from the standard applied within the NHC. Other than improving their methodology, we can expand the scope by creating separate models for both intensity and trajectory. These models can be used to predict the trajectory and intensity for future Atlantic storms.\n",
    "\n",
    "## Datasets<a id=\"Datasets\"></a>\n",
    "\n",
    "The following datasets and inputs including their sources will be used to create machine learning models:\n",
    "- NHC Hurricane Database (HURDAT2)\n",
    "    - http://www.nhc.noaa.gov/data/#hurdat\n",
    "    - https://www.kaggle.com/noaa/hurricane-database\n",
    "- NHC Forecast Error Database\n",
    "    - http://www.nhc.noaa.gov/verification/verify7.shtml\n",
    "- NHC GIS\n",
    "    - http://www.nhc.noaa.gov/gis/\n",
    "    \n",
    "The NHC HURDAT2 database contains the tracking information for Atlantic tropical and subtropical cyclones which includes hurricanes and tropical storms from 1851 to 2016. The most updated version of the dataset is included on the noaa.gov site and includes 2 additional years of cyclone data compared to the data set available on Kaggle and is potentially more descriptive. To match the inputs of the baseline model used by the NHC, we are calculating the forward motion of the storm by applying a vector based on previous and current geographical location.\n",
    "\n",
    "*Table 1. This table contains the tentative features as input to the model*\n",
    "\n",
    "| **Name**         | **Data Type** | **Description**                                                     |\n",
    "|------------------|---------------|---------------------------------------------------------------------|\n",
    "| Time             | Date Time     | The date and time of the measurement.                               |\n",
    "| Latitude         | Float         | The geographical latitude of the storm eye to 1 decimal precision.  |\n",
    "| Longitude        | Float         | The geographical longitude of the storm eye to 1 decimal precision. |\n",
    "| Maximum Winds    | Integer       | The maximum sustained winds within the storm.                       |\n",
    "| Minimum Pressure | Integer       | The minimum barometric pressure within the storm.                   |\n",
    "| Forward Motion   | String        | Calculated vector of motion based on location in time series.       |\n",
    "\n",
    "The Forecast Error Database contains information on the accuracy of predicted models from the NHC. The two model forecast errors available are labeled OFCL and BCD5. The OFCL is the official NHC forecast and the BCD5 is the real track available. This data set can be used to benchmark and evaluate the deep learning model. \n",
    "The NOAA and NHC also hosts a geographical information system (GIS) that contains raw and processed data on hurricanes. The server hosting the GIS is publicly accessible and can be used to evaluate our model by comparing the 2017 Atlantic tropical season. The preliminary best tracks can be found here before they are finalized and available in the HURDAT2 data set. With the GIS, we can construct a final evaluation data set.\n",
    "\n",
    "*Diagram 1. This graphic describes the workflow for the deep learning models*.<a id=\"Workflow\"></a>\n",
    "![Data Pipeline](img/Deep Learning Workflow.png \"hurricane-net Data Pipeline\")\n",
    "\n",
    "## Extract Data<a id=\"Extract\"></a>\n",
    "\n",
    "*The following code uses the hurdat2 and models modules created to provide a class interface for the HURDAT2 and error forecast database located in the data and models folder. *\n",
    "\n",
    "We will begin our steps to perform extraction, transformation, and loading of our data for analysis or broadly known as ETL. Although we're dividing these steps into disctinct procedures, they are often more fluid and often have overlaps. The extraction phase consists of collecting and parsing the HURDAT2 and error forecast databases for analysis and benchmarking. The HURDAT2 database is our core foundation for creating the deep learning model. We store the database in its raw .txt format but it can be directly linked to the database hosted by the NHC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_id</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>entry_status</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>34kt_ne</th>\n",
       "      <th>...</th>\n",
       "      <th>34kt_sw</th>\n",
       "      <th>34kt_nw</th>\n",
       "      <th>50kt_ne</th>\n",
       "      <th>50kt_se</th>\n",
       "      <th>50kt_sw</th>\n",
       "      <th>50kt_nw</th>\n",
       "      <th>64kt_ne</th>\n",
       "      <th>64kt_se</th>\n",
       "      <th>64kt_sw</th>\n",
       "      <th>64kt_nw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44063</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-23 18:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.1N</td>\n",
       "      <td>75.1W</td>\n",
       "      <td>30</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44064</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.4N</td>\n",
       "      <td>75.7W</td>\n",
       "      <td>30</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44065</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 06:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.8N</td>\n",
       "      <td>76.2W</td>\n",
       "      <td>30</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44066</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 12:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>24.5N</td>\n",
       "      <td>76.5W</td>\n",
       "      <td>35</td>\n",
       "      <td>1006</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44067</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 18:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>25.4N</td>\n",
       "      <td>76.9W</td>\n",
       "      <td>40</td>\n",
       "      <td>1003</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
       "44063  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
       "44064  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
       "44065  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
       "44066  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
       "44067  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
       "\n",
       "        long max_wind min_pressure 34kt_ne   ...   34kt_sw 34kt_nw 50kt_ne  \\\n",
       "44063  75.1W       30         1008       0   ...         0       0       0   \n",
       "44064  75.7W       30         1007       0   ...         0       0       0   \n",
       "44065  76.2W       30         1007       0   ...         0       0       0   \n",
       "44066  76.5W       35         1006      60   ...         0       0       0   \n",
       "44067  76.9W       40         1003      60   ...         0       0       0   \n",
       "\n",
       "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
       "44063       0       0       0       0       0       0       0  \n",
       "44064       0       0       0       0       0       0       0  \n",
       "44065       0       0       0       0       0       0       0  \n",
       "44066       0       0       0       0       0       0       0  \n",
       "44067       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import various libraries throughout the software\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Import from hurdat2 class in data folder and models class from hurricane-models folder\n",
    "from data.hurdat2 import hurdat2\n",
    "from errors.models import models\n",
    "\n",
    "# Initialize Dataframe for hurricanes and error database\n",
    "dataset = hurdat2(\"data/hurdat2.txt\")\n",
    "errors = models(\"errors/1970-present_OFCL_v_BCD5_ind_ATL_TI_errors_noTDs.txt\")\n",
    "\n",
    "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
    "dataset.hurricanes.query('storm_id == \"AL122005\"').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{       'intensity_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): 0.0,\n",
      "                                      datetime.datetime(2005, 8, 29, 6, 0): 20.9,\n",
      "                                      datetime.datetime(2005, 8, 29, 18, 0): 93.6,\n",
      "                                      datetime.datetime(2005, 8, 30, 6, 0): 170.2,\n",
      "                                      datetime.datetime(2005, 8, 30, 18, 0): None,\n",
      "                                      datetime.datetime(2005, 8, 31, 18, 0): None,\n",
      "                                      datetime.datetime(2005, 9, 1, 18, 0): None,\n",
      "                                      datetime.datetime(2005, 9, 2, 18, 0): None,\n",
      "                                      datetime.datetime(2005, 9, 3, 18, 0): None,\n",
      "                                      datetime.datetime(2005, 9, 4, 18, 0): None},\n",
      "        'lat': 26.3,\n",
      "        'long': 88.6,\n",
      "        'sample_sizes': {       'F012': 0.33,\n",
      "                                'F024': 0.33,\n",
      "                                'F036': 0.33,\n",
      "                                'F048': 0.0,\n",
      "                                'F072': 0.0,\n",
      "                                'F096': 0.0,\n",
      "                                'F120': 0.0,\n",
      "                                'F144': 0.0,\n",
      "                                'F168': 0.0},\n",
      "        'track_forecast': {       datetime.datetime(2005, 8, 28, 18, 0): 0.0,\n",
      "                                  datetime.datetime(2005, 8, 29, 6, 0): 28.0,\n",
      "                                  datetime.datetime(2005, 8, 29, 18, 0): 32.0,\n",
      "                                  datetime.datetime(2005, 8, 30, 6, 0): 17.0,\n",
      "                                  datetime.datetime(2005, 8, 30, 18, 0): None,\n",
      "                                  datetime.datetime(2005, 8, 31, 18, 0): None,\n",
      "                                  datetime.datetime(2005, 9, 1, 18, 0): None,\n",
      "                                  datetime.datetime(2005, 9, 2, 18, 0): None,\n",
      "                                  datetime.datetime(2005, 9, 3, 18, 0): None,\n",
      "                                  datetime.datetime(2005, 9, 4, 18, 0): None},\n",
      "        'wind_speed': 150}\n"
     ]
    }
   ],
   "source": [
    "# Show the first 3 OFCL hurricane model errors for Hurricane Katrina 2005 on 28-08-2005/18:00:00\n",
    "pprint(errors.models['OFCL'].storm['AL122005'][datetime.datetime(2005, 8, 28, 18, 0)], indent = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Data<a id=\"Transform\"></a>\n",
    "\n",
    "The following code will tranform the hurricane best path data into objects that can be better manipulated for processing. to match between datasets, we will also create a `storm_id` dictionary to store storm names matched with ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming HURDAT2 into objects . . .\n",
      "Transforming 49691/49691 entries from HURDAT2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Create hurricane class\n",
    "class hurricane(object) : \n",
    "    def __init__(self, name, id) :\n",
    "        # Set instance variables\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.entries = dict()\n",
    "        self.models = dict()\n",
    "        \n",
    "        return\n",
    "    # Add hurricane track entry based on standard HURDAT2 format\n",
    "    def add_entry(self, array) :\n",
    "        entry = {\n",
    "            array[0] : { # dateteime of entry\n",
    "                'entry_time' : array[0], \n",
    "                'entry_id' : array[1],\n",
    "                'entry_status' : array[2],\n",
    "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
    "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
    "                'max_wind' : float(array[5]),\n",
    "                'min_pressure' : None if array[6] is None else float(array[6]), # Early records are -999 or None\n",
    "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
    "            }\n",
    "        }\n",
    "        self.entries.update(entry)\n",
    "        \n",
    "        return\n",
    "    # Add hurricane model errors\n",
    "    def add_model(self, name, model) :\n",
    "        self.models[name] = model\n",
    "        \n",
    "        return\n",
    "# Storm ID Key for matching between datasets\n",
    "storm_id = dict()\n",
    "\n",
    "# Parse in hurricanes\n",
    "hurricanes = dict()\n",
    "print(\"Transforming HURDAT2 into objects . . .\")\n",
    "for index, entry in dataset.hurricanes.iterrows() :\n",
    "    print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset.hurricanes)), end = \"\\r\")\n",
    "    # New hurricane\n",
    "    if entry['storm_id'] not in hurricanes :\n",
    "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
    "        storm_id[entry['storm_id']] = entry['storm_name']\n",
    "    # Add entry to hurricane\n",
    "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data<a id=\"Load\"></a>\n",
    "\n",
    "The following will finalize our preliminary data preparation by loading some of the errors into each hurricane object. Note that models start from the year 1970 and any hurricane before that has no previous model data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available model errors\n",
    "models = errors.models.keys()\n",
    "# Load model errors into hurricanes\n",
    "for id in storm_id :\n",
    "    for model in models :\n",
    "        # Skip if this hurricane does not have the model\n",
    "        if id not in errors.models[model].storm :\n",
    "            continue\n",
    "        hurricanes[id].add_model(model, errors.models[model].storm[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Engineering & Data Augmentation<a id=\"FeatureEngineering\"></a>\n",
    "\n",
    "The following section will extract the relevant features and engineer each data point so that we can fit it into the model. Because the type of inputs are important, the features will be transformed based on the model architecture. This will also include data augmentation methods. The higher level architecture will be a deep learning recurrent neural network with LSTM and time distributed layers.\n",
    "\n",
    "The current statistical baseline model using multivariate regression uses multiple predictors as input. According to Knaff 2013, the following predictors were calculated for their intensity model that were not included in the HURDAT2 database. These features can be calculated from the data loaded into our current object model.\n",
    "\n",
    "1. Date Information\n",
    "2. Zonal Speed Of The Storm (U) (kt)\n",
    "3. Meridional Speed Of The Storm (V) (kt)\n",
    "4. 12-h Change In Intensity (DVMX) (kt)\n",
    "\n",
    "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 5 day forecast and observations without track data 5 days in the future will not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered 1830/1830 hurricanes for 5 timestep(s)\n",
      "Done feature engineering hurricanes.\n",
      "Scaling Data . . . (1 timestep for unqiue data)\n",
      "Feature engineered 1830/1830 hurricanes for 1 timestep(s)\n",
      "Done feature engineering hurricanes.\n",
      "Done scaling.\n"
     ]
    }
   ],
   "source": [
    "def feature_extraction(timestep, previous) :\n",
    "    '''\n",
    "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
    "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
    "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
    "            previous - previous timestep dictionary of features in the hurricane object format\n",
    "    OUTPUT: Dictionary of features\n",
    "    '''\n",
    "    features = {\n",
    "        'lat' : timestep['lat'],\n",
    "        'long' : timestep['long'],\n",
    "        'max_wind' : timestep['max_wind'],\n",
    "        'delta_wind' : (timestep['max_wind'] - previous['max_wind']) / # Calculated from track (12h)\n",
    "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 43200),\n",
    "        'min_pressure' : timestep['min_pressure'], \n",
    "        'zonal_speed' : (timestep['lat'] - previous['lat'])/ # Calculated from track (per hour)\n",
    "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
    "        'meridonal_speed' : (timestep['long'] - previous['long'])/# Calculated from track (per hour)\n",
    "            ((timestep['entry_time'] - previous['entry_time']).total_seconds() / 3600),\n",
    "        'year' : timestep['entry_time'].year,\n",
    "        'month' : timestep['entry_time'].month,\n",
    "        'day' : timestep['entry_time'].day,\n",
    "        'hour' : timestep['entry_time'].hour,\n",
    "    }\n",
    "    return features\n",
    "    \n",
    "def storm_x_y(storm, timesteps = 1, lag = 24) :\n",
    "    '''\n",
    "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
    "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
    "    INPUT:  storm - hurricane object\n",
    "            timesteps - (default = 1) number of timesteps to calculate\n",
    "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
    "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
    "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
    "    '''\n",
    "    x = []\n",
    "    # Create testing data structure with a dictionary\n",
    "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
    "    y = dict([(time,[]) for time in times])\n",
    "    \n",
    "    # Sort by entry time\n",
    "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
    "    \n",
    "    for index in range(len(entries)) :\n",
    "        if index < timesteps : # Flag for insufficient initial time steps\n",
    "            continue\n",
    "\n",
    "        # If we're not including None values, check to see if there will be any\n",
    "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
    "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
    "            \n",
    "        # Calculate time steps and their features for independent values\n",
    "        sample = []\n",
    "        for step in range(timesteps) :\n",
    "            # Training sample\n",
    "            timestep = entries[index - step]\n",
    "            previous = entries[index - step - 1]\n",
    "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
    "        x.append(sample) # Add our constructed sample\n",
    "        \n",
    "        # Calculate time steps and their features for dependent values\n",
    "        for future in times :\n",
    "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
    "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
    "            \n",
    "            if timestep and previous: \n",
    "                y[future].append(feature_extraction(timestep, previous))\n",
    "            else :\n",
    "                y[future].append(None)\n",
    "    \n",
    "    # Return output, if there is no output, return None.\n",
    "    if len(x) is 0 :\n",
    "        return None\n",
    "    else:\n",
    "        return {'x': x, 'y': y}\n",
    "def shape(hurricanes, timesteps, remove_missing = True) :\n",
    "    '''\n",
    "    PURPOSE: Shape our data for input into machine learning models\n",
    "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
    "    INPUT:  hurricanes - dictionary of hurricane objects\n",
    "            timesteps - number of timesteps for the shape\n",
    "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
    "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    lag = 24 # lag time in hours\n",
    "    precision = np.float64 # defines the precision of our data type\n",
    "    times = [time * lag for time in range(1, (120 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
    "    count = 0\n",
    "    for hurricane in hurricanes.values() :\n",
    "        count += 1\n",
    "        result = storm_x_y(hurricane, timesteps, lag)\n",
    "        if result is None :\n",
    "            continue\n",
    "        # Extract only the values from the strom features using our specified precision\n",
    "        hurricane_x = np.array(\n",
    "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
    "            dtype = precision)\n",
    "        hurricane_y = np.array(\n",
    "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
    "            dtype = precision)\n",
    "        # Disregard if algorithm requires no missing values\n",
    "        if remove_missing :\n",
    "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
    "                continue\n",
    "        # Add to our results\n",
    "        x.extend(hurricane_x)\n",
    "        y.extend(hurricane_y)\n",
    "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
    "    print(\"\\nDone feature engineering hurricanes.\")\n",
    "    \n",
    "    return {'x': np.array(x), 'y': np.array(y)}\n",
    "def scaler(processed_data, hurricanes) :\n",
    "    '''\n",
    "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
    "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
    "    INPUT:  hurricanes - dictionary of hurricane objects\n",
    "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
    "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
    "            2) RobustScaler object fit with appropriate data\n",
    "    '''\n",
    "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
    "    # Create our scaler\n",
    "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
    "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
    "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(x)\n",
    "    \n",
    "    # Scale our data\n",
    "    for index in range(len(processed_data['x'])) :\n",
    "        # Scale our x\n",
    "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
    "        # Scale our y\n",
    "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
    "    print(\"Done scaling.\")\n",
    "    return processed_data, scaler\n",
    "# Finalize and scale procesed data into a dictionary\n",
    "preprocessed_data = shape(hurricanes, timesteps = 5)\n",
    "processed_data, scaler = scaler(preprocessed_data, hurricanes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Architecture<a id=\"ModelArchitecture\"></a>\n",
    "\n",
    "Following feature engineering, we are now ready to input our data into a machine learning algorithm. The scope of this project will attempt a deep learning approach to forecasting Atlantic tropical cyclones. We will experiment with nunermous different architectures but we will focus around a Recurrent Neural Network utilizing LSTM cells.\n",
    "\n",
    "Notes:\n",
    "- We will use 500 epochs for wind intensity because the validation loss is not decresing\n",
    "- We will use 1,000 epochs for latitute and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 5, 2048)           8486912   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 5, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 5, 1)              513       \n",
      "=================================================================\n",
      "Total params: 13,732,353\n",
      "Trainable params: 13,732,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3298 samples, validate on 825 samples\n",
      "Epoch 1/500\n",
      "3298/3298 [==============================] - 8s 2ms/step - loss: 0.7058 - val_loss: 0.6104\n",
      "Epoch 2/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.6021 - val_loss: 0.5843\n",
      "Epoch 3/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5731 - val_loss: 0.5577\n",
      "Epoch 4/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5435 - val_loss: 0.5327\n",
      "Epoch 5/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5220 - val_loss: 0.5132\n",
      "Epoch 6/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5117 - val_loss: 0.5200\n",
      "Epoch 7/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5213 - val_loss: 0.5176\n",
      "Epoch 8/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5144 - val_loss: 0.5116\n",
      "Epoch 9/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5051 - val_loss: 0.5088\n",
      "Epoch 10/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.5031 - val_loss: 0.5064\n",
      "Epoch 11/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4991 - val_loss: 0.5050\n",
      "Epoch 12/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4962 - val_loss: 0.5049\n",
      "Epoch 13/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4995 - val_loss: 0.5011\n",
      "Epoch 14/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4961 - val_loss: 0.4958\n",
      "Epoch 15/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4921 - val_loss: 0.4926\n",
      "Epoch 16/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4876 - val_loss: 0.4917\n",
      "Epoch 17/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4882 - val_loss: 0.4921\n",
      "Epoch 18/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4883 - val_loss: 0.4917\n",
      "Epoch 19/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4859 - val_loss: 0.4896\n",
      "Epoch 20/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4860 - val_loss: 0.4868\n",
      "Epoch 21/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4845 - val_loss: 0.4843\n",
      "Epoch 22/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4810 - val_loss: 0.4827\n",
      "Epoch 23/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4788 - val_loss: 0.4816\n",
      "Epoch 24/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4784 - val_loss: 0.4794\n",
      "Epoch 25/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4742 - val_loss: 0.4768\n",
      "Epoch 26/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4718 - val_loss: 0.4745\n",
      "Epoch 27/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4702 - val_loss: 0.4724\n",
      "Epoch 28/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4691 - val_loss: 0.4695\n",
      "Epoch 29/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4659 - val_loss: 0.4653\n",
      "Epoch 30/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4650 - val_loss: 0.4613\n",
      "Epoch 31/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4572 - val_loss: 0.4580\n",
      "Epoch 32/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4581 - val_loss: 0.4563\n",
      "Epoch 33/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4550 - val_loss: 0.4549\n",
      "Epoch 34/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4539 - val_loss: 0.4532\n",
      "Epoch 35/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4511 - val_loss: 0.4521\n",
      "Epoch 36/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4506 - val_loss: 0.4510\n",
      "Epoch 37/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4516 - val_loss: 0.4502\n",
      "Epoch 38/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4494 - val_loss: 0.4491\n",
      "Epoch 39/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4469 - val_loss: 0.4473\n",
      "Epoch 40/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4455 - val_loss: 0.4451\n",
      "Epoch 41/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4418 - val_loss: 0.4432\n",
      "Epoch 42/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4395 - val_loss: 0.4417\n",
      "Epoch 43/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4392 - val_loss: 0.4407\n",
      "Epoch 44/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4388 - val_loss: 0.4405\n",
      "Epoch 45/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4385 - val_loss: 0.4413\n",
      "Epoch 46/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4372 - val_loss: 0.4384\n",
      "Epoch 47/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4349 - val_loss: 0.4363\n",
      "Epoch 48/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4316 - val_loss: 0.4369\n",
      "Epoch 49/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4330 - val_loss: 0.4357\n",
      "Epoch 50/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.4300 - val_loss: 0.4348\n",
      "Epoch 51/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4316 - val_loss: 0.4350\n",
      "Epoch 52/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4301 - val_loss: 0.4341\n",
      "Epoch 53/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4275 - val_loss: 0.4314\n",
      "Epoch 54/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4272 - val_loss: 0.4307\n",
      "Epoch 55/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4252 - val_loss: 0.4303\n",
      "Epoch 56/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.4261 - val_loss: 0.4288\n",
      "Epoch 57/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4249 - val_loss: 0.4281\n",
      "Epoch 58/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4217 - val_loss: 0.4292\n",
      "Epoch 59/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4242 - val_loss: 0.4270\n",
      "Epoch 60/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4239 - val_loss: 0.4273\n",
      "Epoch 61/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4252 - val_loss: 0.4293\n",
      "Epoch 62/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4228 - val_loss: 0.4285\n",
      "Epoch 63/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4227 - val_loss: 0.4229\n",
      "Epoch 64/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4181 - val_loss: 0.4241\n",
      "Epoch 65/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4184 - val_loss: 0.4232\n",
      "Epoch 66/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4195 - val_loss: 0.4233\n",
      "Epoch 67/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4157 - val_loss: 0.4202\n",
      "Epoch 68/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4149 - val_loss: 0.4193\n",
      "Epoch 69/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4116 - val_loss: 0.4209\n",
      "Epoch 70/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4134 - val_loss: 0.4199\n",
      "Epoch 71/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4129 - val_loss: 0.4185\n",
      "Epoch 72/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4120 - val_loss: 0.4166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4087 - val_loss: 0.4183\n",
      "Epoch 74/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4102 - val_loss: 0.4155\n",
      "Epoch 75/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.4072 - val_loss: 0.4154\n",
      "Epoch 76/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4068 - val_loss: 0.4168\n",
      "Epoch 77/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4070 - val_loss: 0.4151\n",
      "Epoch 78/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4051 - val_loss: 0.4109\n",
      "Epoch 79/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4038 - val_loss: 0.4124\n",
      "Epoch 80/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4040 - val_loss: 0.4100\n",
      "Epoch 81/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4021 - val_loss: 0.4098\n",
      "Epoch 82/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4033 - val_loss: 0.4113\n",
      "Epoch 83/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4044 - val_loss: 0.4129\n",
      "Epoch 84/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4066 - val_loss: 0.4099\n",
      "Epoch 85/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4023 - val_loss: 0.4075\n",
      "Epoch 86/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3969 - val_loss: 0.4057\n",
      "Epoch 87/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3961 - val_loss: 0.4043\n",
      "Epoch 88/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3975 - val_loss: 0.4053\n",
      "Epoch 89/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3980 - val_loss: 0.4048\n",
      "Epoch 90/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3946 - val_loss: 0.4012\n",
      "Epoch 91/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3927 - val_loss: 0.4021\n",
      "Epoch 92/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3946 - val_loss: 0.4031\n",
      "Epoch 93/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3946 - val_loss: 0.4003\n",
      "Epoch 94/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3889 - val_loss: 0.3996\n",
      "Epoch 95/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3881 - val_loss: 0.3993\n",
      "Epoch 96/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3882 - val_loss: 0.4011\n",
      "Epoch 97/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3914 - val_loss: 0.3955\n",
      "Epoch 98/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3847 - val_loss: 0.3985\n",
      "Epoch 99/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3880 - val_loss: 0.3984\n",
      "Epoch 100/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3864 - val_loss: 0.3960\n",
      "Epoch 101/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3821 - val_loss: 0.3914\n",
      "Epoch 102/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3834 - val_loss: 0.3889\n",
      "Epoch 103/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3789 - val_loss: 0.4002\n",
      "Epoch 104/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3835 - val_loss: 0.3891\n",
      "Epoch 105/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3780 - val_loss: 0.3893\n",
      "Epoch 106/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3772 - val_loss: 0.3885\n",
      "Epoch 107/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3760 - val_loss: 0.3937\n",
      "Epoch 108/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3767 - val_loss: 0.3843\n",
      "Epoch 109/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3697 - val_loss: 0.3808\n",
      "Epoch 110/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3710 - val_loss: 0.3800\n",
      "Epoch 111/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3681 - val_loss: 0.3841\n",
      "Epoch 112/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.3673 - val_loss: 0.3801\n",
      "Epoch 113/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3673 - val_loss: 0.3793\n",
      "Epoch 114/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3642 - val_loss: 0.3779\n",
      "Epoch 115/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3617 - val_loss: 0.3782\n",
      "Epoch 116/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3617 - val_loss: 0.3739\n",
      "Epoch 117/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3592 - val_loss: 0.3732\n",
      "Epoch 118/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3566 - val_loss: 0.3732\n",
      "Epoch 119/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3575 - val_loss: 0.3805\n",
      "Epoch 120/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3627 - val_loss: 0.3892\n",
      "Epoch 121/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3809 - val_loss: 0.3799\n",
      "Epoch 122/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3652 - val_loss: 0.3713\n",
      "Epoch 123/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3570 - val_loss: 0.3685\n",
      "Epoch 124/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3550 - val_loss: 0.3699\n",
      "Epoch 125/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3562 - val_loss: 0.3685\n",
      "Epoch 126/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3525 - val_loss: 0.3650\n",
      "Epoch 127/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3478 - val_loss: 0.3694\n",
      "Epoch 128/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3506 - val_loss: 0.3619\n",
      "Epoch 129/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3420 - val_loss: 0.3633\n",
      "Epoch 130/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3428 - val_loss: 0.3580\n",
      "Epoch 131/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3420 - val_loss: 0.3585\n",
      "Epoch 132/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3381 - val_loss: 0.3549\n",
      "Epoch 133/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3369 - val_loss: 0.3542\n",
      "Epoch 134/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.3397 - val_loss: 0.3494\n",
      "Epoch 135/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3344 - val_loss: 0.3540\n",
      "Epoch 136/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3343 - val_loss: 0.3467\n",
      "Epoch 137/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3287 - val_loss: 0.3439\n",
      "Epoch 138/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3298 - val_loss: 0.3464\n",
      "Epoch 139/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3267 - val_loss: 0.3439\n",
      "Epoch 140/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3245 - val_loss: 0.3413\n",
      "Epoch 141/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3208 - val_loss: 0.3392\n",
      "Epoch 142/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3209 - val_loss: 0.3361\n",
      "Epoch 143/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3151 - val_loss: 0.3350\n",
      "Epoch 144/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3170 - val_loss: 0.3291\n",
      "Epoch 145/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3106 - val_loss: 0.3275\n",
      "Epoch 146/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3129 - val_loss: 0.3296\n",
      "Epoch 147/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3117 - val_loss: 0.3281\n",
      "Epoch 148/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.3088 - val_loss: 0.3261\n",
      "Epoch 149/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3131 - val_loss: 0.3239\n",
      "Epoch 150/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.3095 - val_loss: 0.3300\n",
      "Epoch 151/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3112 - val_loss: 0.3213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3100 - val_loss: 0.3203\n",
      "Epoch 153/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3089 - val_loss: 0.3109\n",
      "Epoch 154/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2984 - val_loss: 0.3139\n",
      "Epoch 155/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3002 - val_loss: 0.3079\n",
      "Epoch 156/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2981 - val_loss: 0.3062\n",
      "Epoch 157/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2941 - val_loss: 0.3069\n",
      "Epoch 158/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2896 - val_loss: 0.3066\n",
      "Epoch 159/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2880 - val_loss: 0.3018\n",
      "Epoch 160/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2878 - val_loss: 0.3008\n",
      "Epoch 161/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2849 - val_loss: 0.3089\n",
      "Epoch 162/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2861 - val_loss: 0.2980\n",
      "Epoch 163/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2854 - val_loss: 0.2911\n",
      "Epoch 164/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2785 - val_loss: 0.2994\n",
      "Epoch 165/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2822 - val_loss: 0.2934\n",
      "Epoch 166/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2790 - val_loss: 0.2880\n",
      "Epoch 167/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2766 - val_loss: 0.2896\n",
      "Epoch 168/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2740 - val_loss: 0.2892\n",
      "Epoch 169/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2781 - val_loss: 0.2825\n",
      "Epoch 170/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2688 - val_loss: 0.2822\n",
      "Epoch 171/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2643 - val_loss: 0.2817\n",
      "Epoch 172/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2665 - val_loss: 0.2822\n",
      "Epoch 173/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2692 - val_loss: 0.2831\n",
      "Epoch 174/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2690 - val_loss: 0.2779\n",
      "Epoch 175/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2632 - val_loss: 0.2717\n",
      "Epoch 176/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2651 - val_loss: 0.2708\n",
      "Epoch 177/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2557 - val_loss: 0.2681\n",
      "Epoch 178/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2545 - val_loss: 0.2611\n",
      "Epoch 179/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2518 - val_loss: 0.2614\n",
      "Epoch 180/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2518 - val_loss: 0.2624\n",
      "Epoch 181/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2525 - val_loss: 0.2607\n",
      "Epoch 182/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2462 - val_loss: 0.2573\n",
      "Epoch 183/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2470 - val_loss: 0.2641\n",
      "Epoch 184/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2468 - val_loss: 0.2572\n",
      "Epoch 185/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2467 - val_loss: 0.2569\n",
      "Epoch 186/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2442 - val_loss: 0.2538\n",
      "Epoch 187/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2397 - val_loss: 0.2468\n",
      "Epoch 188/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2365 - val_loss: 0.2494\n",
      "Epoch 189/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2379 - val_loss: 0.2524\n",
      "Epoch 190/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2365 - val_loss: 0.2443\n",
      "Epoch 191/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2331 - val_loss: 0.2398\n",
      "Epoch 192/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2272 - val_loss: 0.2421\n",
      "Epoch 193/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2283 - val_loss: 0.2397\n",
      "Epoch 194/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2252 - val_loss: 0.2387\n",
      "Epoch 195/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2253 - val_loss: 0.2420\n",
      "Epoch 196/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2259 - val_loss: 0.2379\n",
      "Epoch 197/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2266 - val_loss: 0.2362\n",
      "Epoch 198/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2231 - val_loss: 0.2356\n",
      "Epoch 199/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2194 - val_loss: 0.2310\n",
      "Epoch 200/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2212 - val_loss: 0.2348\n",
      "Epoch 201/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2187 - val_loss: 0.2327\n",
      "Epoch 202/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2222 - val_loss: 0.2422\n",
      "Epoch 203/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2283 - val_loss: 0.2499\n",
      "Epoch 204/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2394 - val_loss: 0.2485\n",
      "Epoch 205/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2276 - val_loss: 0.2341\n",
      "Epoch 206/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2218 - val_loss: 0.2267\n",
      "Epoch 207/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2140 - val_loss: 0.2330\n",
      "Epoch 208/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2172 - val_loss: 0.2323\n",
      "Epoch 209/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2227 - val_loss: 0.2252\n",
      "Epoch 210/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2122 - val_loss: 0.2287\n",
      "Epoch 211/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2117 - val_loss: 0.2243\n",
      "Epoch 212/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2121 - val_loss: 0.2258\n",
      "Epoch 213/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2140 - val_loss: 0.2173\n",
      "Epoch 214/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2011 - val_loss: 0.2229\n",
      "Epoch 215/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2064 - val_loss: 0.2205\n",
      "Epoch 216/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2044 - val_loss: 0.2150\n",
      "Epoch 217/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2017 - val_loss: 0.2150\n",
      "Epoch 218/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1988 - val_loss: 0.2134\n",
      "Epoch 219/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1978 - val_loss: 0.2121\n",
      "Epoch 220/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1981 - val_loss: 0.2135\n",
      "Epoch 221/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1947 - val_loss: 0.2104\n",
      "Epoch 222/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1952 - val_loss: 0.2080\n",
      "Epoch 223/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1925 - val_loss: 0.2114\n",
      "Epoch 224/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1949 - val_loss: 0.2076\n",
      "Epoch 225/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1944 - val_loss: 0.2099\n",
      "Epoch 226/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1926 - val_loss: 0.2047\n",
      "Epoch 227/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1884 - val_loss: 0.2029\n",
      "Epoch 228/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1898 - val_loss: 0.2049\n",
      "Epoch 229/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1857 - val_loss: 0.2034\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1873 - val_loss: 0.2051\n",
      "Epoch 231/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1904 - val_loss: 0.2019\n",
      "Epoch 232/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1874 - val_loss: 0.2024\n",
      "Epoch 233/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1842 - val_loss: 0.2003\n",
      "Epoch 234/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1832 - val_loss: 0.1974\n",
      "Epoch 235/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1829 - val_loss: 0.1965\n",
      "Epoch 236/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1833 - val_loss: 0.1999\n",
      "Epoch 237/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1805 - val_loss: 0.1989\n",
      "Epoch 238/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1809 - val_loss: 0.1961\n",
      "Epoch 239/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1799 - val_loss: 0.1967\n",
      "Epoch 240/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1779 - val_loss: 0.1932\n",
      "Epoch 241/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1778 - val_loss: 0.1965\n",
      "Epoch 242/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1813 - val_loss: 0.1930\n",
      "Epoch 243/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1758 - val_loss: 0.1921\n",
      "Epoch 244/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1749 - val_loss: 0.1888\n",
      "Epoch 245/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1731 - val_loss: 0.1905\n",
      "Epoch 246/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1765 - val_loss: 0.1898\n",
      "Epoch 247/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1724 - val_loss: 0.1872\n",
      "Epoch 248/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1723 - val_loss: 0.1890\n",
      "Epoch 249/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1691 - val_loss: 0.1853\n",
      "Epoch 250/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1719 - val_loss: 0.1863\n",
      "Epoch 251/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1663 - val_loss: 0.1886\n",
      "Epoch 252/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1673 - val_loss: 0.1871\n",
      "Epoch 253/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1654 - val_loss: 0.1811\n",
      "Epoch 254/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1664 - val_loss: 0.1845\n",
      "Epoch 255/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1662 - val_loss: 0.1842\n",
      "Epoch 256/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1606 - val_loss: 0.1841\n",
      "Epoch 257/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1627 - val_loss: 0.1824\n",
      "Epoch 258/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1631 - val_loss: 0.1809\n",
      "Epoch 259/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1606 - val_loss: 0.1785\n",
      "Epoch 260/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1639 - val_loss: 0.1815\n",
      "Epoch 261/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1590 - val_loss: 0.1790\n",
      "Epoch 262/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1579 - val_loss: 0.1777\n",
      "Epoch 263/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1626 - val_loss: 0.1844\n",
      "Epoch 264/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1620 - val_loss: 0.1824\n",
      "Epoch 265/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1664 - val_loss: 0.1855\n",
      "Epoch 266/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1656 - val_loss: 0.1793\n",
      "Epoch 267/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1586 - val_loss: 0.1776\n",
      "Epoch 268/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1555 - val_loss: 0.1761\n",
      "Epoch 269/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1542 - val_loss: 0.1784\n",
      "Epoch 270/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1576 - val_loss: 0.1733\n",
      "Epoch 271/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1562 - val_loss: 0.1717\n",
      "Epoch 272/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1523 - val_loss: 0.1775\n",
      "Epoch 273/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1565 - val_loss: 0.1727\n",
      "Epoch 274/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1563 - val_loss: 0.1823\n",
      "Epoch 275/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1588 - val_loss: 0.1749\n",
      "Epoch 276/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1603 - val_loss: 0.1761\n",
      "Epoch 277/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1550 - val_loss: 0.1714\n",
      "Epoch 278/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1524 - val_loss: 0.1709\n",
      "Epoch 279/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1531 - val_loss: 0.1729\n",
      "Epoch 280/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1522 - val_loss: 0.1730\n",
      "Epoch 281/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1538 - val_loss: 0.1777\n",
      "Epoch 282/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1548 - val_loss: 0.1696\n",
      "Epoch 283/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1521 - val_loss: 0.1680\n",
      "Epoch 284/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1449 - val_loss: 0.1741\n",
      "Epoch 285/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1514 - val_loss: 0.1698\n",
      "Epoch 286/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1522 - val_loss: 0.1740\n",
      "Epoch 287/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1491 - val_loss: 0.1711\n",
      "Epoch 288/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1529 - val_loss: 0.1644\n",
      "Epoch 289/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1461 - val_loss: 0.1637\n",
      "Epoch 290/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1440 - val_loss: 0.1658\n",
      "Epoch 291/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1458 - val_loss: 0.1705\n",
      "Epoch 292/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1457 - val_loss: 0.1646\n",
      "Epoch 293/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1435 - val_loss: 0.1660\n",
      "Epoch 294/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1439 - val_loss: 0.1660\n",
      "Epoch 295/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1399 - val_loss: 0.1630\n",
      "Epoch 296/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1426 - val_loss: 0.1659\n",
      "Epoch 297/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1426 - val_loss: 0.1656\n",
      "Epoch 298/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1421 - val_loss: 0.1659\n",
      "Epoch 299/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1456 - val_loss: 0.1608\n",
      "Epoch 300/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1412 - val_loss: 0.1669\n",
      "Epoch 301/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1423 - val_loss: 0.1641\n",
      "Epoch 302/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1423 - val_loss: 0.1595\n",
      "Epoch 303/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1389 - val_loss: 0.1637\n",
      "Epoch 304/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1379 - val_loss: 0.1613\n",
      "Epoch 305/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1411 - val_loss: 0.1604\n",
      "Epoch 306/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1333 - val_loss: 0.1616\n",
      "Epoch 307/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1339 - val_loss: 0.1597\n",
      "Epoch 308/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1340 - val_loss: 0.1612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1362 - val_loss: 0.1589\n",
      "Epoch 310/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1392 - val_loss: 0.1624\n",
      "Epoch 311/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1379 - val_loss: 0.1590\n",
      "Epoch 312/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1397 - val_loss: 0.1598\n",
      "Epoch 313/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1346 - val_loss: 0.1577\n",
      "Epoch 314/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1334 - val_loss: 0.1591\n",
      "Epoch 315/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1332 - val_loss: 0.1596\n",
      "Epoch 316/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1364 - val_loss: 0.1571\n",
      "Epoch 317/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1321 - val_loss: 0.1543\n",
      "Epoch 318/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1356 - val_loss: 0.1569\n",
      "Epoch 319/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1342 - val_loss: 0.1588\n",
      "Epoch 320/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1311 - val_loss: 0.1551\n",
      "Epoch 321/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1301 - val_loss: 0.1530\n",
      "Epoch 322/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1304 - val_loss: 0.1581\n",
      "Epoch 323/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1328 - val_loss: 0.1556\n",
      "Epoch 324/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1533\n",
      "Epoch 325/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1279 - val_loss: 0.1568\n",
      "Epoch 326/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1283 - val_loss: 0.1538\n",
      "Epoch 327/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1285 - val_loss: 0.1590\n",
      "Epoch 328/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1323 - val_loss: 0.1539\n",
      "Epoch 329/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1288 - val_loss: 0.1535\n",
      "Epoch 330/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1257 - val_loss: 0.1540\n",
      "Epoch 331/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1262 - val_loss: 0.1541\n",
      "Epoch 332/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1596\n",
      "Epoch 333/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1324 - val_loss: 0.1536\n",
      "Epoch 334/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1334 - val_loss: 0.1548\n",
      "Epoch 335/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1243 - val_loss: 0.1499\n",
      "Epoch 336/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1224 - val_loss: 0.1493\n",
      "Epoch 337/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1271 - val_loss: 0.1524\n",
      "Epoch 338/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1294 - val_loss: 0.1520\n",
      "Epoch 339/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1281 - val_loss: 0.1529\n",
      "Epoch 340/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1231 - val_loss: 0.1487\n",
      "Epoch 341/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1251 - val_loss: 0.1496\n",
      "Epoch 342/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1219 - val_loss: 0.1516\n",
      "Epoch 343/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1213 - val_loss: 0.1496\n",
      "Epoch 344/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1274 - val_loss: 0.1553\n",
      "Epoch 345/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1260 - val_loss: 0.1500\n",
      "Epoch 346/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1259 - val_loss: 0.1478\n",
      "Epoch 347/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1216 - val_loss: 0.1501\n",
      "Epoch 348/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1210 - val_loss: 0.1477\n",
      "Epoch 349/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1229 - val_loss: 0.1539\n",
      "Epoch 350/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1216 - val_loss: 0.1509\n",
      "Epoch 351/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1243 - val_loss: 0.1467\n",
      "Epoch 352/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1211 - val_loss: 0.1449\n",
      "Epoch 353/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1193 - val_loss: 0.1472\n",
      "Epoch 354/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1173 - val_loss: 0.1517\n",
      "Epoch 355/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1210 - val_loss: 0.1468\n",
      "Epoch 356/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1218 - val_loss: 0.1489\n",
      "Epoch 357/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1210 - val_loss: 0.1460\n",
      "Epoch 358/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1172 - val_loss: 0.1448\n",
      "Epoch 359/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1182 - val_loss: 0.1492\n",
      "Epoch 360/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1187 - val_loss: 0.1461\n",
      "Epoch 361/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1210 - val_loss: 0.1497\n",
      "Epoch 362/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1223 - val_loss: 0.1447\n",
      "Epoch 363/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1192 - val_loss: 0.1479\n",
      "Epoch 364/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1172 - val_loss: 0.1445\n",
      "Epoch 365/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1180 - val_loss: 0.1417\n",
      "Epoch 366/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1130 - val_loss: 0.1478\n",
      "Epoch 367/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1168 - val_loss: 0.1450\n",
      "Epoch 368/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1138 - val_loss: 0.1428\n",
      "Epoch 369/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1141 - val_loss: 0.1466\n",
      "Epoch 370/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1161 - val_loss: 0.1463\n",
      "Epoch 371/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1156 - val_loss: 0.1419\n",
      "Epoch 372/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1135 - val_loss: 0.1463\n",
      "Epoch 373/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1178 - val_loss: 0.1456\n",
      "Epoch 374/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1157 - val_loss: 0.1411\n",
      "Epoch 375/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1132 - val_loss: 0.1480\n",
      "Epoch 376/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1165 - val_loss: 0.1460\n",
      "Epoch 377/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1157 - val_loss: 0.1431\n",
      "Epoch 378/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1154 - val_loss: 0.1427\n",
      "Epoch 379/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1123 - val_loss: 0.1454\n",
      "Epoch 380/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1154 - val_loss: 0.1413\n",
      "Epoch 381/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1135 - val_loss: 0.1418\n",
      "Epoch 382/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1108 - val_loss: 0.1444\n",
      "Epoch 383/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1145 - val_loss: 0.1427\n",
      "Epoch 384/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1145 - val_loss: 0.1411\n",
      "Epoch 385/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1107 - val_loss: 0.1427\n",
      "Epoch 386/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1115 - val_loss: 0.1415\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1138 - val_loss: 0.1460\n",
      "Epoch 388/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1152 - val_loss: 0.1407\n",
      "Epoch 389/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1099 - val_loss: 0.1414\n",
      "Epoch 390/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1086 - val_loss: 0.1426\n",
      "Epoch 391/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1083 - val_loss: 0.1423\n",
      "Epoch 392/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1077 - val_loss: 0.1422\n",
      "Epoch 393/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1113 - val_loss: 0.1395\n",
      "Epoch 394/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1092 - val_loss: 0.1441\n",
      "Epoch 395/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1100 - val_loss: 0.1389\n",
      "Epoch 396/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1117 - val_loss: 0.1391\n",
      "Epoch 397/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1114 - val_loss: 0.1417\n",
      "Epoch 398/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1082 - val_loss: 0.1407\n",
      "Epoch 399/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1079 - val_loss: 0.1395\n",
      "Epoch 400/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1024 - val_loss: 0.1404\n",
      "Epoch 401/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1072 - val_loss: 0.1376\n",
      "Epoch 402/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1073 - val_loss: 0.1373\n",
      "Epoch 403/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1056 - val_loss: 0.1398\n",
      "Epoch 404/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1036 - val_loss: 0.1406\n",
      "Epoch 405/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1097 - val_loss: 0.1391\n",
      "Epoch 406/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1072 - val_loss: 0.1386\n",
      "Epoch 407/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1123 - val_loss: 0.1400\n",
      "Epoch 408/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1044 - val_loss: 0.1383\n",
      "Epoch 409/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1036 - val_loss: 0.1370\n",
      "Epoch 410/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1033 - val_loss: 0.1383\n",
      "Epoch 411/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1065 - val_loss: 0.1385\n",
      "Epoch 412/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1061 - val_loss: 0.1408\n",
      "Epoch 413/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1050 - val_loss: 0.1375\n",
      "Epoch 414/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1057 - val_loss: 0.1389\n",
      "Epoch 415/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0999 - val_loss: 0.1372\n",
      "Epoch 416/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1047 - val_loss: 0.1374\n",
      "Epoch 417/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1021 - val_loss: 0.1378\n",
      "Epoch 418/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0998 - val_loss: 0.1370\n",
      "Epoch 419/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1017 - val_loss: 0.1398\n",
      "Epoch 420/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1041 - val_loss: 0.1380\n",
      "Epoch 421/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1046 - val_loss: 0.1388\n",
      "Epoch 422/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1027 - val_loss: 0.1356\n",
      "Epoch 423/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0981 - val_loss: 0.1376\n",
      "Epoch 424/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1002 - val_loss: 0.1400\n",
      "Epoch 425/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0999 - val_loss: 0.1378\n",
      "Epoch 426/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0996 - val_loss: 0.1387\n",
      "Epoch 427/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1021 - val_loss: 0.1367\n",
      "Epoch 428/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1013 - val_loss: 0.1400\n",
      "Epoch 429/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1023 - val_loss: 0.1358\n",
      "Epoch 430/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1019 - val_loss: 0.1346\n",
      "Epoch 431/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0960 - val_loss: 0.1398\n",
      "Epoch 432/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1010 - val_loss: 0.1382\n",
      "Epoch 433/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1048 - val_loss: 0.1394\n",
      "Epoch 434/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1046 - val_loss: 0.1371\n",
      "Epoch 435/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0998 - val_loss: 0.1362\n",
      "Epoch 436/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1001 - val_loss: 0.1364\n",
      "Epoch 437/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1004 - val_loss: 0.1384\n",
      "Epoch 438/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1034 - val_loss: 0.1402\n",
      "Epoch 439/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1008 - val_loss: 0.1352\n",
      "Epoch 440/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0971 - val_loss: 0.1359\n",
      "Epoch 441/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0954 - val_loss: 0.1361\n",
      "Epoch 442/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0998 - val_loss: 0.1346\n",
      "Epoch 443/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0984 - val_loss: 0.1376\n",
      "Epoch 444/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0982 - val_loss: 0.1366\n",
      "Epoch 445/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0988 - val_loss: 0.1383\n",
      "Epoch 446/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0988 - val_loss: 0.1350\n",
      "Epoch 447/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0969 - val_loss: 0.1335\n",
      "Epoch 448/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0958 - val_loss: 0.1357\n",
      "Epoch 449/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0969 - val_loss: 0.1350\n",
      "Epoch 450/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0980 - val_loss: 0.1337\n",
      "Epoch 451/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0963 - val_loss: 0.1357\n",
      "Epoch 452/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0982 - val_loss: 0.1356\n",
      "Epoch 453/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0983 - val_loss: 0.1331\n",
      "Epoch 454/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0934 - val_loss: 0.1333\n",
      "Epoch 455/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0948 - val_loss: 0.1331\n",
      "Epoch 456/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0923 - val_loss: 0.1325\n",
      "Epoch 457/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0955 - val_loss: 0.1342\n",
      "Epoch 458/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0943 - val_loss: 0.1325\n",
      "Epoch 459/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0960 - val_loss: 0.1334\n",
      "Epoch 460/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0971 - val_loss: 0.1334\n",
      "Epoch 461/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0943 - val_loss: 0.1321\n",
      "Epoch 462/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0906 - val_loss: 0.1336\n",
      "Epoch 463/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0962 - val_loss: 0.1325\n",
      "Epoch 464/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0964 - val_loss: 0.1343\n",
      "Epoch 465/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0945 - val_loss: 0.1315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0947 - val_loss: 0.1325\n",
      "Epoch 467/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0932 - val_loss: 0.1336\n",
      "Epoch 468/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0927 - val_loss: 0.1318\n",
      "Epoch 469/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0926 - val_loss: 0.1333\n",
      "Epoch 470/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0957 - val_loss: 0.1324\n",
      "Epoch 471/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0912 - val_loss: 0.1332\n",
      "Epoch 472/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0940 - val_loss: 0.1337\n",
      "Epoch 473/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0958 - val_loss: 0.1315\n",
      "Epoch 474/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0917 - val_loss: 0.1351\n",
      "Epoch 475/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0941 - val_loss: 0.1356\n",
      "Epoch 476/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1013 - val_loss: 0.1365\n",
      "Epoch 477/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0984 - val_loss: 0.1298\n",
      "Epoch 478/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0927 - val_loss: 0.1308\n",
      "Epoch 479/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0895 - val_loss: 0.1344\n",
      "Epoch 480/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0942 - val_loss: 0.1335\n",
      "Epoch 481/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0945 - val_loss: 0.1337\n",
      "Epoch 482/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0921 - val_loss: 0.1319\n",
      "Epoch 483/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0892 - val_loss: 0.1304\n",
      "Epoch 484/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0908 - val_loss: 0.1322\n",
      "Epoch 485/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0905 - val_loss: 0.1332\n",
      "Epoch 486/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0933 - val_loss: 0.1326\n",
      "Epoch 487/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0920 - val_loss: 0.1294\n",
      "Epoch 488/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0942 - val_loss: 0.1312\n",
      "Epoch 489/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0884 - val_loss: 0.1354\n",
      "Epoch 490/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0943 - val_loss: 0.1316\n",
      "Epoch 491/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0967 - val_loss: 0.1320\n",
      "Epoch 492/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0932 - val_loss: 0.1329\n",
      "Epoch 493/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0927 - val_loss: 0.1347\n",
      "Epoch 494/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0943 - val_loss: 0.1357\n",
      "Epoch 495/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0933 - val_loss: 0.1340\n",
      "Epoch 496/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0971 - val_loss: 0.1298\n",
      "Epoch 497/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0876 - val_loss: 0.1327\n",
      "Epoch 498/500\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0883 - val_loss: 0.1333\n",
      "Epoch 499/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0926 - val_loss: 0.1343\n",
      "Epoch 500/500\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0952 - val_loss: 0.1299\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 5, 2048)           8486912   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 5, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 5, 1)              513       \n",
      "=================================================================\n",
      "Total params: 13,732,353\n",
      "Trainable params: 13,732,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3298 samples, validate on 825 samples\n",
      "Epoch 1/1000\n",
      "3298/3298 [==============================] - 7s 2ms/step - loss: 0.7716 - val_loss: 0.5541\n",
      "Epoch 2/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.5652 - val_loss: 0.5244\n",
      "Epoch 3/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.5213 - val_loss: 0.4314\n",
      "Epoch 4/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4378 - val_loss: 0.4063\n",
      "Epoch 5/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4233 - val_loss: 0.3750\n",
      "Epoch 6/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3869 - val_loss: 0.3378\n",
      "Epoch 7/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3490 - val_loss: 0.3398\n",
      "Epoch 8/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3564 - val_loss: 0.3332\n",
      "Epoch 9/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3507 - val_loss: 0.3157\n",
      "Epoch 10/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3336 - val_loss: 0.3178\n",
      "Epoch 11/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3374 - val_loss: 0.3126\n",
      "Epoch 12/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3271 - val_loss: 0.3017\n",
      "Epoch 13/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3115 - val_loss: 0.3032\n",
      "Epoch 14/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3106 - val_loss: 0.3016\n",
      "Epoch 15/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3073 - val_loss: 0.2893\n",
      "Epoch 16/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2953 - val_loss: 0.2823\n",
      "Epoch 17/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2929 - val_loss: 0.2834\n",
      "Epoch 18/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2974 - val_loss: 0.2825\n",
      "Epoch 19/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2956 - val_loss: 0.2787\n",
      "Epoch 20/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2903 - val_loss: 0.2770\n",
      "Epoch 21/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2901 - val_loss: 0.2786\n",
      "Epoch 22/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2874 - val_loss: 0.2801\n",
      "Epoch 23/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2874 - val_loss: 0.2787\n",
      "Epoch 24/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2849 - val_loss: 0.2751\n",
      "Epoch 25/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2816 - val_loss: 0.2713\n",
      "Epoch 26/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2788 - val_loss: 0.2671\n",
      "Epoch 27/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2754 - val_loss: 0.2645\n",
      "Epoch 28/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2744 - val_loss: 0.2642\n",
      "Epoch 29/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2741 - val_loss: 0.2633\n",
      "Epoch 30/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2754 - val_loss: 0.2613\n",
      "Epoch 31/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2738 - val_loss: 0.2607\n",
      "Epoch 32/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2709 - val_loss: 0.2606\n",
      "Epoch 33/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2709 - val_loss: 0.2592\n",
      "Epoch 34/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2718 - val_loss: 0.2576\n",
      "Epoch 35/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2672 - val_loss: 0.2568\n",
      "Epoch 36/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2690 - val_loss: 0.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2655 - val_loss: 0.2540\n",
      "Epoch 38/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2635 - val_loss: 0.2534\n",
      "Epoch 39/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2632 - val_loss: 0.2526\n",
      "Epoch 40/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2640 - val_loss: 0.2532\n",
      "Epoch 41/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2637 - val_loss: 0.2536\n",
      "Epoch 42/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2626 - val_loss: 0.2521\n",
      "Epoch 43/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2626 - val_loss: 0.2504\n",
      "Epoch 44/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2613 - val_loss: 0.2490\n",
      "Epoch 45/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2599 - val_loss: 0.2488\n",
      "Epoch 46/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2597 - val_loss: 0.2488\n",
      "Epoch 47/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2612 - val_loss: 0.2482\n",
      "Epoch 48/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2588 - val_loss: 0.2479\n",
      "Epoch 49/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2586 - val_loss: 0.2479\n",
      "Epoch 50/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2585 - val_loss: 0.2475\n",
      "Epoch 51/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2605 - val_loss: 0.2464\n",
      "Epoch 52/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2563 - val_loss: 0.2455\n",
      "Epoch 53/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2553 - val_loss: 0.2451\n",
      "Epoch 54/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2557 - val_loss: 0.2454\n",
      "Epoch 55/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2569 - val_loss: 0.2455\n",
      "Epoch 56/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2571 - val_loss: 0.2456\n",
      "Epoch 57/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2549 - val_loss: 0.2459\n",
      "Epoch 58/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2529 - val_loss: 0.2452\n",
      "Epoch 59/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2525 - val_loss: 0.2439\n",
      "Epoch 60/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2506 - val_loss: 0.2432\n",
      "Epoch 61/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2547 - val_loss: 0.2432\n",
      "Epoch 62/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2530 - val_loss: 0.2434\n",
      "Epoch 63/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2517 - val_loss: 0.2439\n",
      "Epoch 64/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2538 - val_loss: 0.2437\n",
      "Epoch 65/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2511 - val_loss: 0.2434\n",
      "Epoch 66/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2517 - val_loss: 0.2432\n",
      "Epoch 67/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2500 - val_loss: 0.2424\n",
      "Epoch 68/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2520 - val_loss: 0.2425\n",
      "Epoch 69/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2532 - val_loss: 0.2419\n",
      "Epoch 70/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2506 - val_loss: 0.2419\n",
      "Epoch 71/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2513 - val_loss: 0.2412\n",
      "Epoch 72/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2498 - val_loss: 0.2414\n",
      "Epoch 73/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2496 - val_loss: 0.2411\n",
      "Epoch 74/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2497 - val_loss: 0.2419\n",
      "Epoch 75/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2489 - val_loss: 0.2414\n",
      "Epoch 76/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2484 - val_loss: 0.2407\n",
      "Epoch 77/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2499 - val_loss: 0.2409\n",
      "Epoch 78/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2477 - val_loss: 0.2409\n",
      "Epoch 79/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2476 - val_loss: 0.2415\n",
      "Epoch 80/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2464 - val_loss: 0.2398\n",
      "Epoch 81/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2466 - val_loss: 0.2395\n",
      "Epoch 82/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2452 - val_loss: 0.2411\n",
      "Epoch 83/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2469 - val_loss: 0.2401\n",
      "Epoch 84/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2440 - val_loss: 0.2389\n",
      "Epoch 85/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2478 - val_loss: 0.2386\n",
      "Epoch 86/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2439 - val_loss: 0.2397\n",
      "Epoch 87/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2447 - val_loss: 0.2382\n",
      "Epoch 88/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2448 - val_loss: 0.2370\n",
      "Epoch 89/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2425 - val_loss: 0.2378\n",
      "Epoch 90/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2415 - val_loss: 0.2390\n",
      "Epoch 91/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2451 - val_loss: 0.2373\n",
      "Epoch 92/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2415 - val_loss: 0.2362\n",
      "Epoch 93/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2398 - val_loss: 0.2384\n",
      "Epoch 94/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2417 - val_loss: 0.2369\n",
      "Epoch 95/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2402 - val_loss: 0.2377\n",
      "Epoch 96/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2437 - val_loss: 0.2381\n",
      "Epoch 97/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2432 - val_loss: 0.2413\n",
      "Epoch 98/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2427 - val_loss: 0.2381\n",
      "Epoch 99/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2415 - val_loss: 0.2347\n",
      "Epoch 100/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2396 - val_loss: 0.2360\n",
      "Epoch 101/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2367 - val_loss: 0.2365\n",
      "Epoch 102/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2387 - val_loss: 0.2353\n",
      "Epoch 103/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2363 - val_loss: 0.2356\n",
      "Epoch 104/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2388 - val_loss: 0.2340\n",
      "Epoch 105/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2365 - val_loss: 0.2341\n",
      "Epoch 106/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2353 - val_loss: 0.2333\n",
      "Epoch 107/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2370 - val_loss: 0.2322\n",
      "Epoch 108/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2342 - val_loss: 0.2328\n",
      "Epoch 109/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2334 - val_loss: 0.2324\n",
      "Epoch 110/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2326 - val_loss: 0.2331\n",
      "Epoch 111/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2359 - val_loss: 0.2316\n",
      "Epoch 112/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2331 - val_loss: 0.2331\n",
      "Epoch 113/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2332 - val_loss: 0.2311\n",
      "Epoch 114/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2328 - val_loss: 0.2307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2316 - val_loss: 0.2316\n",
      "Epoch 116/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2308 - val_loss: 0.2324\n",
      "Epoch 117/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2309 - val_loss: 0.2343\n",
      "Epoch 118/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2363 - val_loss: 0.2412\n",
      "Epoch 119/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2407 - val_loss: 0.2297\n",
      "Epoch 120/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2324 - val_loss: 0.2297\n",
      "Epoch 121/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2290 - val_loss: 0.2349\n",
      "Epoch 122/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2317 - val_loss: 0.2302\n",
      "Epoch 123/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2319 - val_loss: 0.2290\n",
      "Epoch 124/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2257 - val_loss: 0.2305\n",
      "Epoch 125/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2284 - val_loss: 0.2284\n",
      "Epoch 126/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2288 - val_loss: 0.2273\n",
      "Epoch 127/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2264 - val_loss: 0.2258\n",
      "Epoch 128/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2257 - val_loss: 0.2269\n",
      "Epoch 129/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2258 - val_loss: 0.2253\n",
      "Epoch 130/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2254 - val_loss: 0.2227\n",
      "Epoch 131/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2236 - val_loss: 0.2254\n",
      "Epoch 132/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2249 - val_loss: 0.2256\n",
      "Epoch 133/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.2227 - val_loss: 0.2214\n",
      "Epoch 134/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2220 - val_loss: 0.2218\n",
      "Epoch 135/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2208 - val_loss: 0.2253\n",
      "Epoch 136/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2234 - val_loss: 0.2203\n",
      "Epoch 137/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2208 - val_loss: 0.2199\n",
      "Epoch 138/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2153 - val_loss: 0.2219\n",
      "Epoch 139/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2209 - val_loss: 0.2211\n",
      "Epoch 140/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2197 - val_loss: 0.2253\n",
      "Epoch 141/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2213 - val_loss: 0.2173\n",
      "Epoch 142/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2162 - val_loss: 0.2162\n",
      "Epoch 143/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2175 - val_loss: 0.2207\n",
      "Epoch 144/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2191 - val_loss: 0.2163\n",
      "Epoch 145/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2157 - val_loss: 0.2171\n",
      "Epoch 146/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2109 - val_loss: 0.2177\n",
      "Epoch 147/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2154 - val_loss: 0.2149\n",
      "Epoch 148/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2125 - val_loss: 0.2140\n",
      "Epoch 149/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2147 - val_loss: 0.2155\n",
      "Epoch 150/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2127 - val_loss: 0.2150\n",
      "Epoch 151/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2105 - val_loss: 0.2133\n",
      "Epoch 152/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2128 - val_loss: 0.2120\n",
      "Epoch 153/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2081 - val_loss: 0.2099\n",
      "Epoch 154/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2075 - val_loss: 0.2103\n",
      "Epoch 155/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2090 - val_loss: 0.2114\n",
      "Epoch 156/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2076 - val_loss: 0.2099\n",
      "Epoch 157/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2093 - val_loss: 0.2084\n",
      "Epoch 158/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2071 - val_loss: 0.2132\n",
      "Epoch 159/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2104 - val_loss: 0.2103\n",
      "Epoch 160/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2064 - val_loss: 0.2112\n",
      "Epoch 161/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2086 - val_loss: 0.2149\n",
      "Epoch 162/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2092 - val_loss: 0.2163\n",
      "Epoch 163/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2121 - val_loss: 0.2135\n",
      "Epoch 164/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2108 - val_loss: 0.2106\n",
      "Epoch 165/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2050 - val_loss: 0.2081\n",
      "Epoch 166/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2017 - val_loss: 0.2116\n",
      "Epoch 167/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2089 - val_loss: 0.2166\n",
      "Epoch 168/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2104 - val_loss: 0.2086\n",
      "Epoch 169/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2021 - val_loss: 0.2076\n",
      "Epoch 170/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2063 - val_loss: 0.2107\n",
      "Epoch 171/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2085 - val_loss: 0.2043\n",
      "Epoch 172/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2007 - val_loss: 0.2070\n",
      "Epoch 173/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2032 - val_loss: 0.2037\n",
      "Epoch 174/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1965 - val_loss: 0.2057\n",
      "Epoch 175/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2025 - val_loss: 0.1995\n",
      "Epoch 176/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1986 - val_loss: 0.2012\n",
      "Epoch 177/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1983 - val_loss: 0.2027\n",
      "Epoch 178/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1978 - val_loss: 0.1988\n",
      "Epoch 179/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1952 - val_loss: 0.1998\n",
      "Epoch 180/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1969 - val_loss: 0.2020\n",
      "Epoch 181/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1962 - val_loss: 0.1981\n",
      "Epoch 182/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1934 - val_loss: 0.1962\n",
      "Epoch 183/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1935 - val_loss: 0.2003\n",
      "Epoch 184/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1947 - val_loss: 0.1972\n",
      "Epoch 185/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1939 - val_loss: 0.1968\n",
      "Epoch 186/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1942 - val_loss: 0.1968\n",
      "Epoch 187/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1903 - val_loss: 0.2020\n",
      "Epoch 188/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1967 - val_loss: 0.1946\n",
      "Epoch 189/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1905 - val_loss: 0.1973\n",
      "Epoch 190/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1930 - val_loss: 0.1977\n",
      "Epoch 191/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1904 - val_loss: 0.1969\n",
      "Epoch 192/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1918 - val_loss: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1903 - val_loss: 0.1944\n",
      "Epoch 194/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1857 - val_loss: 0.1959\n",
      "Epoch 195/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1872 - val_loss: 0.1930\n",
      "Epoch 196/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1891 - val_loss: 0.1893\n",
      "Epoch 197/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1833 - val_loss: 0.1932\n",
      "Epoch 198/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1881 - val_loss: 0.1934\n",
      "Epoch 199/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1857 - val_loss: 0.1901\n",
      "Epoch 200/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1839 - val_loss: 0.1885\n",
      "Epoch 201/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1855 - val_loss: 0.1870\n",
      "Epoch 202/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1809 - val_loss: 0.1882\n",
      "Epoch 203/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1832 - val_loss: 0.1873\n",
      "Epoch 204/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1811 - val_loss: 0.1872\n",
      "Epoch 205/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1816 - val_loss: 0.1867\n",
      "Epoch 206/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1797 - val_loss: 0.1851\n",
      "Epoch 207/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1792 - val_loss: 0.1866\n",
      "Epoch 208/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1812 - val_loss: 0.1835\n",
      "Epoch 209/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1796 - val_loss: 0.1860\n",
      "Epoch 210/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1813 - val_loss: 0.1834\n",
      "Epoch 211/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1778 - val_loss: 0.1821\n",
      "Epoch 212/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1743 - val_loss: 0.1818\n",
      "Epoch 213/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1770 - val_loss: 0.1811\n",
      "Epoch 214/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1762 - val_loss: 0.1867\n",
      "Epoch 215/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1791 - val_loss: 0.1804\n",
      "Epoch 216/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1728 - val_loss: 0.1796\n",
      "Epoch 217/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1762 - val_loss: 0.1843\n",
      "Epoch 218/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1770 - val_loss: 0.1850\n",
      "Epoch 219/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1798 - val_loss: 0.1836\n",
      "Epoch 220/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1784 - val_loss: 0.1780\n",
      "Epoch 221/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1693 - val_loss: 0.1784\n",
      "Epoch 222/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1740 - val_loss: 0.1776\n",
      "Epoch 223/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1747 - val_loss: 0.1786\n",
      "Epoch 224/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1703 - val_loss: 0.1746\n",
      "Epoch 225/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1687 - val_loss: 0.1754\n",
      "Epoch 226/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1684 - val_loss: 0.1750\n",
      "Epoch 227/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1679 - val_loss: 0.1730\n",
      "Epoch 228/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1686 - val_loss: 0.1709\n",
      "Epoch 229/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1673 - val_loss: 0.1714\n",
      "Epoch 230/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1659 - val_loss: 0.1730\n",
      "Epoch 231/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1668 - val_loss: 0.1680\n",
      "Epoch 232/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1626 - val_loss: 0.1676\n",
      "Epoch 233/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1643 - val_loss: 0.1677\n",
      "Epoch 234/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1646 - val_loss: 0.1674\n",
      "Epoch 235/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1612 - val_loss: 0.1639\n",
      "Epoch 236/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1566 - val_loss: 0.1634\n",
      "Epoch 237/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1586 - val_loss: 0.1652\n",
      "Epoch 238/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1593 - val_loss: 0.1651\n",
      "Epoch 239/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1632 - val_loss: 0.1647\n",
      "Epoch 240/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1602 - val_loss: 0.1634\n",
      "Epoch 241/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1564 - val_loss: 0.1624\n",
      "Epoch 242/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1571 - val_loss: 0.1692\n",
      "Epoch 243/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1623 - val_loss: 0.1726\n",
      "Epoch 244/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1668 - val_loss: 0.1711\n",
      "Epoch 245/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1698 - val_loss: 0.1728\n",
      "Epoch 246/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1662 - val_loss: 0.1593\n",
      "Epoch 247/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1530 - val_loss: 0.1614\n",
      "Epoch 248/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1571 - val_loss: 0.1703\n",
      "Epoch 249/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1656 - val_loss: 0.1639\n",
      "Epoch 250/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1595 - val_loss: 0.1579\n",
      "Epoch 251/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1550 - val_loss: 0.1640\n",
      "Epoch 252/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1560 - val_loss: 0.1596\n",
      "Epoch 253/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1531 - val_loss: 0.1585\n",
      "Epoch 254/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1557 - val_loss: 0.1610\n",
      "Epoch 255/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1534 - val_loss: 0.1557\n",
      "Epoch 256/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1494 - val_loss: 0.1599\n",
      "Epoch 257/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1560 - val_loss: 0.1574\n",
      "Epoch 258/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1515 - val_loss: 0.1600\n",
      "Epoch 259/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1522 - val_loss: 0.1537\n",
      "Epoch 260/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1515 - val_loss: 0.1489\n",
      "Epoch 261/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1480 - val_loss: 0.1565\n",
      "Epoch 262/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1498 - val_loss: 0.1520\n",
      "Epoch 263/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1479 - val_loss: 0.1511\n",
      "Epoch 264/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1471 - val_loss: 0.1495\n",
      "Epoch 265/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1429 - val_loss: 0.1511\n",
      "Epoch 266/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1453 - val_loss: 0.1500\n",
      "Epoch 267/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1463 - val_loss: 0.1485\n",
      "Epoch 268/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1435 - val_loss: 0.1468\n",
      "Epoch 269/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1403 - val_loss: 0.1455\n",
      "Epoch 270/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1402 - val_loss: 0.1485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1442 - val_loss: 0.1479\n",
      "Epoch 272/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1432 - val_loss: 0.1451\n",
      "Epoch 273/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1389 - val_loss: 0.1414\n",
      "Epoch 274/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1383 - val_loss: 0.1411\n",
      "Epoch 275/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1405 - val_loss: 0.1439\n",
      "Epoch 276/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1381 - val_loss: 0.1419\n",
      "Epoch 277/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1360 - val_loss: 0.1414\n",
      "Epoch 278/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1367 - val_loss: 0.1397\n",
      "Epoch 279/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1368 - val_loss: 0.1385\n",
      "Epoch 280/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1362 - val_loss: 0.1378\n",
      "Epoch 281/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1333 - val_loss: 0.1365\n",
      "Epoch 282/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1332 - val_loss: 0.1362\n",
      "Epoch 283/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1346 - val_loss: 0.1363\n",
      "Epoch 284/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1339 - val_loss: 0.1366\n",
      "Epoch 285/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1321 - val_loss: 0.1358\n",
      "Epoch 286/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1300 - val_loss: 0.1358\n",
      "Epoch 287/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1316 - val_loss: 0.1350\n",
      "Epoch 288/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1298 - val_loss: 0.1338\n",
      "Epoch 289/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1328\n",
      "Epoch 290/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1304\n",
      "Epoch 291/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1300 - val_loss: 0.1307\n",
      "Epoch 292/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1299 - val_loss: 0.1315\n",
      "Epoch 293/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1261 - val_loss: 0.1287\n",
      "Epoch 294/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1274 - val_loss: 0.1303\n",
      "Epoch 295/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1264 - val_loss: 0.1266\n",
      "Epoch 296/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1239 - val_loss: 0.1287\n",
      "Epoch 297/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1237 - val_loss: 0.1326\n",
      "Epoch 298/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1297 - val_loss: 0.1382\n",
      "Epoch 299/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1334 - val_loss: 0.1343\n",
      "Epoch 300/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1303 - val_loss: 0.1345\n",
      "Epoch 301/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1315 - val_loss: 0.1317\n",
      "Epoch 302/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1254 - val_loss: 0.1242\n",
      "Epoch 303/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1221 - val_loss: 0.1263\n",
      "Epoch 304/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1219 - val_loss: 0.1228\n",
      "Epoch 305/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1197 - val_loss: 0.1255\n",
      "Epoch 306/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1228 - val_loss: 0.1244\n",
      "Epoch 307/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1243 - val_loss: 0.1253\n",
      "Epoch 308/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1212 - val_loss: 0.1242\n",
      "Epoch 309/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1230 - val_loss: 0.1277\n",
      "Epoch 310/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1242 - val_loss: 0.1291\n",
      "Epoch 311/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1237 - val_loss: 0.1224\n",
      "Epoch 312/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1227 - val_loss: 0.1242\n",
      "Epoch 313/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1196 - val_loss: 0.1179\n",
      "Epoch 314/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1170 - val_loss: 0.1203\n",
      "Epoch 315/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1193 - val_loss: 0.1203\n",
      "Epoch 316/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1189 - val_loss: 0.1188\n",
      "Epoch 317/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1158 - val_loss: 0.1187\n",
      "Epoch 318/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1159 - val_loss: 0.1179\n",
      "Epoch 319/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1135 - val_loss: 0.1152\n",
      "Epoch 320/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1127 - val_loss: 0.1149\n",
      "Epoch 321/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1161 - val_loss: 0.1161\n",
      "Epoch 322/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1148 - val_loss: 0.1174\n",
      "Epoch 323/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1132 - val_loss: 0.1154\n",
      "Epoch 324/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1109 - val_loss: 0.1169\n",
      "Epoch 325/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1133 - val_loss: 0.1208\n",
      "Epoch 326/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1204 - val_loss: 0.1170\n",
      "Epoch 327/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1150 - val_loss: 0.1149\n",
      "Epoch 328/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1134 - val_loss: 0.1120\n",
      "Epoch 329/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1117 - val_loss: 0.1191\n",
      "Epoch 330/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1170 - val_loss: 0.1174\n",
      "Epoch 331/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1162 - val_loss: 0.1133\n",
      "Epoch 332/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1109 - val_loss: 0.1124\n",
      "Epoch 333/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1120 - val_loss: 0.1158\n",
      "Epoch 334/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1117 - val_loss: 0.1200\n",
      "Epoch 335/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1163 - val_loss: 0.1153\n",
      "Epoch 336/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1153 - val_loss: 0.1125\n",
      "Epoch 337/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1091 - val_loss: 0.1101\n",
      "Epoch 338/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1092 - val_loss: 0.1084\n",
      "Epoch 339/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1071 - val_loss: 0.1158\n",
      "Epoch 340/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1105 - val_loss: 0.1080\n",
      "Epoch 341/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1064 - val_loss: 0.1081\n",
      "Epoch 342/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1069 - val_loss: 0.1098\n",
      "Epoch 343/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1043 - val_loss: 0.1067\n",
      "Epoch 344/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1065 - val_loss: 0.1146\n",
      "Epoch 345/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1087 - val_loss: 0.1078\n",
      "Epoch 346/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1068 - val_loss: 0.1075\n",
      "Epoch 347/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1091 - val_loss: 0.1103\n",
      "Epoch 348/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1074 - val_loss: 0.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1113 - val_loss: 0.1119\n",
      "Epoch 350/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1109 - val_loss: 0.1078\n",
      "Epoch 351/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1045 - val_loss: 0.1056\n",
      "Epoch 352/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1058 - val_loss: 0.1092\n",
      "Epoch 353/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1050 - val_loss: 0.1021\n",
      "Epoch 354/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1015 - val_loss: 0.1094\n",
      "Epoch 355/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1080 - val_loss: 0.1060\n",
      "Epoch 356/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1000 - val_loss: 0.1054\n",
      "Epoch 357/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1053 - val_loss: 0.1047\n",
      "Epoch 358/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1007 - val_loss: 0.1036\n",
      "Epoch 359/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1010 - val_loss: 0.1021\n",
      "Epoch 360/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1025 - val_loss: 0.1056\n",
      "Epoch 361/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1053 - val_loss: 0.1002\n",
      "Epoch 362/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0992 - val_loss: 0.1021\n",
      "Epoch 363/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1000 - val_loss: 0.1006\n",
      "Epoch 364/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0980 - val_loss: 0.0999\n",
      "Epoch 365/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0970 - val_loss: 0.1030\n",
      "Epoch 366/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1012 - val_loss: 0.1025\n",
      "Epoch 367/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0976 - val_loss: 0.1013\n",
      "Epoch 368/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1006 - val_loss: 0.0962\n",
      "Epoch 369/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0987 - val_loss: 0.1055\n",
      "Epoch 370/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1022 - val_loss: 0.0973\n",
      "Epoch 371/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0951 - val_loss: 0.1018\n",
      "Epoch 372/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0972 - val_loss: 0.1007\n",
      "Epoch 373/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0936 - val_loss: 0.0984\n",
      "Epoch 374/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0975 - val_loss: 0.1039\n",
      "Epoch 375/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0990 - val_loss: 0.0956\n",
      "Epoch 376/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0943 - val_loss: 0.0994\n",
      "Epoch 377/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0986 - val_loss: 0.0988\n",
      "Epoch 378/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0939 - val_loss: 0.0979\n",
      "Epoch 379/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0993 - val_loss: 0.0992\n",
      "Epoch 380/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0959 - val_loss: 0.0961\n",
      "Epoch 381/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0944 - val_loss: 0.0937\n",
      "Epoch 382/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0942 - val_loss: 0.0955\n",
      "Epoch 383/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0956 - val_loss: 0.0942\n",
      "Epoch 384/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0937 - val_loss: 0.0964\n",
      "Epoch 385/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0948 - val_loss: 0.0978\n",
      "Epoch 386/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0964 - val_loss: 0.0980\n",
      "Epoch 387/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0965 - val_loss: 0.1021\n",
      "Epoch 388/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1010 - val_loss: 0.0954\n",
      "Epoch 389/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0948 - val_loss: 0.0908\n",
      "Epoch 390/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0931 - val_loss: 0.0950\n",
      "Epoch 391/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0923 - val_loss: 0.0937\n",
      "Epoch 392/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0929 - val_loss: 0.0955\n",
      "Epoch 393/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0934 - val_loss: 0.0956\n",
      "Epoch 394/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0895 - val_loss: 0.0911\n",
      "Epoch 395/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0919 - val_loss: 0.0990\n",
      "Epoch 396/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0964 - val_loss: 0.0946\n",
      "Epoch 397/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0956 - val_loss: 0.0952\n",
      "Epoch 398/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0937 - val_loss: 0.0946\n",
      "Epoch 399/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0886 - val_loss: 0.0899\n",
      "Epoch 400/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0886 - val_loss: 0.0948\n",
      "Epoch 401/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0896 - val_loss: 0.0938\n",
      "Epoch 402/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0899 - val_loss: 0.0933\n",
      "Epoch 403/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0890 - val_loss: 0.0936\n",
      "Epoch 404/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0902 - val_loss: 0.0890\n",
      "Epoch 405/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0868 - val_loss: 0.0910\n",
      "Epoch 406/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0888 - val_loss: 0.0877\n",
      "Epoch 407/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0859 - val_loss: 0.0900\n",
      "Epoch 408/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0868 - val_loss: 0.0879\n",
      "Epoch 409/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0853 - val_loss: 0.0884\n",
      "Epoch 410/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0847 - val_loss: 0.0902\n",
      "Epoch 411/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0875 - val_loss: 0.0869\n",
      "Epoch 412/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0856 - val_loss: 0.0902\n",
      "Epoch 413/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0861 - val_loss: 0.0896\n",
      "Epoch 414/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0877 - val_loss: 0.0888\n",
      "Epoch 415/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0846 - val_loss: 0.0897\n",
      "Epoch 416/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0860 - val_loss: 0.0894\n",
      "Epoch 417/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0876 - val_loss: 0.0859\n",
      "Epoch 418/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0824 - val_loss: 0.0863\n",
      "Epoch 419/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0844 - val_loss: 0.0873\n",
      "Epoch 420/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0836 - val_loss: 0.0861\n",
      "Epoch 421/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0840 - val_loss: 0.0856\n",
      "Epoch 422/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0832 - val_loss: 0.0873\n",
      "Epoch 423/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0842 - val_loss: 0.0896\n",
      "Epoch 424/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0877 - val_loss: 0.0897\n",
      "Epoch 425/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0869 - val_loss: 0.0887\n",
      "Epoch 426/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0857 - val_loss: 0.0873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0851 - val_loss: 0.0881\n",
      "Epoch 428/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0852 - val_loss: 0.0866\n",
      "Epoch 429/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0869 - val_loss: 0.0875\n",
      "Epoch 430/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0834 - val_loss: 0.0849\n",
      "Epoch 431/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0784 - val_loss: 0.0854\n",
      "Epoch 432/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0803 - val_loss: 0.0846\n",
      "Epoch 433/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0841 - val_loss: 0.0850\n",
      "Epoch 434/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0818 - val_loss: 0.0844\n",
      "Epoch 435/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0819 - val_loss: 0.0825\n",
      "Epoch 436/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0806 - val_loss: 0.0847\n",
      "Epoch 437/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0820 - val_loss: 0.0822\n",
      "Epoch 438/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0812 - val_loss: 0.0870\n",
      "Epoch 439/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0811 - val_loss: 0.0820\n",
      "Epoch 440/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0803 - val_loss: 0.0854\n",
      "Epoch 441/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0816 - val_loss: 0.0847\n",
      "Epoch 442/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0817 - val_loss: 0.0858\n",
      "Epoch 443/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0862 - val_loss: 0.0866\n",
      "Epoch 444/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0819 - val_loss: 0.0845\n",
      "Epoch 445/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0806 - val_loss: 0.0800\n",
      "Epoch 446/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0752 - val_loss: 0.0843\n",
      "Epoch 447/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 448/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0754 - val_loss: 0.0832\n",
      "Epoch 449/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0775 - val_loss: 0.0796\n",
      "Epoch 450/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0780 - val_loss: 0.0811\n",
      "Epoch 451/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0764 - val_loss: 0.0830\n",
      "Epoch 452/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0779 - val_loss: 0.0807\n",
      "Epoch 453/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0802 - val_loss: 0.0809\n",
      "Epoch 454/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0782 - val_loss: 0.0809\n",
      "Epoch 455/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0764 - val_loss: 0.0781\n",
      "Epoch 456/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0750 - val_loss: 0.0806\n",
      "Epoch 457/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0781 - val_loss: 0.0801\n",
      "Epoch 458/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0780 - val_loss: 0.0826\n",
      "Epoch 459/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0778 - val_loss: 0.0779\n",
      "Epoch 460/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0784 - val_loss: 0.0805\n",
      "Epoch 461/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0767 - val_loss: 0.0831\n",
      "Epoch 462/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0816 - val_loss: 0.0810\n",
      "Epoch 463/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0755 - val_loss: 0.0837\n",
      "Epoch 464/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0794 - val_loss: 0.0801\n",
      "Epoch 465/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0777 - val_loss: 0.0777\n",
      "Epoch 466/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0751 - val_loss: 0.0821\n",
      "Epoch 467/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0754 - val_loss: 0.0773\n",
      "Epoch 468/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0759 - val_loss: 0.0781\n",
      "Epoch 469/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0732 - val_loss: 0.0778\n",
      "Epoch 470/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0696 - val_loss: 0.0782\n",
      "Epoch 471/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0757 - val_loss: 0.0830\n",
      "Epoch 472/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0753 - val_loss: 0.0768\n",
      "Epoch 473/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0763 - val_loss: 0.0800\n",
      "Epoch 474/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0748 - val_loss: 0.0766\n",
      "Epoch 475/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0722 - val_loss: 0.0764\n",
      "Epoch 476/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0727 - val_loss: 0.0783\n",
      "Epoch 477/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0727 - val_loss: 0.0759\n",
      "Epoch 478/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0735 - val_loss: 0.0796\n",
      "Epoch 479/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0743 - val_loss: 0.0760\n",
      "Epoch 480/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0747 - val_loss: 0.0813\n",
      "Epoch 481/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0764 - val_loss: 0.0760\n",
      "Epoch 482/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0737 - val_loss: 0.0752\n",
      "Epoch 483/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0726 - val_loss: 0.0808\n",
      "Epoch 484/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0757 - val_loss: 0.0774\n",
      "Epoch 485/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0753 - val_loss: 0.0837\n",
      "Epoch 486/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0757 - val_loss: 0.0763\n",
      "Epoch 487/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0743 - val_loss: 0.0747\n",
      "Epoch 488/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0725 - val_loss: 0.0814\n",
      "Epoch 489/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0758 - val_loss: 0.0752\n",
      "Epoch 490/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0754 - val_loss: 0.0790\n",
      "Epoch 491/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0751 - val_loss: 0.0758\n",
      "Epoch 492/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0716 - val_loss: 0.0773\n",
      "Epoch 493/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0714 - val_loss: 0.0753\n",
      "Epoch 494/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0714 - val_loss: 0.0762\n",
      "Epoch 495/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0706 - val_loss: 0.0791\n",
      "Epoch 496/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0745 - val_loss: 0.0781\n",
      "Epoch 497/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0758 - val_loss: 0.0786\n",
      "Epoch 498/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0769 - val_loss: 0.0815\n",
      "Epoch 499/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0762 - val_loss: 0.0750\n",
      "Epoch 500/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0723 - val_loss: 0.0760\n",
      "Epoch 501/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0713 - val_loss: 0.0754\n",
      "Epoch 502/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0723 - val_loss: 0.0777\n",
      "Epoch 503/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0716 - val_loss: 0.0731\n",
      "Epoch 504/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0703 - val_loss: 0.0747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0697 - val_loss: 0.0732\n",
      "Epoch 506/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0667 - val_loss: 0.0753\n",
      "Epoch 507/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0697 - val_loss: 0.0738\n",
      "Epoch 508/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0705 - val_loss: 0.0797\n",
      "Epoch 509/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0719 - val_loss: 0.0759\n",
      "Epoch 510/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0728 - val_loss: 0.0743\n",
      "Epoch 511/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0677 - val_loss: 0.0752\n",
      "Epoch 512/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0716 - val_loss: 0.0741\n",
      "Epoch 513/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0724 - val_loss: 0.0794\n",
      "Epoch 514/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0750 - val_loss: 0.0756\n",
      "Epoch 515/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0736 - val_loss: 0.0731\n",
      "Epoch 516/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0689 - val_loss: 0.0747\n",
      "Epoch 517/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0690 - val_loss: 0.0710\n",
      "Epoch 518/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0710 - val_loss: 0.0757\n",
      "Epoch 519/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0695 - val_loss: 0.0757\n",
      "Epoch 520/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0709 - val_loss: 0.0712\n",
      "Epoch 521/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0686 - val_loss: 0.0781\n",
      "Epoch 522/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0739 - val_loss: 0.0744\n",
      "Epoch 523/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0722 - val_loss: 0.0714\n",
      "Epoch 524/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0669 - val_loss: 0.0785\n",
      "Epoch 525/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0737 - val_loss: 0.0728\n",
      "Epoch 526/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0726 - val_loss: 0.0756\n",
      "Epoch 527/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0679 - val_loss: 0.0741\n",
      "Epoch 528/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0672 - val_loss: 0.0705\n",
      "Epoch 529/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0706 - val_loss: 0.0742\n",
      "Epoch 530/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0684 - val_loss: 0.0719\n",
      "Epoch 531/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0686 - val_loss: 0.0716\n",
      "Epoch 532/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0659 - val_loss: 0.0731\n",
      "Epoch 533/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0678 - val_loss: 0.0697\n",
      "Epoch 534/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0664 - val_loss: 0.0738\n",
      "Epoch 535/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0665 - val_loss: 0.0719\n",
      "Epoch 536/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0686 - val_loss: 0.0709\n",
      "Epoch 537/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0651 - val_loss: 0.0739\n",
      "Epoch 538/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0689 - val_loss: 0.0695\n",
      "Epoch 539/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0668 - val_loss: 0.0735\n",
      "Epoch 540/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0669 - val_loss: 0.0699\n",
      "Epoch 541/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0684 - val_loss: 0.0703\n",
      "Epoch 542/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0650 - val_loss: 0.0704\n",
      "Epoch 543/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0652 - val_loss: 0.0701\n",
      "Epoch 544/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0647 - val_loss: 0.0768\n",
      "Epoch 545/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0691 - val_loss: 0.0698\n",
      "Epoch 546/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0649 - val_loss: 0.0706\n",
      "Epoch 547/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0642 - val_loss: 0.0723\n",
      "Epoch 548/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0667 - val_loss: 0.0706\n",
      "Epoch 549/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0670 - val_loss: 0.0725\n",
      "Epoch 550/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0646 - val_loss: 0.0696\n",
      "Epoch 551/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0651 - val_loss: 0.0710\n",
      "Epoch 552/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0650 - val_loss: 0.0713\n",
      "Epoch 553/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0661 - val_loss: 0.0707\n",
      "Epoch 554/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0682 - val_loss: 0.0718\n",
      "Epoch 555/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0656 - val_loss: 0.0690\n",
      "Epoch 556/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0637 - val_loss: 0.0672\n",
      "Epoch 557/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0628 - val_loss: 0.0733\n",
      "Epoch 558/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0668 - val_loss: 0.0704\n",
      "Epoch 559/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0698 - val_loss: 0.0748\n",
      "Epoch 560/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0716 - val_loss: 0.0733\n",
      "Epoch 561/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0671 - val_loss: 0.0707\n",
      "Epoch 562/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0662 - val_loss: 0.0719\n",
      "Epoch 563/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0652 - val_loss: 0.0687\n",
      "Epoch 564/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0631 - val_loss: 0.0704\n",
      "Epoch 565/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0671 - val_loss: 0.0754\n",
      "Epoch 566/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0672 - val_loss: 0.0702\n",
      "Epoch 567/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0651 - val_loss: 0.0705\n",
      "Epoch 568/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0663 - val_loss: 0.0690\n",
      "Epoch 569/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0643 - val_loss: 0.0701\n",
      "Epoch 570/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0653 - val_loss: 0.0739\n",
      "Epoch 571/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0682 - val_loss: 0.0695\n",
      "Epoch 572/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0654 - val_loss: 0.0665\n",
      "Epoch 573/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0621 - val_loss: 0.0713\n",
      "Epoch 574/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0671 - val_loss: 0.0668\n",
      "Epoch 575/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0645 - val_loss: 0.0700\n",
      "Epoch 576/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0638 - val_loss: 0.0709\n",
      "Epoch 577/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0630 - val_loss: 0.0662\n",
      "Epoch 578/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0627 - val_loss: 0.0699\n",
      "Epoch 579/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0639 - val_loss: 0.0691\n",
      "Epoch 580/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0641 - val_loss: 0.0676\n",
      "Epoch 581/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0672 - val_loss: 0.0712\n",
      "Epoch 582/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0642 - val_loss: 0.0661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0619 - val_loss: 0.0661\n",
      "Epoch 584/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0623 - val_loss: 0.0706\n",
      "Epoch 585/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0637 - val_loss: 0.0680\n",
      "Epoch 586/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0639 - val_loss: 0.0699\n",
      "Epoch 587/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0641 - val_loss: 0.0680\n",
      "Epoch 588/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0602 - val_loss: 0.0666\n",
      "Epoch 589/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0633 - val_loss: 0.0704\n",
      "Epoch 590/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0639 - val_loss: 0.0654\n",
      "Epoch 591/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0607 - val_loss: 0.0667\n",
      "Epoch 592/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0634 - val_loss: 0.0714\n",
      "Epoch 593/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0643 - val_loss: 0.0662\n",
      "Epoch 594/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0615 - val_loss: 0.0658\n",
      "Epoch 595/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0600 - val_loss: 0.0685\n",
      "Epoch 596/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0612 - val_loss: 0.0657\n",
      "Epoch 597/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0636 - val_loss: 0.0675\n",
      "Epoch 598/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0603 - val_loss: 0.0672\n",
      "Epoch 599/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0607 - val_loss: 0.0646\n",
      "Epoch 600/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0615 - val_loss: 0.0707\n",
      "Epoch 601/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0616 - val_loss: 0.0663\n",
      "Epoch 602/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0610 - val_loss: 0.0658\n",
      "Epoch 603/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0625 - val_loss: 0.0700\n",
      "Epoch 604/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0623 - val_loss: 0.0647\n",
      "Epoch 605/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0576 - val_loss: 0.0655\n",
      "Epoch 606/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0618 - val_loss: 0.0702\n",
      "Epoch 607/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0621 - val_loss: 0.0657\n",
      "Epoch 608/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0598 - val_loss: 0.0676\n",
      "Epoch 609/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0607 - val_loss: 0.0674\n",
      "Epoch 610/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0597 - val_loss: 0.0659\n",
      "Epoch 611/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0616 - val_loss: 0.0675\n",
      "Epoch 612/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0597 - val_loss: 0.0661\n",
      "Epoch 613/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0603 - val_loss: 0.0647\n",
      "Epoch 614/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0593 - val_loss: 0.0680\n",
      "Epoch 615/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0611 - val_loss: 0.0679\n",
      "Epoch 616/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0633 - val_loss: 0.0666\n",
      "Epoch 617/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0596 - val_loss: 0.0671\n",
      "Epoch 618/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0662\n",
      "Epoch 619/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0575 - val_loss: 0.0653\n",
      "Epoch 620/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0583 - val_loss: 0.0647\n",
      "Epoch 621/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0577 - val_loss: 0.0637\n",
      "Epoch 622/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0586 - val_loss: 0.0645\n",
      "Epoch 623/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0585 - val_loss: 0.0645\n",
      "Epoch 624/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0586 - val_loss: 0.0635\n",
      "Epoch 625/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0576 - val_loss: 0.0665\n",
      "Epoch 626/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0567 - val_loss: 0.0639\n",
      "Epoch 627/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0582 - val_loss: 0.0643\n",
      "Epoch 628/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0593 - val_loss: 0.0677\n",
      "Epoch 629/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0585 - val_loss: 0.0636\n",
      "Epoch 630/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0591 - val_loss: 0.0653\n",
      "Epoch 631/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0561 - val_loss: 0.0649\n",
      "Epoch 632/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0582 - val_loss: 0.0627\n",
      "Epoch 633/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0585 - val_loss: 0.0662\n",
      "Epoch 634/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0568 - val_loss: 0.0632\n",
      "Epoch 635/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0570 - val_loss: 0.0638\n",
      "Epoch 636/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0574 - val_loss: 0.0664\n",
      "Epoch 637/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0584 - val_loss: 0.0628\n",
      "Epoch 638/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0568 - val_loss: 0.0668\n",
      "Epoch 639/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0574 - val_loss: 0.0618\n",
      "Epoch 640/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0570 - val_loss: 0.0638\n",
      "Epoch 641/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0582 - val_loss: 0.0665\n",
      "Epoch 642/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0568 - val_loss: 0.0636\n",
      "Epoch 643/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0577 - val_loss: 0.0650\n",
      "Epoch 644/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0574 - val_loss: 0.0642\n",
      "Epoch 645/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0546 - val_loss: 0.0620\n",
      "Epoch 646/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0569 - val_loss: 0.0686\n",
      "Epoch 647/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0576 - val_loss: 0.0615\n",
      "Epoch 648/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0574 - val_loss: 0.0624\n",
      "Epoch 649/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0574 - val_loss: 0.0671\n",
      "Epoch 650/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0566 - val_loss: 0.0625\n",
      "Epoch 651/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0564 - val_loss: 0.0651\n",
      "Epoch 652/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0605 - val_loss: 0.0639\n",
      "Epoch 653/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0572 - val_loss: 0.0624\n",
      "Epoch 654/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0571 - val_loss: 0.0685\n",
      "Epoch 655/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0585 - val_loss: 0.0630\n",
      "Epoch 656/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0654\n",
      "Epoch 657/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0619 - val_loss: 0.0687\n",
      "Epoch 658/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0595 - val_loss: 0.0650\n",
      "Epoch 659/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0592 - val_loss: 0.0636\n",
      "Epoch 660/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0561 - val_loss: 0.0653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 661/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0565 - val_loss: 0.0657\n",
      "Epoch 662/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0610 - val_loss: 0.0641\n",
      "Epoch 663/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0570 - val_loss: 0.0670\n",
      "Epoch 664/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0594 - val_loss: 0.0626\n",
      "Epoch 665/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0599 - val_loss: 0.0670\n",
      "Epoch 666/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0596 - val_loss: 0.0646\n",
      "Epoch 667/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0579 - val_loss: 0.0607\n",
      "Epoch 668/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0574 - val_loss: 0.0636\n",
      "Epoch 669/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0562 - val_loss: 0.0632\n",
      "Epoch 670/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0572 - val_loss: 0.0638\n",
      "Epoch 671/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0575 - val_loss: 0.0655\n",
      "Epoch 672/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0590 - val_loss: 0.0615\n",
      "Epoch 673/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0633\n",
      "Epoch 674/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0581 - val_loss: 0.0629\n",
      "Epoch 675/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0553 - val_loss: 0.0612\n",
      "Epoch 676/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0558 - val_loss: 0.0632\n",
      "Epoch 677/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0562 - val_loss: 0.0617\n",
      "Epoch 678/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0553 - val_loss: 0.0627\n",
      "Epoch 679/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0539 - val_loss: 0.0640\n",
      "Epoch 680/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0551 - val_loss: 0.0623\n",
      "Epoch 681/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0528 - val_loss: 0.0613\n",
      "Epoch 682/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0551 - val_loss: 0.0620\n",
      "Epoch 683/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0543 - val_loss: 0.0605\n",
      "Epoch 684/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0539 - val_loss: 0.0612\n",
      "Epoch 685/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0530 - val_loss: 0.0622\n",
      "Epoch 686/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0528 - val_loss: 0.0625\n",
      "Epoch 687/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0543 - val_loss: 0.0634\n",
      "Epoch 688/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0565 - val_loss: 0.0623\n",
      "Epoch 689/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0528 - val_loss: 0.0613\n",
      "Epoch 690/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0602\n",
      "Epoch 691/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0526 - val_loss: 0.0590\n",
      "Epoch 692/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0518 - val_loss: 0.0638\n",
      "Epoch 693/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0547 - val_loss: 0.0603\n",
      "Epoch 694/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0524 - val_loss: 0.0639\n",
      "Epoch 695/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0562 - val_loss: 0.0618\n",
      "Epoch 696/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0521 - val_loss: 0.0608\n",
      "Epoch 697/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0629\n",
      "Epoch 698/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0528 - val_loss: 0.0587\n",
      "Epoch 699/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0522 - val_loss: 0.0621\n",
      "Epoch 700/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0549 - val_loss: 0.0598\n",
      "Epoch 701/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0589\n",
      "Epoch 702/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0514 - val_loss: 0.0636\n",
      "Epoch 703/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0537 - val_loss: 0.0593\n",
      "Epoch 704/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0537 - val_loss: 0.0634\n",
      "Epoch 705/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0538 - val_loss: 0.0603\n",
      "Epoch 706/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0519 - val_loss: 0.0581\n",
      "Epoch 707/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0526 - val_loss: 0.0644\n",
      "Epoch 708/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0544 - val_loss: 0.0583\n",
      "Epoch 709/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0529 - val_loss: 0.0600\n",
      "Epoch 710/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0499 - val_loss: 0.0614\n",
      "Epoch 711/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0603\n",
      "Epoch 712/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0543 - val_loss: 0.0622\n",
      "Epoch 713/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0544 - val_loss: 0.0619\n",
      "Epoch 714/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0526 - val_loss: 0.0584\n",
      "Epoch 715/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0519 - val_loss: 0.0617\n",
      "Epoch 716/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0530 - val_loss: 0.0599\n",
      "Epoch 717/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0505 - val_loss: 0.0569\n",
      "Epoch 718/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0523 - val_loss: 0.0624\n",
      "Epoch 719/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0526 - val_loss: 0.0593\n",
      "Epoch 720/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0522 - val_loss: 0.0588\n",
      "Epoch 721/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0523 - val_loss: 0.0594\n",
      "Epoch 722/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0588\n",
      "Epoch 723/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0492 - val_loss: 0.0602\n",
      "Epoch 724/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0524 - val_loss: 0.0605\n",
      "Epoch 725/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0603\n",
      "Epoch 726/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0511 - val_loss: 0.0616\n",
      "Epoch 727/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0519 - val_loss: 0.0587\n",
      "Epoch 728/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0504 - val_loss: 0.0592\n",
      "Epoch 729/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0509 - val_loss: 0.0593\n",
      "Epoch 730/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0499 - val_loss: 0.0578\n",
      "Epoch 731/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0512 - val_loss: 0.0607\n",
      "Epoch 732/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0589\n",
      "Epoch 733/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0497 - val_loss: 0.0597\n",
      "Epoch 734/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0528 - val_loss: 0.0605\n",
      "Epoch 735/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0509 - val_loss: 0.0602\n",
      "Epoch 736/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0522 - val_loss: 0.0609\n",
      "Epoch 737/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0520 - val_loss: 0.0614\n",
      "Epoch 738/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0514 - val_loss: 0.0597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 739/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0537 - val_loss: 0.0597\n",
      "Epoch 740/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0495 - val_loss: 0.0574\n",
      "Epoch 741/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0490 - val_loss: 0.0590\n",
      "Epoch 742/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0523 - val_loss: 0.0632\n",
      "Epoch 743/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0529 - val_loss: 0.0610\n",
      "Epoch 744/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0514 - val_loss: 0.0605\n",
      "Epoch 745/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0513 - val_loss: 0.0598\n",
      "Epoch 746/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0501 - val_loss: 0.0577\n",
      "Epoch 747/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0655\n",
      "Epoch 748/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0560 - val_loss: 0.0623\n",
      "Epoch 749/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0601\n",
      "Epoch 750/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0533 - val_loss: 0.0616\n",
      "Epoch 751/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0513 - val_loss: 0.0581\n",
      "Epoch 752/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0511 - val_loss: 0.0613\n",
      "Epoch 753/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0607\n",
      "Epoch 754/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0531 - val_loss: 0.0591\n",
      "Epoch 755/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0508 - val_loss: 0.0572\n",
      "Epoch 756/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0499 - val_loss: 0.0588\n",
      "Epoch 757/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0569\n",
      "Epoch 758/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0492 - val_loss: 0.0586\n",
      "Epoch 759/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0485 - val_loss: 0.0576\n",
      "Epoch 760/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0484 - val_loss: 0.0596\n",
      "Epoch 761/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0488 - val_loss: 0.0575\n",
      "Epoch 762/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0489 - val_loss: 0.0578\n",
      "Epoch 763/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0477 - val_loss: 0.0576\n",
      "Epoch 764/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0591\n",
      "Epoch 765/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0489 - val_loss: 0.0605\n",
      "Epoch 766/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0510 - val_loss: 0.0625\n",
      "Epoch 767/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0518 - val_loss: 0.0604\n",
      "Epoch 768/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0508 - val_loss: 0.0601\n",
      "Epoch 769/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0502 - val_loss: 0.0602\n",
      "Epoch 770/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0495 - val_loss: 0.0563\n",
      "Epoch 771/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0478 - val_loss: 0.0595\n",
      "Epoch 772/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0567\n",
      "Epoch 773/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0589\n",
      "Epoch 774/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0490 - val_loss: 0.0572\n",
      "Epoch 775/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0484 - val_loss: 0.0586\n",
      "Epoch 776/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0475 - val_loss: 0.0611\n",
      "Epoch 777/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0499 - val_loss: 0.0577\n",
      "Epoch 778/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0487 - val_loss: 0.0584\n",
      "Epoch 779/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0474 - val_loss: 0.0595\n",
      "Epoch 780/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0567\n",
      "Epoch 781/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0483 - val_loss: 0.0588\n",
      "Epoch 782/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0569\n",
      "Epoch 783/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0485 - val_loss: 0.0602\n",
      "Epoch 784/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0490 - val_loss: 0.0554\n",
      "Epoch 785/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0486 - val_loss: 0.0583\n",
      "Epoch 786/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0489 - val_loss: 0.0616\n",
      "Epoch 787/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0493 - val_loss: 0.0592\n",
      "Epoch 788/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0526 - val_loss: 0.0621\n",
      "Epoch 789/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0516 - val_loss: 0.0592\n",
      "Epoch 790/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0475 - val_loss: 0.0567\n",
      "Epoch 791/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0487 - val_loss: 0.0601\n",
      "Epoch 792/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0574\n",
      "Epoch 793/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0590\n",
      "Epoch 794/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0505 - val_loss: 0.0619\n",
      "Epoch 795/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0508 - val_loss: 0.0597\n",
      "Epoch 796/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0514 - val_loss: 0.0581\n",
      "Epoch 797/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0577\n",
      "Epoch 798/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0480 - val_loss: 0.0564\n",
      "Epoch 799/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0485 - val_loss: 0.0603\n",
      "Epoch 800/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0586\n",
      "Epoch 801/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0489 - val_loss: 0.0572\n",
      "Epoch 802/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0484 - val_loss: 0.0591\n",
      "Epoch 803/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0471 - val_loss: 0.0552\n",
      "Epoch 804/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0472 - val_loss: 0.0572\n",
      "Epoch 805/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0479 - val_loss: 0.0575\n",
      "Epoch 806/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0470 - val_loss: 0.0565\n",
      "Epoch 807/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0480 - val_loss: 0.0569\n",
      "Epoch 808/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0555\n",
      "Epoch 809/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0467 - val_loss: 0.0591\n",
      "Epoch 810/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0493 - val_loss: 0.0564\n",
      "Epoch 811/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0465 - val_loss: 0.0568\n",
      "Epoch 812/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0478 - val_loss: 0.0582\n",
      "Epoch 813/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0486 - val_loss: 0.0569\n",
      "Epoch 814/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0584\n",
      "Epoch 815/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0569\n",
      "Epoch 816/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0457 - val_loss: 0.0563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0471 - val_loss: 0.0591\n",
      "Epoch 818/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0482 - val_loss: 0.0554\n",
      "Epoch 819/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0580\n",
      "Epoch 820/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0486 - val_loss: 0.0582\n",
      "Epoch 821/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0488 - val_loss: 0.0574\n",
      "Epoch 822/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0475 - val_loss: 0.0579\n",
      "Epoch 823/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0459 - val_loss: 0.0574\n",
      "Epoch 824/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0453 - val_loss: 0.0556\n",
      "Epoch 825/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0466 - val_loss: 0.0570\n",
      "Epoch 826/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0461 - val_loss: 0.0540\n",
      "Epoch 827/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0461 - val_loss: 0.0561\n",
      "Epoch 828/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0464 - val_loss: 0.0576\n",
      "Epoch 829/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0473 - val_loss: 0.0549\n",
      "Epoch 830/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0473 - val_loss: 0.0577\n",
      "Epoch 831/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0480 - val_loss: 0.0573\n",
      "Epoch 832/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0554\n",
      "Epoch 833/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0479 - val_loss: 0.0599\n",
      "Epoch 834/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0573\n",
      "Epoch 835/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0485 - val_loss: 0.0570\n",
      "Epoch 836/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0486 - val_loss: 0.0602\n",
      "Epoch 837/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0469 - val_loss: 0.0568\n",
      "Epoch 838/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0570\n",
      "Epoch 839/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0483 - val_loss: 0.0592\n",
      "Epoch 840/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0478 - val_loss: 0.0565\n",
      "Epoch 841/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0490 - val_loss: 0.0560\n",
      "Epoch 842/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0458 - val_loss: 0.0583\n",
      "Epoch 843/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0557\n",
      "Epoch 844/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0475 - val_loss: 0.0574\n",
      "Epoch 845/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0469 - val_loss: 0.0552\n",
      "Epoch 846/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0448 - val_loss: 0.0557\n",
      "Epoch 847/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0574\n",
      "Epoch 848/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0546\n",
      "Epoch 849/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0444 - val_loss: 0.0568\n",
      "Epoch 850/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0461 - val_loss: 0.0562\n",
      "Epoch 851/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0461 - val_loss: 0.0566\n",
      "Epoch 852/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0465 - val_loss: 0.0566\n",
      "Epoch 853/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0542\n",
      "Epoch 854/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0435 - val_loss: 0.0561\n",
      "Epoch 855/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0442 - val_loss: 0.0548\n",
      "Epoch 856/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0460 - val_loss: 0.0570\n",
      "Epoch 857/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0456 - val_loss: 0.0544\n",
      "Epoch 858/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0565\n",
      "Epoch 859/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0562\n",
      "Epoch 860/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0565\n",
      "Epoch 861/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0452 - val_loss: 0.0582\n",
      "Epoch 862/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0480 - val_loss: 0.0572\n",
      "Epoch 863/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0568\n",
      "Epoch 864/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0483 - val_loss: 0.0592\n",
      "Epoch 865/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0477 - val_loss: 0.0555\n",
      "Epoch 866/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0461 - val_loss: 0.0555\n",
      "Epoch 867/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0456 - val_loss: 0.0603\n",
      "Epoch 868/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0452 - val_loss: 0.0551\n",
      "Epoch 869/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0472 - val_loss: 0.0575\n",
      "Epoch 870/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0442 - val_loss: 0.0555\n",
      "Epoch 871/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0432 - val_loss: 0.0548\n",
      "Epoch 872/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0602\n",
      "Epoch 873/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0471 - val_loss: 0.0559\n",
      "Epoch 874/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0460 - val_loss: 0.0551\n",
      "Epoch 875/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0453 - val_loss: 0.0582\n",
      "Epoch 876/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0460 - val_loss: 0.0533\n",
      "Epoch 877/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0447 - val_loss: 0.0582\n",
      "Epoch 878/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0548\n",
      "Epoch 879/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0545\n",
      "Epoch 880/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0587\n",
      "Epoch 881/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0457 - val_loss: 0.0541\n",
      "Epoch 882/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0455 - val_loss: 0.0581\n",
      "Epoch 883/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0459 - val_loss: 0.0560\n",
      "Epoch 884/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0562\n",
      "Epoch 885/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0483 - val_loss: 0.0573\n",
      "Epoch 886/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0447 - val_loss: 0.0563\n",
      "Epoch 887/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0538\n",
      "Epoch 888/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0435 - val_loss: 0.0587\n",
      "Epoch 889/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0441 - val_loss: 0.0552\n",
      "Epoch 890/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0562\n",
      "Epoch 891/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0459 - val_loss: 0.0580\n",
      "Epoch 892/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0462 - val_loss: 0.0535\n",
      "Epoch 893/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0552\n",
      "Epoch 894/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0542\n",
      "Epoch 896/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0560\n",
      "Epoch 897/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0451 - val_loss: 0.0560\n",
      "Epoch 898/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0444 - val_loss: 0.0542\n",
      "Epoch 899/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0552\n",
      "Epoch 900/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0546\n",
      "Epoch 901/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0432 - val_loss: 0.0533\n",
      "Epoch 902/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0429 - val_loss: 0.0560\n",
      "Epoch 903/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0422 - val_loss: 0.0535\n",
      "Epoch 904/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0439 - val_loss: 0.0547\n",
      "Epoch 905/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0417 - val_loss: 0.0550\n",
      "Epoch 906/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0425 - val_loss: 0.0541\n",
      "Epoch 907/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0438 - val_loss: 0.0551\n",
      "Epoch 908/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0426 - val_loss: 0.0541\n",
      "Epoch 909/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0426 - val_loss: 0.0546\n",
      "Epoch 910/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0446 - val_loss: 0.0563\n",
      "Epoch 911/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0442 - val_loss: 0.0552\n",
      "Epoch 912/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0548\n",
      "Epoch 913/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0418 - val_loss: 0.0537\n",
      "Epoch 914/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0551\n",
      "Epoch 915/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0537\n",
      "Epoch 916/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0431 - val_loss: 0.0544\n",
      "Epoch 917/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0438 - val_loss: 0.0538\n",
      "Epoch 918/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0408 - val_loss: 0.0539\n",
      "Epoch 919/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0542\n",
      "Epoch 920/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0537\n",
      "Epoch 921/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0542\n",
      "Epoch 922/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0428 - val_loss: 0.0538\n",
      "Epoch 923/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0418 - val_loss: 0.0543\n",
      "Epoch 924/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0437 - val_loss: 0.0564\n",
      "Epoch 925/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0427 - val_loss: 0.0548\n",
      "Epoch 926/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0431 - val_loss: 0.0544\n",
      "Epoch 927/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0557\n",
      "Epoch 928/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0422 - val_loss: 0.0536\n",
      "Epoch 929/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0438 - val_loss: 0.0552\n",
      "Epoch 930/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0551\n",
      "Epoch 931/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0547\n",
      "Epoch 932/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0576\n",
      "Epoch 933/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0458 - val_loss: 0.0563\n",
      "Epoch 934/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0552\n",
      "Epoch 935/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0456 - val_loss: 0.0539\n",
      "Epoch 936/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0546\n",
      "Epoch 937/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0429 - val_loss: 0.0548\n",
      "Epoch 938/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0561\n",
      "Epoch 939/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0450 - val_loss: 0.0566\n",
      "Epoch 940/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0531\n",
      "Epoch 941/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0550\n",
      "Epoch 942/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0423 - val_loss: 0.0537\n",
      "Epoch 943/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0441 - val_loss: 0.0577\n",
      "Epoch 944/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0470 - val_loss: 0.0593\n",
      "Epoch 945/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0483 - val_loss: 0.0546\n",
      "Epoch 946/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0446 - val_loss: 0.0532\n",
      "Epoch 947/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0536\n",
      "Epoch 948/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0542\n",
      "Epoch 949/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0426 - val_loss: 0.0590\n",
      "Epoch 950/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0580\n",
      "Epoch 951/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0531\n",
      "Epoch 952/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0439 - val_loss: 0.0541\n",
      "Epoch 953/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0406 - val_loss: 0.0539\n",
      "Epoch 954/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0420 - val_loss: 0.0563\n",
      "Epoch 955/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0455 - val_loss: 0.0584\n",
      "Epoch 956/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0462 - val_loss: 0.0564\n",
      "Epoch 957/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0432 - val_loss: 0.0519\n",
      "Epoch 958/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0568\n",
      "Epoch 959/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0426 - val_loss: 0.0558\n",
      "Epoch 960/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0428 - val_loss: 0.0543\n",
      "Epoch 961/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0554\n",
      "Epoch 962/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0540\n",
      "Epoch 963/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0420 - val_loss: 0.0539\n",
      "Epoch 964/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0573\n",
      "Epoch 965/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0451 - val_loss: 0.0539\n",
      "Epoch 966/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0523\n",
      "Epoch 967/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0416 - val_loss: 0.0572\n",
      "Epoch 968/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0437 - val_loss: 0.0522\n",
      "Epoch 969/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0428 - val_loss: 0.0521\n",
      "Epoch 970/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0404 - val_loss: 0.0571\n",
      "Epoch 971/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0517\n",
      "Epoch 972/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0417 - val_loss: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 973/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0395 - val_loss: 0.0543\n",
      "Epoch 974/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0398 - val_loss: 0.0511\n",
      "Epoch 975/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0420 - val_loss: 0.0554\n",
      "Epoch 976/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0519\n",
      "Epoch 977/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0397 - val_loss: 0.0511\n",
      "Epoch 978/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0558\n",
      "Epoch 979/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0407 - val_loss: 0.0526\n",
      "Epoch 980/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0401 - val_loss: 0.0530\n",
      "Epoch 981/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0400 - val_loss: 0.0534\n",
      "Epoch 982/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0406 - val_loss: 0.0518\n",
      "Epoch 983/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0411 - val_loss: 0.0526\n",
      "Epoch 984/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0394 - val_loss: 0.0529\n",
      "Epoch 985/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0403 - val_loss: 0.0517\n",
      "Epoch 986/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0391 - val_loss: 0.0538\n",
      "Epoch 987/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0396 - val_loss: 0.0510\n",
      "Epoch 988/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0527\n",
      "Epoch 989/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0400 - val_loss: 0.0527\n",
      "Epoch 990/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0396 - val_loss: 0.0521\n",
      "Epoch 991/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0408 - val_loss: 0.0547\n",
      "Epoch 992/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0421 - val_loss: 0.0554\n",
      "Epoch 993/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0424 - val_loss: 0.0536\n",
      "Epoch 994/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0432 - val_loss: 0.0554\n",
      "Epoch 995/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0409 - val_loss: 0.0530\n",
      "Epoch 996/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0395 - val_loss: 0.0517\n",
      "Epoch 997/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0404 - val_loss: 0.0544\n",
      "Epoch 998/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0400 - val_loss: 0.0543\n",
      "Epoch 999/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0543\n",
      "Epoch 1000/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0421 - val_loss: 0.0548\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_3 (Bidirection (None, 5, 2048)           8486912   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 5, 512)            5244928   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 5, 1)              513       \n",
      "=================================================================\n",
      "Total params: 13,732,353\n",
      "Trainable params: 13,732,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3298 samples, validate on 825 samples\n",
      "Epoch 1/1000\n",
      "3298/3298 [==============================] - 9s 3ms/step - loss: 0.5245 - val_loss: 0.4138\n",
      "Epoch 2/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.4082 - val_loss: 0.3091\n",
      "Epoch 3/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3111 - val_loss: 0.3274\n",
      "Epoch 4/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3349 - val_loss: 0.3027\n",
      "Epoch 5/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.3139 - val_loss: 0.2499\n",
      "Epoch 6/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2621 - val_loss: 0.2504\n",
      "Epoch 7/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2536 - val_loss: 0.2664\n",
      "Epoch 8/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2664 - val_loss: 0.2530\n",
      "Epoch 9/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2570 - val_loss: 0.2325\n",
      "Epoch 10/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2427 - val_loss: 0.2220\n",
      "Epoch 11/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2354 - val_loss: 0.2104\n",
      "Epoch 12/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2276 - val_loss: 0.2090\n",
      "Epoch 13/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2261 - val_loss: 0.2133\n",
      "Epoch 14/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2259 - val_loss: 0.2085\n",
      "Epoch 15/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2204 - val_loss: 0.2008\n",
      "Epoch 16/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2139 - val_loss: 0.1969\n",
      "Epoch 17/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2137 - val_loss: 0.1943\n",
      "Epoch 18/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2118 - val_loss: 0.1938\n",
      "Epoch 19/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2102 - val_loss: 0.1936\n",
      "Epoch 20/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2105 - val_loss: 0.1888\n",
      "Epoch 21/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2066 - val_loss: 0.1851\n",
      "Epoch 22/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1996 - val_loss: 0.1844\n",
      "Epoch 23/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2002 - val_loss: 0.1858\n",
      "Epoch 24/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2030 - val_loss: 0.1864\n",
      "Epoch 25/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2044 - val_loss: 0.1855\n",
      "Epoch 26/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2012 - val_loss: 0.1838\n",
      "Epoch 27/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2008 - val_loss: 0.1836\n",
      "Epoch 28/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1993 - val_loss: 0.1841\n",
      "Epoch 29/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1971 - val_loss: 0.1839\n",
      "Epoch 30/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.2014 - val_loss: 0.1834\n",
      "Epoch 31/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1962 - val_loss: 0.1819\n",
      "Epoch 32/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1983 - val_loss: 0.1804\n",
      "Epoch 33/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1973 - val_loss: 0.1796\n",
      "Epoch 34/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1937 - val_loss: 0.1794\n",
      "Epoch 35/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1953 - val_loss: 0.1789\n",
      "Epoch 36/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1955 - val_loss: 0.1788\n",
      "Epoch 37/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1944 - val_loss: 0.1778\n",
      "Epoch 38/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1926 - val_loss: 0.1780\n",
      "Epoch 39/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1925 - val_loss: 0.1788\n",
      "Epoch 40/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1909 - val_loss: 0.1786\n",
      "Epoch 41/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1902 - val_loss: 0.1771\n",
      "Epoch 42/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1936 - val_loss: 0.1761\n",
      "Epoch 43/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1908 - val_loss: 0.1759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1896 - val_loss: 0.1769\n",
      "Epoch 45/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1914 - val_loss: 0.1763\n",
      "Epoch 46/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1902 - val_loss: 0.1755\n",
      "Epoch 47/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1896 - val_loss: 0.1753\n",
      "Epoch 48/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1883 - val_loss: 0.1755\n",
      "Epoch 49/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1875 - val_loss: 0.1764\n",
      "Epoch 50/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1889 - val_loss: 0.1761\n",
      "Epoch 51/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1873 - val_loss: 0.1755\n",
      "Epoch 52/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1860 - val_loss: 0.1749\n",
      "Epoch 53/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1885 - val_loss: 0.1744\n",
      "Epoch 54/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1866 - val_loss: 0.1738\n",
      "Epoch 55/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1852 - val_loss: 0.1736\n",
      "Epoch 56/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1858 - val_loss: 0.1735\n",
      "Epoch 57/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1865 - val_loss: 0.1739\n",
      "Epoch 58/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1860 - val_loss: 0.1738\n",
      "Epoch 59/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1841 - val_loss: 0.1733\n",
      "Epoch 60/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1852 - val_loss: 0.1734\n",
      "Epoch 61/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1827 - val_loss: 0.1732\n",
      "Epoch 62/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1862 - val_loss: 0.1724\n",
      "Epoch 63/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1849 - val_loss: 0.1718\n",
      "Epoch 64/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1856 - val_loss: 0.1723\n",
      "Epoch 65/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1852 - val_loss: 0.1727\n",
      "Epoch 66/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1824 - val_loss: 0.1722\n",
      "Epoch 67/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1829 - val_loss: 0.1717\n",
      "Epoch 68/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1792 - val_loss: 0.1711\n",
      "Epoch 69/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1804 - val_loss: 0.1711\n",
      "Epoch 70/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1842 - val_loss: 0.1703\n",
      "Epoch 71/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1855 - val_loss: 0.1698\n",
      "Epoch 72/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1816 - val_loss: 0.1699\n",
      "Epoch 73/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1811 - val_loss: 0.1704\n",
      "Epoch 74/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1822 - val_loss: 0.1700\n",
      "Epoch 75/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1810 - val_loss: 0.1700\n",
      "Epoch 76/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1812 - val_loss: 0.1695\n",
      "Epoch 77/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1809 - val_loss: 0.1681\n",
      "Epoch 78/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1810 - val_loss: 0.1684\n",
      "Epoch 79/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1800 - val_loss: 0.1700\n",
      "Epoch 80/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1804 - val_loss: 0.1696\n",
      "Epoch 81/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1790 - val_loss: 0.1675\n",
      "Epoch 82/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1806 - val_loss: 0.1679\n",
      "Epoch 83/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1817 - val_loss: 0.1688\n",
      "Epoch 84/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1791 - val_loss: 0.1717\n",
      "Epoch 85/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1798 - val_loss: 0.1692\n",
      "Epoch 86/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1787 - val_loss: 0.1676\n",
      "Epoch 87/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1812 - val_loss: 0.1677\n",
      "Epoch 88/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1802 - val_loss: 0.1691\n",
      "Epoch 89/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1831 - val_loss: 0.1693\n",
      "Epoch 90/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1781 - val_loss: 0.1671\n",
      "Epoch 91/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1779 - val_loss: 0.1675\n",
      "Epoch 92/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1810 - val_loss: 0.1698\n",
      "Epoch 93/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1803 - val_loss: 0.1682\n",
      "Epoch 94/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1769 - val_loss: 0.1678\n",
      "Epoch 95/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1793 - val_loss: 0.1675\n",
      "Epoch 96/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1796 - val_loss: 0.1652\n",
      "Epoch 97/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1745 - val_loss: 0.1668\n",
      "Epoch 98/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1756 - val_loss: 0.1694\n",
      "Epoch 99/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1782 - val_loss: 0.1658\n",
      "Epoch 100/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1759 - val_loss: 0.1646\n",
      "Epoch 101/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1759 - val_loss: 0.1651\n",
      "Epoch 102/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1747 - val_loss: 0.1656\n",
      "Epoch 103/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1740 - val_loss: 0.1659\n",
      "Epoch 104/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1739 - val_loss: 0.1647\n",
      "Epoch 105/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1742 - val_loss: 0.1649\n",
      "Epoch 106/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1745 - val_loss: 0.1655\n",
      "Epoch 107/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1738 - val_loss: 0.1635\n",
      "Epoch 108/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1720 - val_loss: 0.1634\n",
      "Epoch 109/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1716 - val_loss: 0.1665\n",
      "Epoch 110/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1719 - val_loss: 0.1650\n",
      "Epoch 111/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1716 - val_loss: 0.1617\n",
      "Epoch 112/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1711 - val_loss: 0.1623\n",
      "Epoch 113/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1722 - val_loss: 0.1638\n",
      "Epoch 114/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1702 - val_loss: 0.1627\n",
      "Epoch 115/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1705 - val_loss: 0.1610\n",
      "Epoch 116/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1717 - val_loss: 0.1604\n",
      "Epoch 117/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
      "Epoch 118/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1682 - val_loss: 0.1626\n",
      "Epoch 119/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1706 - val_loss: 0.1601\n",
      "Epoch 120/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1665 - val_loss: 0.1600\n",
      "Epoch 121/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1653 - val_loss: 0.1619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1688 - val_loss: 0.1614\n",
      "Epoch 123/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1673 - val_loss: 0.1590\n",
      "Epoch 124/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1642 - val_loss: 0.1601\n",
      "Epoch 125/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1654 - val_loss: 0.1591\n",
      "Epoch 126/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1635 - val_loss: 0.1589\n",
      "Epoch 127/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1641 - val_loss: 0.1627\n",
      "Epoch 128/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1660 - val_loss: 0.1593\n",
      "Epoch 129/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1652 - val_loss: 0.1608\n",
      "Epoch 130/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1671 - val_loss: 0.1600\n",
      "Epoch 131/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1655 - val_loss: 0.1561\n",
      "Epoch 132/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1632 - val_loss: 0.1596\n",
      "Epoch 133/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1646 - val_loss: 0.1611\n",
      "Epoch 134/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1674 - val_loss: 0.1574\n",
      "Epoch 135/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1638 - val_loss: 0.1558\n",
      "Epoch 136/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1613 - val_loss: 0.1577\n",
      "Epoch 137/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1622 - val_loss: 0.1570\n",
      "Epoch 138/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1644 - val_loss: 0.1553\n",
      "Epoch 139/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1655 - val_loss: 0.1558\n",
      "Epoch 140/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1649 - val_loss: 0.1553\n",
      "Epoch 141/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1596 - val_loss: 0.1526\n",
      "Epoch 142/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1609 - val_loss: 0.1552\n",
      "Epoch 143/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1661 - val_loss: 0.1537\n",
      "Epoch 144/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1587 - val_loss: 0.1535\n",
      "Epoch 145/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1628 - val_loss: 0.1530\n",
      "Epoch 146/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1588 - val_loss: 0.1517\n",
      "Epoch 147/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1588 - val_loss: 0.1528\n",
      "Epoch 148/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1574 - val_loss: 0.1518\n",
      "Epoch 149/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1592 - val_loss: 0.1500\n",
      "Epoch 150/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1596 - val_loss: 0.1499\n",
      "Epoch 151/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1602 - val_loss: 0.1505\n",
      "Epoch 152/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1598 - val_loss: 0.1498\n",
      "Epoch 153/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1575 - val_loss: 0.1509\n",
      "Epoch 154/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1580 - val_loss: 0.1507\n",
      "Epoch 155/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1577 - val_loss: 0.1472\n",
      "Epoch 156/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1563 - val_loss: 0.1466\n",
      "Epoch 157/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1550 - val_loss: 0.1503\n",
      "Epoch 158/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1592 - val_loss: 0.1478\n",
      "Epoch 159/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1564 - val_loss: 0.1518\n",
      "Epoch 160/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1588 - val_loss: 0.1477\n",
      "Epoch 161/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1565 - val_loss: 0.1466\n",
      "Epoch 162/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1558 - val_loss: 0.1488\n",
      "Epoch 163/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1515 - val_loss: 0.1491\n",
      "Epoch 164/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1548 - val_loss: 0.1476\n",
      "Epoch 165/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1556 - val_loss: 0.1450\n",
      "Epoch 166/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1539 - val_loss: 0.1479\n",
      "Epoch 167/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1541 - val_loss: 0.1467\n",
      "Epoch 168/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1571 - val_loss: 0.1445\n",
      "Epoch 169/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1528 - val_loss: 0.1453\n",
      "Epoch 170/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1504 - val_loss: 0.1452\n",
      "Epoch 171/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1526 - val_loss: 0.1463\n",
      "Epoch 172/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1543 - val_loss: 0.1449\n",
      "Epoch 173/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1548 - val_loss: 0.1437\n",
      "Epoch 174/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1519 - val_loss: 0.1428\n",
      "Epoch 175/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1495 - val_loss: 0.1437\n",
      "Epoch 176/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1509 - val_loss: 0.1412\n",
      "Epoch 177/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1474 - val_loss: 0.1404\n",
      "Epoch 178/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1458 - val_loss: 0.1434\n",
      "Epoch 179/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1503 - val_loss: 0.1440\n",
      "Epoch 180/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1479 - val_loss: 0.1464\n",
      "Epoch 181/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1546 - val_loss: 0.1513\n",
      "Epoch 182/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1559 - val_loss: 0.1402\n",
      "Epoch 183/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1491 - val_loss: 0.1376\n",
      "Epoch 184/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1442 - val_loss: 0.1421\n",
      "Epoch 185/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1463 - val_loss: 0.1386\n",
      "Epoch 186/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1438 - val_loss: 0.1380\n",
      "Epoch 187/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1429 - val_loss: 0.1409\n",
      "Epoch 188/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1456 - val_loss: 0.1371\n",
      "Epoch 189/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1441 - val_loss: 0.1378\n",
      "Epoch 190/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1431 - val_loss: 0.1389\n",
      "Epoch 191/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1448 - val_loss: 0.1341\n",
      "Epoch 192/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1443 - val_loss: 0.1376\n",
      "Epoch 193/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1409 - val_loss: 0.1354\n",
      "Epoch 194/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1423 - val_loss: 0.1356\n",
      "Epoch 195/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1417 - val_loss: 0.1388\n",
      "Epoch 196/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1439 - val_loss: 0.1323\n",
      "Epoch 197/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1373 - val_loss: 0.1316\n",
      "Epoch 198/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1398 - val_loss: 0.1367\n",
      "Epoch 199/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1380 - val_loss: 0.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1415 - val_loss: 0.1370\n",
      "Epoch 201/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1410 - val_loss: 0.1352\n",
      "Epoch 202/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1419 - val_loss: 0.1329\n",
      "Epoch 203/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1378 - val_loss: 0.1300\n",
      "Epoch 204/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1365 - val_loss: 0.1340\n",
      "Epoch 205/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1402 - val_loss: 0.1371\n",
      "Epoch 206/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1429 - val_loss: 0.1307\n",
      "Epoch 207/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1370 - val_loss: 0.1327\n",
      "Epoch 208/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1372 - val_loss: 0.1330\n",
      "Epoch 209/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1380 - val_loss: 0.1288\n",
      "Epoch 210/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1362 - val_loss: 0.1292\n",
      "Epoch 211/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1349 - val_loss: 0.1300\n",
      "Epoch 212/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1324 - val_loss: 0.1307\n",
      "Epoch 213/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1333 - val_loss: 0.1280\n",
      "Epoch 214/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1340 - val_loss: 0.1286\n",
      "Epoch 215/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1337 - val_loss: 0.1261\n",
      "Epoch 216/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1310 - val_loss: 0.1252\n",
      "Epoch 217/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1313 - val_loss: 0.1249\n",
      "Epoch 218/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1292 - val_loss: 0.1268\n",
      "Epoch 219/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1252\n",
      "Epoch 220/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1310 - val_loss: 0.1302\n",
      "Epoch 221/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1310 - val_loss: 0.1246\n",
      "Epoch 222/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1290 - val_loss: 0.1286\n",
      "Epoch 223/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1311 - val_loss: 0.1217\n",
      "Epoch 224/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1305 - val_loss: 0.1216\n",
      "Epoch 225/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1276 - val_loss: 0.1249\n",
      "Epoch 226/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1274 - val_loss: 0.1217\n",
      "Epoch 227/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1298 - val_loss: 0.1299\n",
      "Epoch 228/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1306 - val_loss: 0.1212\n",
      "Epoch 229/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1231 - val_loss: 0.1203\n",
      "Epoch 230/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1320 - val_loss: 0.1285\n",
      "Epoch 231/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1309 - val_loss: 0.1199\n",
      "Epoch 232/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1248 - val_loss: 0.1159\n",
      "Epoch 233/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1242 - val_loss: 0.1211\n",
      "Epoch 234/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1264 - val_loss: 0.1187\n",
      "Epoch 235/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1244 - val_loss: 0.1163\n",
      "Epoch 236/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1232 - val_loss: 0.1202\n",
      "Epoch 237/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1215 - val_loss: 0.1164\n",
      "Epoch 238/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1234 - val_loss: 0.1179\n",
      "Epoch 239/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1180 - val_loss: 0.1187\n",
      "Epoch 240/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1201 - val_loss: 0.1141\n",
      "Epoch 241/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1196 - val_loss: 0.1160\n",
      "Epoch 242/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1181 - val_loss: 0.1198\n",
      "Epoch 243/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1220 - val_loss: 0.1137\n",
      "Epoch 244/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1184 - val_loss: 0.1200\n",
      "Epoch 245/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1242 - val_loss: 0.1217\n",
      "Epoch 246/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1216 - val_loss: 0.1210\n",
      "Epoch 247/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1257 - val_loss: 0.1225\n",
      "Epoch 248/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1255 - val_loss: 0.1176\n",
      "Epoch 249/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1200 - val_loss: 0.1110\n",
      "Epoch 250/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1166 - val_loss: 0.1162\n",
      "Epoch 251/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1204 - val_loss: 0.1208\n",
      "Epoch 252/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1253 - val_loss: 0.1169\n",
      "Epoch 253/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1196 - val_loss: 0.1149\n",
      "Epoch 254/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1171 - val_loss: 0.1121\n",
      "Epoch 255/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1152 - val_loss: 0.1189\n",
      "Epoch 256/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1234 - val_loss: 0.1137\n",
      "Epoch 257/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1186 - val_loss: 0.1096\n",
      "Epoch 258/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1167 - val_loss: 0.1162\n",
      "Epoch 259/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1172 - val_loss: 0.1140\n",
      "Epoch 260/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1192 - val_loss: 0.1082\n",
      "Epoch 261/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1138 - val_loss: 0.1136\n",
      "Epoch 262/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1151 - val_loss: 0.1091\n",
      "Epoch 263/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1129 - val_loss: 0.1123\n",
      "Epoch 264/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1160 - val_loss: 0.1079\n",
      "Epoch 265/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1106 - val_loss: 0.1082\n",
      "Epoch 266/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1142 - val_loss: 0.1126\n",
      "Epoch 267/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1122 - val_loss: 0.1065\n",
      "Epoch 268/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1068 - val_loss: 0.1077\n",
      "Epoch 269/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1082 - val_loss: 0.1125\n",
      "Epoch 270/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1135 - val_loss: 0.1035\n",
      "Epoch 271/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1068 - val_loss: 0.1074\n",
      "Epoch 272/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1069 - val_loss: 0.1106\n",
      "Epoch 273/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1108 - val_loss: 0.1026\n",
      "Epoch 274/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1084 - val_loss: 0.1058\n",
      "Epoch 275/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1054 - val_loss: 0.1043\n",
      "Epoch 276/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1054 - val_loss: 0.1034\n",
      "Epoch 277/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1092 - val_loss: 0.1056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1061 - val_loss: 0.1049\n",
      "Epoch 279/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1049 - val_loss: 0.0991\n",
      "Epoch 280/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1053 - val_loss: 0.1073\n",
      "Epoch 281/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.1097 - val_loss: 0.1009\n",
      "Epoch 282/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1024 - val_loss: 0.0994\n",
      "Epoch 283/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0994 - val_loss: 0.1013\n",
      "Epoch 284/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0997 - val_loss: 0.1007\n",
      "Epoch 285/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1021 - val_loss: 0.1001\n",
      "Epoch 286/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1036 - val_loss: 0.0998\n",
      "Epoch 287/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1013 - val_loss: 0.0992\n",
      "Epoch 288/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1014 - val_loss: 0.1022\n",
      "Epoch 289/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1033 - val_loss: 0.1003\n",
      "Epoch 290/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1035 - val_loss: 0.0996\n",
      "Epoch 291/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1009 - val_loss: 0.0995\n",
      "Epoch 292/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1016 - val_loss: 0.0949\n",
      "Epoch 293/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0984 - val_loss: 0.1001\n",
      "Epoch 294/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0995 - val_loss: 0.0975\n",
      "Epoch 295/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1014 - val_loss: 0.0990\n",
      "Epoch 296/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1026 - val_loss: 0.0942\n",
      "Epoch 297/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0956 - val_loss: 0.0995\n",
      "Epoch 298/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1030 - val_loss: 0.1010\n",
      "Epoch 299/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1057 - val_loss: 0.1046\n",
      "Epoch 300/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1040 - val_loss: 0.0975\n",
      "Epoch 301/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1001 - val_loss: 0.0945\n",
      "Epoch 302/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0957 - val_loss: 0.0957\n",
      "Epoch 303/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0989 - val_loss: 0.0982\n",
      "Epoch 304/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.1001 - val_loss: 0.0970\n",
      "Epoch 305/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0983 - val_loss: 0.0942\n",
      "Epoch 306/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0979 - val_loss: 0.0927\n",
      "Epoch 307/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 308/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0928 - val_loss: 0.0947\n",
      "Epoch 309/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0963 - val_loss: 0.0961\n",
      "Epoch 310/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0965 - val_loss: 0.0930\n",
      "Epoch 311/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0961 - val_loss: 0.0908\n",
      "Epoch 312/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0950 - val_loss: 0.0942\n",
      "Epoch 313/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0946 - val_loss: 0.0883\n",
      "Epoch 314/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0944 - val_loss: 0.0949\n",
      "Epoch 315/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 316/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0952 - val_loss: 0.0867\n",
      "Epoch 317/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0949 - val_loss: 0.0963\n",
      "Epoch 318/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0923 - val_loss: 0.0857\n",
      "Epoch 319/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0907 - val_loss: 0.0859\n",
      "Epoch 320/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0911 - val_loss: 0.0923\n",
      "Epoch 321/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0924 - val_loss: 0.0872\n",
      "Epoch 322/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0933 - val_loss: 0.0907\n",
      "Epoch 323/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0918 - val_loss: 0.0890\n",
      "Epoch 324/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0921 - val_loss: 0.0891\n",
      "Epoch 325/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0948 - val_loss: 0.0862\n",
      "Epoch 326/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0884 - val_loss: 0.0893\n",
      "Epoch 327/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0875 - val_loss: 0.0829\n",
      "Epoch 328/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0900 - val_loss: 0.0862\n",
      "Epoch 329/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0863 - val_loss: 0.0843\n",
      "Epoch 330/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0856 - val_loss: 0.0835\n",
      "Epoch 331/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0868 - val_loss: 0.0868\n",
      "Epoch 332/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0880 - val_loss: 0.0835\n",
      "Epoch 333/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0868 - val_loss: 0.0852\n",
      "Epoch 334/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0855 - val_loss: 0.0873\n",
      "Epoch 335/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0874 - val_loss: 0.0825\n",
      "Epoch 336/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0886 - val_loss: 0.0892\n",
      "Epoch 337/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0891 - val_loss: 0.0848\n",
      "Epoch 338/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0865 - val_loss: 0.0825\n",
      "Epoch 339/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0839 - val_loss: 0.0839\n",
      "Epoch 340/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0839 - val_loss: 0.0831\n",
      "Epoch 341/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0831 - val_loss: 0.0860\n",
      "Epoch 342/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0882 - val_loss: 0.0864\n",
      "Epoch 343/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0881 - val_loss: 0.0816\n",
      "Epoch 344/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0842 - val_loss: 0.0812\n",
      "Epoch 345/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0821 - val_loss: 0.0798\n",
      "Epoch 346/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0840 - val_loss: 0.0850\n",
      "Epoch 347/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0871 - val_loss: 0.0799\n",
      "Epoch 348/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0846 - val_loss: 0.0827\n",
      "Epoch 349/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 350/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0863 - val_loss: 0.0790\n",
      "Epoch 351/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0835 - val_loss: 0.0808\n",
      "Epoch 352/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0805 - val_loss: 0.0777\n",
      "Epoch 353/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0816 - val_loss: 0.0804\n",
      "Epoch 354/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0809 - val_loss: 0.0754\n",
      "Epoch 355/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0803 - val_loss: 0.0819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0793 - val_loss: 0.0763\n",
      "Epoch 357/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0793 - val_loss: 0.0784\n",
      "Epoch 358/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0782 - val_loss: 0.0767\n",
      "Epoch 359/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0803 - val_loss: 0.0774\n",
      "Epoch 360/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0773 - val_loss: 0.0750\n",
      "Epoch 361/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0795 - val_loss: 0.0798\n",
      "Epoch 362/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0798 - val_loss: 0.0763\n",
      "Epoch 363/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0785 - val_loss: 0.0761\n",
      "Epoch 364/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0783 - val_loss: 0.0796\n",
      "Epoch 365/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0796 - val_loss: 0.0755\n",
      "Epoch 366/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0796 - val_loss: 0.0820\n",
      "Epoch 367/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0806 - val_loss: 0.0770\n",
      "Epoch 368/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0835 - val_loss: 0.0821\n",
      "Epoch 369/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0838 - val_loss: 0.0848\n",
      "Epoch 370/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0868 - val_loss: 0.0808\n",
      "Epoch 371/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0841 - val_loss: 0.0786\n",
      "Epoch 372/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0793 - val_loss: 0.0753\n",
      "Epoch 373/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0789 - val_loss: 0.0748\n",
      "Epoch 374/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0761 - val_loss: 0.0723\n",
      "Epoch 375/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0759 - val_loss: 0.0765\n",
      "Epoch 376/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0768 - val_loss: 0.0813\n",
      "Epoch 377/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0813 - val_loss: 0.0754\n",
      "Epoch 378/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0780 - val_loss: 0.0758\n",
      "Epoch 379/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0786 - val_loss: 0.0753\n",
      "Epoch 380/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0781 - val_loss: 0.0742\n",
      "Epoch 381/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0756 - val_loss: 0.0785\n",
      "Epoch 382/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0776 - val_loss: 0.0726\n",
      "Epoch 383/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0787 - val_loss: 0.0771\n",
      "Epoch 384/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0769 - val_loss: 0.0718\n",
      "Epoch 385/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0738 - val_loss: 0.0771\n",
      "Epoch 386/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0784 - val_loss: 0.0780\n",
      "Epoch 387/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0804 - val_loss: 0.0747\n",
      "Epoch 388/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0777 - val_loss: 0.0711\n",
      "Epoch 389/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0744 - val_loss: 0.0761\n",
      "Epoch 390/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0744 - val_loss: 0.0712\n",
      "Epoch 391/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0743 - val_loss: 0.0774\n",
      "Epoch 392/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0794 - val_loss: 0.0733\n",
      "Epoch 393/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0748 - val_loss: 0.0718\n",
      "Epoch 394/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0727 - val_loss: 0.0775\n",
      "Epoch 395/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0766 - val_loss: 0.0700\n",
      "Epoch 396/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0742 - val_loss: 0.0732\n",
      "Epoch 397/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0734 - val_loss: 0.0694\n",
      "Epoch 398/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0692 - val_loss: 0.0690\n",
      "Epoch 399/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0748 - val_loss: 0.0744\n",
      "Epoch 400/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0750 - val_loss: 0.0669\n",
      "Epoch 401/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0713 - val_loss: 0.0695\n",
      "Epoch 402/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0721 - val_loss: 0.0700\n",
      "Epoch 403/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0702 - val_loss: 0.0679\n",
      "Epoch 404/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0741 - val_loss: 0.0762\n",
      "Epoch 405/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0746 - val_loss: 0.0711\n",
      "Epoch 406/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0771 - val_loss: 0.0739\n",
      "Epoch 407/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0738 - val_loss: 0.0712\n",
      "Epoch 408/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0703 - val_loss: 0.0674\n",
      "Epoch 409/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0719 - val_loss: 0.0755\n",
      "Epoch 410/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0742 - val_loss: 0.0665\n",
      "Epoch 411/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0724 - val_loss: 0.0682\n",
      "Epoch 412/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0717 - val_loss: 0.0708\n",
      "Epoch 413/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0705 - val_loss: 0.0657\n",
      "Epoch 414/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0693 - val_loss: 0.0735\n",
      "Epoch 415/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0726 - val_loss: 0.0683\n",
      "Epoch 416/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0690 - val_loss: 0.0662\n",
      "Epoch 417/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0679 - val_loss: 0.0713\n",
      "Epoch 418/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0698 - val_loss: 0.0665\n",
      "Epoch 419/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0707 - val_loss: 0.0713\n",
      "Epoch 420/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0687 - val_loss: 0.0682\n",
      "Epoch 421/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0682 - val_loss: 0.0642\n",
      "Epoch 422/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0686 - val_loss: 0.0714\n",
      "Epoch 423/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0709 - val_loss: 0.0650\n",
      "Epoch 424/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0703 - val_loss: 0.0645\n",
      "Epoch 425/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0678 - val_loss: 0.0710\n",
      "Epoch 426/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0701 - val_loss: 0.0660\n",
      "Epoch 427/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0693 - val_loss: 0.0688\n",
      "Epoch 428/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0681 - val_loss: 0.0658\n",
      "Epoch 429/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0685 - val_loss: 0.0642\n",
      "Epoch 430/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0697 - val_loss: 0.0736\n",
      "Epoch 431/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0706 - val_loss: 0.0640\n",
      "Epoch 432/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0663 - val_loss: 0.0641\n",
      "Epoch 433/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0658 - val_loss: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0685 - val_loss: 0.0622\n",
      "Epoch 435/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0683 - val_loss: 0.0655\n",
      "Epoch 436/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0656 - val_loss: 0.0663\n",
      "Epoch 437/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0667 - val_loss: 0.0626\n",
      "Epoch 438/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0672 - val_loss: 0.0661\n",
      "Epoch 439/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0644 - val_loss: 0.0637\n",
      "Epoch 440/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0665 - val_loss: 0.0662\n",
      "Epoch 441/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0689 - val_loss: 0.0635\n",
      "Epoch 442/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0666 - val_loss: 0.0660\n",
      "Epoch 443/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0660 - val_loss: 0.0672\n",
      "Epoch 444/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0681 - val_loss: 0.0635\n",
      "Epoch 445/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0679 - val_loss: 0.0657\n",
      "Epoch 446/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0658 - val_loss: 0.0665\n",
      "Epoch 447/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0682 - val_loss: 0.0637\n",
      "Epoch 448/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0669 - val_loss: 0.0661\n",
      "Epoch 449/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0676 - val_loss: 0.0642\n",
      "Epoch 450/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0668 - val_loss: 0.0627\n",
      "Epoch 451/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0637 - val_loss: 0.0636\n",
      "Epoch 452/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0647 - val_loss: 0.0652\n",
      "Epoch 453/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0664 - val_loss: 0.0644\n",
      "Epoch 454/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0653 - val_loss: 0.0639\n",
      "Epoch 455/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0665 - val_loss: 0.0643\n",
      "Epoch 456/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0660 - val_loss: 0.0646\n",
      "Epoch 457/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0654 - val_loss: 0.0632\n",
      "Epoch 458/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0650 - val_loss: 0.0598\n",
      "Epoch 459/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0614 - val_loss: 0.0651\n",
      "Epoch 460/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0652 - val_loss: 0.0606\n",
      "Epoch 461/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0651 - val_loss: 0.0643\n",
      "Epoch 462/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0639 - val_loss: 0.0633\n",
      "Epoch 463/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0649 - val_loss: 0.0659\n",
      "Epoch 464/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0657 - val_loss: 0.0628\n",
      "Epoch 465/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0650 - val_loss: 0.0650\n",
      "Epoch 466/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0649 - val_loss: 0.0598\n",
      "Epoch 467/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0624 - val_loss: 0.0629\n",
      "Epoch 468/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 469/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0636 - val_loss: 0.0588\n",
      "Epoch 470/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0615 - val_loss: 0.0647\n",
      "Epoch 471/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0645 - val_loss: 0.0580\n",
      "Epoch 472/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0618 - val_loss: 0.0659\n",
      "Epoch 473/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0627 - val_loss: 0.0590\n",
      "Epoch 474/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0632 - val_loss: 0.0616\n",
      "Epoch 475/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0602 - val_loss: 0.0607\n",
      "Epoch 476/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0614 - val_loss: 0.0583\n",
      "Epoch 477/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0602 - val_loss: 0.0609\n",
      "Epoch 478/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0628 - val_loss: 0.0595\n",
      "Epoch 479/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0609 - val_loss: 0.0621\n",
      "Epoch 480/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0596 - val_loss: 0.0584\n",
      "Epoch 481/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0608 - val_loss: 0.0639\n",
      "Epoch 482/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0609 - val_loss: 0.0566\n",
      "Epoch 483/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 484/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0613 - val_loss: 0.0588\n",
      "Epoch 485/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0610 - val_loss: 0.0587\n",
      "Epoch 486/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0580 - val_loss: 0.0585\n",
      "Epoch 487/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0589\n",
      "Epoch 488/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0584 - val_loss: 0.0597\n",
      "Epoch 489/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0599 - val_loss: 0.0573\n",
      "Epoch 490/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0592 - val_loss: 0.0594\n",
      "Epoch 491/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0589 - val_loss: 0.0591\n",
      "Epoch 492/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0581\n",
      "Epoch 493/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0581 - val_loss: 0.0570\n",
      "Epoch 494/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0608 - val_loss: 0.0623\n",
      "Epoch 495/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0598 - val_loss: 0.0611\n",
      "Epoch 496/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0633 - val_loss: 0.0633\n",
      "Epoch 497/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0634 - val_loss: 0.0605\n",
      "Epoch 498/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0640 - val_loss: 0.0639\n",
      "Epoch 499/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0607 - val_loss: 0.0571\n",
      "Epoch 500/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0608 - val_loss: 0.0598\n",
      "Epoch 501/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0585 - val_loss: 0.0570\n",
      "Epoch 502/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 503/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0593 - val_loss: 0.0552\n",
      "Epoch 504/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0571 - val_loss: 0.0585\n",
      "Epoch 505/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0593 - val_loss: 0.0583\n",
      "Epoch 506/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0581 - val_loss: 0.0556\n",
      "Epoch 507/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0583 - val_loss: 0.0604\n",
      "Epoch 508/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0572 - val_loss: 0.0555\n",
      "Epoch 509/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0592 - val_loss: 0.0626\n",
      "Epoch 510/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0601 - val_loss: 0.0547\n",
      "Epoch 511/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0576 - val_loss: 0.0590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 512/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0596 - val_loss: 0.0582\n",
      "Epoch 513/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0572 - val_loss: 0.0567\n",
      "Epoch 514/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0596 - val_loss: 0.0627\n",
      "Epoch 515/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0597 - val_loss: 0.0564\n",
      "Epoch 516/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0558 - val_loss: 0.0557\n",
      "Epoch 517/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0562 - val_loss: 0.0585\n",
      "Epoch 518/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0567 - val_loss: 0.0553\n",
      "Epoch 519/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0586 - val_loss: 0.0602\n",
      "Epoch 520/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0568 - val_loss: 0.0552\n",
      "Epoch 521/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0555 - val_loss: 0.0586\n",
      "Epoch 522/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0566 - val_loss: 0.0563\n",
      "Epoch 523/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0558 - val_loss: 0.0574\n",
      "Epoch 524/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0573 - val_loss: 0.0580\n",
      "Epoch 525/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0580 - val_loss: 0.0599\n",
      "Epoch 526/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0596 - val_loss: 0.0551\n",
      "Epoch 527/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0562 - val_loss: 0.0594\n",
      "Epoch 528/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0539\n",
      "Epoch 529/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0597 - val_loss: 0.0602\n",
      "Epoch 530/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0573 - val_loss: 0.0549\n",
      "Epoch 531/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0555 - val_loss: 0.0549\n",
      "Epoch 532/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0551 - val_loss: 0.0591\n",
      "Epoch 533/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0596 - val_loss: 0.0539\n",
      "Epoch 534/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0566 - val_loss: 0.0568\n",
      "Epoch 535/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0572 - val_loss: 0.0530\n",
      "Epoch 536/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0556 - val_loss: 0.0577\n",
      "Epoch 537/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0555 - val_loss: 0.0536\n",
      "Epoch 538/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0561 - val_loss: 0.0549\n",
      "Epoch 539/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0536\n",
      "Epoch 540/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0534\n",
      "Epoch 541/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0534 - val_loss: 0.0529\n",
      "Epoch 542/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0540 - val_loss: 0.0578\n",
      "Epoch 543/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0543 - val_loss: 0.0540\n",
      "Epoch 544/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0583 - val_loss: 0.0596\n",
      "Epoch 545/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0575 - val_loss: 0.0576\n",
      "Epoch 546/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0577 - val_loss: 0.0582\n",
      "Epoch 547/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0567 - val_loss: 0.0556\n",
      "Epoch 548/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0552 - val_loss: 0.0541\n",
      "Epoch 549/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0539 - val_loss: 0.0567\n",
      "Epoch 550/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0564 - val_loss: 0.0546\n",
      "Epoch 551/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0554 - val_loss: 0.0597\n",
      "Epoch 552/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0590 - val_loss: 0.0541\n",
      "Epoch 553/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0559 - val_loss: 0.0563\n",
      "Epoch 554/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0554 - val_loss: 0.0519\n",
      "Epoch 555/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0536 - val_loss: 0.0538\n",
      "Epoch 556/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0532 - val_loss: 0.0545\n",
      "Epoch 557/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0558\n",
      "Epoch 558/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0540 - val_loss: 0.0527\n",
      "Epoch 559/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0553 - val_loss: 0.0526\n",
      "Epoch 560/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0546 - val_loss: 0.0551\n",
      "Epoch 561/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0518 - val_loss: 0.0515\n",
      "Epoch 562/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0546 - val_loss: 0.0526\n",
      "Epoch 563/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0531 - val_loss: 0.0546\n",
      "Epoch 564/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0543 - val_loss: 0.0520\n",
      "Epoch 565/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0519 - val_loss: 0.0549\n",
      "Epoch 566/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0514 - val_loss: 0.0524\n",
      "Epoch 567/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0533 - val_loss: 0.0553\n",
      "Epoch 568/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0535 - val_loss: 0.0525\n",
      "Epoch 569/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0534 - val_loss: 0.0526\n",
      "Epoch 570/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0522 - val_loss: 0.0577\n",
      "Epoch 571/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0557 - val_loss: 0.0549\n",
      "Epoch 572/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0558 - val_loss: 0.0534\n",
      "Epoch 573/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0557 - val_loss: 0.0556\n",
      "Epoch 574/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0529 - val_loss: 0.0533\n",
      "Epoch 575/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0539 - val_loss: 0.0542\n",
      "Epoch 576/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0512 - val_loss: 0.0511\n",
      "Epoch 577/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0523 - val_loss: 0.0523\n",
      "Epoch 578/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0505 - val_loss: 0.0539\n",
      "Epoch 579/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0522 - val_loss: 0.0509\n",
      "Epoch 580/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0542 - val_loss: 0.0557\n",
      "Epoch 581/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0549 - val_loss: 0.0526\n",
      "Epoch 582/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0509 - val_loss: 0.0498\n",
      "Epoch 583/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0532 - val_loss: 0.0597\n",
      "Epoch 584/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0563 - val_loss: 0.0490\n",
      "Epoch 585/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0509 - val_loss: 0.0508\n",
      "Epoch 586/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0504 - val_loss: 0.0562\n",
      "Epoch 587/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0509 - val_loss: 0.0492\n",
      "Epoch 588/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0533 - val_loss: 0.0549\n",
      "Epoch 589/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0535 - val_loss: 0.0516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0503 - val_loss: 0.0486\n",
      "Epoch 591/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0513 - val_loss: 0.0544\n",
      "Epoch 592/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0517 - val_loss: 0.0498\n",
      "Epoch 593/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0518 - val_loss: 0.0505\n",
      "Epoch 594/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0508\n",
      "Epoch 595/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0497 - val_loss: 0.0523\n",
      "Epoch 596/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0510 - val_loss: 0.0527\n",
      "Epoch 597/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0511\n",
      "Epoch 598/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0504 - val_loss: 0.0498\n",
      "Epoch 599/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0494 - val_loss: 0.0516\n",
      "Epoch 600/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0513 - val_loss: 0.0496\n",
      "Epoch 601/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0509 - val_loss: 0.0527\n",
      "Epoch 602/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0490 - val_loss: 0.0473\n",
      "Epoch 603/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0482 - val_loss: 0.0518\n",
      "Epoch 604/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0489 - val_loss: 0.0491\n",
      "Epoch 605/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0499 - val_loss: 0.0476\n",
      "Epoch 606/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0470 - val_loss: 0.0543\n",
      "Epoch 607/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 608/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0530 - val_loss: 0.0528\n",
      "Epoch 609/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0503 - val_loss: 0.0485\n",
      "Epoch 610/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0470 - val_loss: 0.0485\n",
      "Epoch 611/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0469 - val_loss: 0.0496\n",
      "Epoch 612/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0472 - val_loss: 0.0472\n",
      "Epoch 613/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0476 - val_loss: 0.0496\n",
      "Epoch 614/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0492 - val_loss: 0.0533\n",
      "Epoch 615/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0501 - val_loss: 0.0517\n",
      "Epoch 616/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0531 - val_loss: 0.0524\n",
      "Epoch 617/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0489 - val_loss: 0.0476\n",
      "Epoch 618/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0490 - val_loss: 0.0492\n",
      "Epoch 619/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0468 - val_loss: 0.0470\n",
      "Epoch 620/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0458 - val_loss: 0.0482\n",
      "Epoch 621/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0468 - val_loss: 0.0473\n",
      "Epoch 622/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0472 - val_loss: 0.0480\n",
      "Epoch 623/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0480 - val_loss: 0.0479\n",
      "Epoch 624/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0473 - val_loss: 0.0505\n",
      "Epoch 625/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0481 - val_loss: 0.0469\n",
      "Epoch 626/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0486 - val_loss: 0.0538\n",
      "Epoch 627/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0497 - val_loss: 0.0464\n",
      "Epoch 628/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0468 - val_loss: 0.0504\n",
      "Epoch 629/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 630/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0490 - val_loss: 0.0514\n",
      "Epoch 631/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0495 - val_loss: 0.0533\n",
      "Epoch 632/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0527 - val_loss: 0.0505\n",
      "Epoch 633/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0488 - val_loss: 0.0469\n",
      "Epoch 634/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0475 - val_loss: 0.0508\n",
      "Epoch 635/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0474 - val_loss: 0.0474\n",
      "Epoch 636/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0489 - val_loss: 0.0498\n",
      "Epoch 637/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0498 - val_loss: 0.0535\n",
      "Epoch 638/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0508 - val_loss: 0.0475\n",
      "Epoch 639/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0493 - val_loss: 0.0483\n",
      "Epoch 640/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0471 - val_loss: 0.0481\n",
      "Epoch 641/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0472 - val_loss: 0.0464\n",
      "Epoch 642/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0457 - val_loss: 0.0483\n",
      "Epoch 643/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0454 - val_loss: 0.0470\n",
      "Epoch 644/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0468 - val_loss: 0.0487\n",
      "Epoch 645/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0453 - val_loss: 0.0486\n",
      "Epoch 646/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0488 - val_loss: 0.0511\n",
      "Epoch 647/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0502 - val_loss: 0.0478\n",
      "Epoch 648/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0506\n",
      "Epoch 649/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0469 - val_loss: 0.0495\n",
      "Epoch 650/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0466 - val_loss: 0.0458\n",
      "Epoch 651/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0463 - val_loss: 0.0541\n",
      "Epoch 652/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0486 - val_loss: 0.0459\n",
      "Epoch 653/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0484 - val_loss: 0.0489\n",
      "Epoch 654/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0474 - val_loss: 0.0479\n",
      "Epoch 655/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0455\n",
      "Epoch 656/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0457 - val_loss: 0.0530\n",
      "Epoch 657/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0462 - val_loss: 0.0455\n",
      "Epoch 658/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0467 - val_loss: 0.0494\n",
      "Epoch 659/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0456 - val_loss: 0.0456\n",
      "Epoch 660/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0447 - val_loss: 0.0465\n",
      "Epoch 661/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0448 - val_loss: 0.0451\n",
      "Epoch 662/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0455 - val_loss: 0.0479\n",
      "Epoch 663/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0446 - val_loss: 0.0448\n",
      "Epoch 664/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0449 - val_loss: 0.0504\n",
      "Epoch 665/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0458 - val_loss: 0.0451\n",
      "Epoch 666/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0452 - val_loss: 0.0497\n",
      "Epoch 667/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0464 - val_loss: 0.0451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 668/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0467 - val_loss: 0.0471\n",
      "Epoch 669/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0438 - val_loss: 0.0471\n",
      "Epoch 670/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0442 - val_loss: 0.0460\n",
      "Epoch 671/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0452 - val_loss: 0.0485\n",
      "Epoch 672/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0459 - val_loss: 0.0476\n",
      "Epoch 673/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0485 - val_loss: 0.0486\n",
      "Epoch 674/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0460 - val_loss: 0.0471\n",
      "Epoch 675/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0456 - val_loss: 0.0464\n",
      "Epoch 676/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0449 - val_loss: 0.0528\n",
      "Epoch 677/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0472\n",
      "Epoch 678/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0484 - val_loss: 0.0494\n",
      "Epoch 679/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0468 - val_loss: 0.0474\n",
      "Epoch 680/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0445 - val_loss: 0.0456\n",
      "Epoch 681/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0474 - val_loss: 0.0522\n",
      "Epoch 682/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0471 - val_loss: 0.0462\n",
      "Epoch 683/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0465\n",
      "Epoch 684/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0441 - val_loss: 0.0466\n",
      "Epoch 685/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0456\n",
      "Epoch 686/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0436 - val_loss: 0.0485\n",
      "Epoch 687/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0429 - val_loss: 0.0442\n",
      "Epoch 688/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0442 - val_loss: 0.0473\n",
      "Epoch 689/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0458 - val_loss: 0.0489\n",
      "Epoch 690/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0461 - val_loss: 0.0493\n",
      "Epoch 691/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0470 - val_loss: 0.0472\n",
      "Epoch 692/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0455 - val_loss: 0.0452\n",
      "Epoch 693/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0441 - val_loss: 0.0466\n",
      "Epoch 694/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0463\n",
      "Epoch 695/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0444 - val_loss: 0.0475\n",
      "Epoch 696/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0450 - val_loss: 0.0490\n",
      "Epoch 697/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0476 - val_loss: 0.0463\n",
      "Epoch 698/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0496\n",
      "Epoch 699/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0447 - val_loss: 0.0432\n",
      "Epoch 700/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0476\n",
      "Epoch 701/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0431 - val_loss: 0.0442\n",
      "Epoch 702/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0434 - val_loss: 0.0481\n",
      "Epoch 703/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0445 - val_loss: 0.0480\n",
      "Epoch 704/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0473\n",
      "Epoch 705/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0451 - val_loss: 0.0464\n",
      "Epoch 706/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0422 - val_loss: 0.0460\n",
      "Epoch 707/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0456\n",
      "Epoch 708/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0440\n",
      "Epoch 709/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0416 - val_loss: 0.0456\n",
      "Epoch 710/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0414 - val_loss: 0.0443\n",
      "Epoch 711/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0451\n",
      "Epoch 712/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0432 - val_loss: 0.0464\n",
      "Epoch 713/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0440 - val_loss: 0.0488\n",
      "Epoch 714/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0443 - val_loss: 0.0442\n",
      "Epoch 715/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0483\n",
      "Epoch 716/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0422 - val_loss: 0.0443\n",
      "Epoch 717/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0417 - val_loss: 0.0450\n",
      "Epoch 718/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0459\n",
      "Epoch 719/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0475\n",
      "Epoch 720/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0452 - val_loss: 0.0493\n",
      "Epoch 721/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0438 - val_loss: 0.0459\n",
      "Epoch 722/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0425 - val_loss: 0.0448\n",
      "Epoch 723/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0405 - val_loss: 0.0471\n",
      "Epoch 724/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0410 - val_loss: 0.0431\n",
      "Epoch 725/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0417 - val_loss: 0.0513\n",
      "Epoch 726/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0432 - val_loss: 0.0437\n",
      "Epoch 727/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0423 - val_loss: 0.0450\n",
      "Epoch 728/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0465\n",
      "Epoch 729/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0437\n",
      "Epoch 730/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0482\n",
      "Epoch 731/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0441 - val_loss: 0.0433\n",
      "Epoch 732/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0430 - val_loss: 0.0469\n",
      "Epoch 733/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0437\n",
      "Epoch 734/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0434 - val_loss: 0.0469\n",
      "Epoch 735/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0446 - val_loss: 0.0451\n",
      "Epoch 736/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0418 - val_loss: 0.0431\n",
      "Epoch 737/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0414 - val_loss: 0.0442\n",
      "Epoch 738/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0393 - val_loss: 0.0453\n",
      "Epoch 739/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0408 - val_loss: 0.0418\n",
      "Epoch 740/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0402 - val_loss: 0.0497\n",
      "Epoch 741/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0416 - val_loss: 0.0426\n",
      "Epoch 742/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0429 - val_loss: 0.0470\n",
      "Epoch 743/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0405 - val_loss: 0.0441\n",
      "Epoch 744/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0436\n",
      "Epoch 745/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0409 - val_loss: 0.0471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 746/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0405 - val_loss: 0.0433\n",
      "Epoch 747/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0411 - val_loss: 0.0460\n",
      "Epoch 748/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0414 - val_loss: 0.0437\n",
      "Epoch 749/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0410 - val_loss: 0.0432\n",
      "Epoch 750/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0402 - val_loss: 0.0441\n",
      "Epoch 751/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0399 - val_loss: 0.0442\n",
      "Epoch 752/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0412 - val_loss: 0.0474\n",
      "Epoch 753/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0417 - val_loss: 0.0417\n",
      "Epoch 754/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0411 - val_loss: 0.0500\n",
      "Epoch 755/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0421\n",
      "Epoch 756/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0411 - val_loss: 0.0456\n",
      "Epoch 757/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0412 - val_loss: 0.0438\n",
      "Epoch 758/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0406 - val_loss: 0.0437\n",
      "Epoch 759/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0402 - val_loss: 0.0455\n",
      "Epoch 760/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0401 - val_loss: 0.0415\n",
      "Epoch 761/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0410 - val_loss: 0.0470\n",
      "Epoch 762/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0408 - val_loss: 0.0428\n",
      "Epoch 763/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0414 - val_loss: 0.0478\n",
      "Epoch 764/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0415 - val_loss: 0.0470\n",
      "Epoch 765/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0429\n",
      "Epoch 766/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0408 - val_loss: 0.0470\n",
      "Epoch 767/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0405 - val_loss: 0.0423\n",
      "Epoch 768/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0403 - val_loss: 0.0453\n",
      "Epoch 769/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0425 - val_loss: 0.0493\n",
      "Epoch 770/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0436 - val_loss: 0.0440\n",
      "Epoch 771/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0440\n",
      "Epoch 772/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0412 - val_loss: 0.0480\n",
      "Epoch 773/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0432\n",
      "Epoch 774/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0432 - val_loss: 0.0485\n",
      "Epoch 775/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0429 - val_loss: 0.0445\n",
      "Epoch 776/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0417 - val_loss: 0.0427\n",
      "Epoch 777/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0409 - val_loss: 0.0455\n",
      "Epoch 778/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0439\n",
      "Epoch 779/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0409 - val_loss: 0.0437\n",
      "Epoch 780/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0413 - val_loss: 0.0470\n",
      "Epoch 781/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0409 - val_loss: 0.0431\n",
      "Epoch 782/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0447\n",
      "Epoch 783/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0399 - val_loss: 0.0479\n",
      "Epoch 784/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0409 - val_loss: 0.0454\n",
      "Epoch 785/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0428 - val_loss: 0.0450\n",
      "Epoch 786/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0391 - val_loss: 0.0449\n",
      "Epoch 787/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0398 - val_loss: 0.0462\n",
      "Epoch 788/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0407 - val_loss: 0.0452\n",
      "Epoch 789/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0442 - val_loss: 0.0459\n",
      "Epoch 790/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0440\n",
      "Epoch 791/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0395 - val_loss: 0.0471\n",
      "Epoch 792/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0443\n",
      "Epoch 793/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0422\n",
      "Epoch 794/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0403 - val_loss: 0.0495\n",
      "Epoch 795/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0420\n",
      "Epoch 796/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0404 - val_loss: 0.0455\n",
      "Epoch 797/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0399 - val_loss: 0.0418\n",
      "Epoch 798/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0373 - val_loss: 0.0433\n",
      "Epoch 799/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0400 - val_loss: 0.0459\n",
      "Epoch 800/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0418 - val_loss: 0.0438\n",
      "Epoch 801/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0401 - val_loss: 0.0435\n",
      "Epoch 802/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0438\n",
      "Epoch 803/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0390 - val_loss: 0.0425\n",
      "Epoch 804/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0388 - val_loss: 0.0425\n",
      "Epoch 805/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0388 - val_loss: 0.0439\n",
      "Epoch 806/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0417\n",
      "Epoch 807/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0438\n",
      "Epoch 808/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0416\n",
      "Epoch 809/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0372 - val_loss: 0.0448\n",
      "Epoch 810/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0379 - val_loss: 0.0400\n",
      "Epoch 811/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0374 - val_loss: 0.0415\n",
      "Epoch 812/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0373 - val_loss: 0.0423\n",
      "Epoch 813/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0415\n",
      "Epoch 814/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0378 - val_loss: 0.0445\n",
      "Epoch 815/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0383 - val_loss: 0.0404\n",
      "Epoch 816/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0455\n",
      "Epoch 817/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0387 - val_loss: 0.0410\n",
      "Epoch 818/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0386 - val_loss: 0.0442\n",
      "Epoch 819/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0408\n",
      "Epoch 820/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0382 - val_loss: 0.0436\n",
      "Epoch 821/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0426\n",
      "Epoch 822/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0394 - val_loss: 0.0442\n",
      "Epoch 823/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0378 - val_loss: 0.0424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0385 - val_loss: 0.0438\n",
      "Epoch 825/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0371 - val_loss: 0.0409\n",
      "Epoch 826/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0440\n",
      "Epoch 827/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0379 - val_loss: 0.0414\n",
      "Epoch 828/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0380 - val_loss: 0.0440\n",
      "Epoch 829/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0400\n",
      "Epoch 830/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0372 - val_loss: 0.0441\n",
      "Epoch 831/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0389 - val_loss: 0.0413\n",
      "Epoch 832/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0368 - val_loss: 0.0441\n",
      "Epoch 833/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0387 - val_loss: 0.0435\n",
      "Epoch 834/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0423\n",
      "Epoch 835/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0390 - val_loss: 0.0428\n",
      "Epoch 836/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0372 - val_loss: 0.0416\n",
      "Epoch 837/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0363 - val_loss: 0.0408\n",
      "Epoch 838/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0361 - val_loss: 0.0419\n",
      "Epoch 839/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0350 - val_loss: 0.0398\n",
      "Epoch 840/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0373 - val_loss: 0.0460\n",
      "Epoch 841/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0387 - val_loss: 0.0394\n",
      "Epoch 842/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0385 - val_loss: 0.0461\n",
      "Epoch 843/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0409\n",
      "Epoch 844/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0382 - val_loss: 0.0444\n",
      "Epoch 845/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0380 - val_loss: 0.0413\n",
      "Epoch 846/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0351 - val_loss: 0.0411\n",
      "Epoch 847/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0360 - val_loss: 0.0440\n",
      "Epoch 848/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0379 - val_loss: 0.0432\n",
      "Epoch 849/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0413\n",
      "Epoch 850/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0371 - val_loss: 0.0440\n",
      "Epoch 851/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0370 - val_loss: 0.0406\n",
      "Epoch 852/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0440\n",
      "Epoch 853/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0396\n",
      "Epoch 854/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0362 - val_loss: 0.0440\n",
      "Epoch 855/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0400\n",
      "Epoch 856/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0378 - val_loss: 0.0441\n",
      "Epoch 857/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0403\n",
      "Epoch 858/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0435\n",
      "Epoch 859/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0361 - val_loss: 0.0417\n",
      "Epoch 860/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0366 - val_loss: 0.0437\n",
      "Epoch 861/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0387 - val_loss: 0.0428\n",
      "Epoch 862/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0392 - val_loss: 0.0443\n",
      "Epoch 863/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0391 - val_loss: 0.0404\n",
      "Epoch 864/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0363 - val_loss: 0.0423\n",
      "Epoch 865/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0367 - val_loss: 0.0411\n",
      "Epoch 866/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0425\n",
      "Epoch 867/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0382 - val_loss: 0.0461\n",
      "Epoch 868/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0417\n",
      "Epoch 869/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0436\n",
      "Epoch 870/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0365 - val_loss: 0.0413\n",
      "Epoch 871/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0347 - val_loss: 0.0405\n",
      "Epoch 872/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0365 - val_loss: 0.0470\n",
      "Epoch 873/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0399\n",
      "Epoch 874/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0364 - val_loss: 0.0432\n",
      "Epoch 875/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0357 - val_loss: 0.0429\n",
      "Epoch 876/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0353 - val_loss: 0.0415\n",
      "Epoch 877/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0368 - val_loss: 0.0448\n",
      "Epoch 878/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0384 - val_loss: 0.0432\n",
      "Epoch 879/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0383 - val_loss: 0.0418\n",
      "Epoch 880/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0355 - val_loss: 0.0417\n",
      "Epoch 881/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0352 - val_loss: 0.0407\n",
      "Epoch 882/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0360 - val_loss: 0.0453\n",
      "Epoch 883/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0379 - val_loss: 0.0391\n",
      "Epoch 884/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0376 - val_loss: 0.0427\n",
      "Epoch 885/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0358 - val_loss: 0.0404\n",
      "Epoch 886/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0353 - val_loss: 0.0415\n",
      "Epoch 887/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0343 - val_loss: 0.0436\n",
      "Epoch 888/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0376 - val_loss: 0.0417\n",
      "Epoch 889/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0455\n",
      "Epoch 890/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0373 - val_loss: 0.0420\n",
      "Epoch 891/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 892/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0416\n",
      "Epoch 893/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0354 - val_loss: 0.0431\n",
      "Epoch 894/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0379 - val_loss: 0.0429\n",
      "Epoch 895/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0381 - val_loss: 0.0421\n",
      "Epoch 896/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0364 - val_loss: 0.0417\n",
      "Epoch 897/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0343 - val_loss: 0.0391\n",
      "Epoch 898/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0345 - val_loss: 0.0447\n",
      "Epoch 899/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 900/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0364 - val_loss: 0.0457\n",
      "Epoch 901/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0350 - val_loss: 0.0383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 902/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0361 - val_loss: 0.0445\n",
      "Epoch 903/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0358 - val_loss: 0.0397\n",
      "Epoch 904/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0348 - val_loss: 0.0398\n",
      "Epoch 905/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0356 - val_loss: 0.0439\n",
      "Epoch 906/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0359 - val_loss: 0.0378\n",
      "Epoch 907/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0451\n",
      "Epoch 908/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0358 - val_loss: 0.0380\n",
      "Epoch 909/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0333 - val_loss: 0.0402\n",
      "Epoch 910/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0343 - val_loss: 0.0437\n",
      "Epoch 911/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0356 - val_loss: 0.0383\n",
      "Epoch 912/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0368 - val_loss: 0.0439\n",
      "Epoch 913/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0350 - val_loss: 0.0376\n",
      "Epoch 914/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0338 - val_loss: 0.0433\n",
      "Epoch 915/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0395\n",
      "Epoch 916/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0349 - val_loss: 0.0420\n",
      "Epoch 917/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0347 - val_loss: 0.0394\n",
      "Epoch 918/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0351 - val_loss: 0.0421\n",
      "Epoch 919/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0349 - val_loss: 0.0390\n",
      "Epoch 920/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0344 - val_loss: 0.0403\n",
      "Epoch 921/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0330 - val_loss: 0.0404\n",
      "Epoch 922/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0342 - val_loss: 0.0409\n",
      "Epoch 923/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0335 - val_loss: 0.0418\n",
      "Epoch 924/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0371 - val_loss: 0.0419\n",
      "Epoch 925/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0366 - val_loss: 0.0423\n",
      "Epoch 926/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0340 - val_loss: 0.0387\n",
      "Epoch 927/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0352 - val_loss: 0.0461\n",
      "Epoch 928/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0413\n",
      "Epoch 929/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0366 - val_loss: 0.0404\n",
      "Epoch 930/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0405\n",
      "Epoch 931/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0337 - val_loss: 0.0393\n",
      "Epoch 932/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0322 - val_loss: 0.0423\n",
      "Epoch 933/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0337 - val_loss: 0.0389\n",
      "Epoch 934/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0344 - val_loss: 0.0446\n",
      "Epoch 935/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0350 - val_loss: 0.0368\n",
      "Epoch 936/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0346 - val_loss: 0.0436\n",
      "Epoch 937/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0393\n",
      "Epoch 938/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0337 - val_loss: 0.0413\n",
      "Epoch 939/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0345 - val_loss: 0.0410\n",
      "Epoch 940/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0340 - val_loss: 0.0404\n",
      "Epoch 941/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0345 - val_loss: 0.0413\n",
      "Epoch 942/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0343 - val_loss: 0.0413\n",
      "Epoch 943/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0327 - val_loss: 0.0376\n",
      "Epoch 944/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0344 - val_loss: 0.0432\n",
      "Epoch 945/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0341 - val_loss: 0.0390\n",
      "Epoch 946/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0431\n",
      "Epoch 947/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0337 - val_loss: 0.0376\n",
      "Epoch 948/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0334 - val_loss: 0.0421\n",
      "Epoch 949/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0376\n",
      "Epoch 950/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0414\n",
      "Epoch 951/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0385\n",
      "Epoch 952/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0323 - val_loss: 0.0408\n",
      "Epoch 953/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0325 - val_loss: 0.0385\n",
      "Epoch 954/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0324 - val_loss: 0.0430\n",
      "Epoch 955/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0332 - val_loss: 0.0387\n",
      "Epoch 956/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0342 - val_loss: 0.0434\n",
      "Epoch 957/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0345 - val_loss: 0.0383\n",
      "Epoch 958/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0331 - val_loss: 0.0402\n",
      "Epoch 959/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0339 - val_loss: 0.0402\n",
      "Epoch 960/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0326 - val_loss: 0.0416\n",
      "Epoch 961/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0370 - val_loss: 0.0450\n",
      "Epoch 962/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0375 - val_loss: 0.0415\n",
      "Epoch 963/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0349 - val_loss: 0.0404\n",
      "Epoch 964/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0338 - val_loss: 0.0437\n",
      "Epoch 965/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0346 - val_loss: 0.0386\n",
      "Epoch 966/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0354 - val_loss: 0.0446\n",
      "Epoch 967/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0342 - val_loss: 0.0383\n",
      "Epoch 968/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0336 - val_loss: 0.0401\n",
      "Epoch 969/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0322 - val_loss: 0.0398\n",
      "Epoch 970/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0322 - val_loss: 0.0400\n",
      "Epoch 971/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0323 - val_loss: 0.0389\n",
      "Epoch 972/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0312 - val_loss: 0.0411\n",
      "Epoch 973/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0335 - val_loss: 0.0425\n",
      "Epoch 974/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0348 - val_loss: 0.0397\n",
      "Epoch 975/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0347 - val_loss: 0.0414\n",
      "Epoch 976/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0333 - val_loss: 0.0402\n",
      "Epoch 977/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0342 - val_loss: 0.0397\n",
      "Epoch 978/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0414\n",
      "Epoch 979/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0344 - val_loss: 0.0401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 980/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0326 - val_loss: 0.0393\n",
      "Epoch 981/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0323 - val_loss: 0.0431\n",
      "Epoch 982/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0324 - val_loss: 0.0362\n",
      "Epoch 983/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0326 - val_loss: 0.0454\n",
      "Epoch 984/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0356 - val_loss: 0.0396\n",
      "Epoch 985/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0347 - val_loss: 0.0400\n",
      "Epoch 986/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0345 - val_loss: 0.0458\n",
      "Epoch 987/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0355 - val_loss: 0.0385\n",
      "Epoch 988/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0329 - val_loss: 0.0400\n",
      "Epoch 989/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0336 - val_loss: 0.0496\n",
      "Epoch 990/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0388 - val_loss: 0.0397\n",
      "Epoch 991/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0337 - val_loss: 0.0385\n",
      "Epoch 992/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0334 - val_loss: 0.0448\n",
      "Epoch 993/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0346 - val_loss: 0.0405\n",
      "Epoch 994/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0356 - val_loss: 0.0416\n",
      "Epoch 995/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0353 - val_loss: 0.0411\n",
      "Epoch 996/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0330 - val_loss: 0.0387\n",
      "Epoch 997/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0335 - val_loss: 0.0445\n",
      "Epoch 998/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0345 - val_loss: 0.0405\n",
      "Epoch 999/1000\n",
      "3298/3298 [==============================] - 3s 1ms/step - loss: 0.0331 - val_loss: 0.0390\n",
      "Epoch 1000/1000\n",
      "3298/3298 [==============================] - 4s 1ms/step - loss: 0.0326 - val_loss: 0.0458\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create our cross validation data structure\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(processed_data['x'], processed_data['y'],\n",
    "                                                                    test_size = 0.2)\n",
    "\n",
    "# Train for wind intensity\n",
    "y_train_wind = np.array([[[features[2]] for features in y] for y in y_train], dtype = np.float64)\n",
    "y_test_wind = np.array([[[features[2]] for features in y] for y in y_test], dtype = np.float64)\n",
    "\n",
    "# Train for latitude and longitude location\n",
    "y_train_lat = np.array([[[features[0]] for features in y] for y in y_train], dtype = np.float64)\n",
    "y_test_lat = np.array([[[features[0]] for features in y] for y in y_test], dtype = np.float64)\n",
    "y_train_long = np.array([[[features[1]] for features in y] for y in y_train], dtype = np.float64)\n",
    "y_test_long = np.array([[[features[1]] for features in y] for y in y_test], dtype = np.float64)\n",
    "\n",
    "\n",
    "def bd_lstm_td(X_train, y_train, X_test, y_test, n_epochs = 500) :    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = 1024, return_sequences = True, dropout = 0.05),\n",
    "                            input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "    model.add(LSTM(units = 512, return_sequences = True, dropout = 0.05))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train, y_train, batch_size = len(X_train), epochs = n_epochs,\n",
    "                        validation_data = (X_test, y_test))\n",
    "    return model, history\n",
    "\n",
    "def lstm_td(X_train, X_test, y_train, y_test) :\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 1024, input_shape = (5,8), return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(8)))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, batch_size = len(X_train), epochs = 300)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_wind, model_wind_history = bd_lstm_td(X_train, y_train_wind, X_test, y_test_wind)\n",
    "model_lat, model_lat_history = bd_lstm_td(X_train, y_train_lat, X_test, y_test_lat, n_epochs = 1000)\n",
    "model_long, model_long_history = bd_lstm_td(X_train, y_train_long, X_test, y_test_long, n_epochs = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection<a id=\"Selection\"></a>\n",
    "The following models were compared\n",
    "- Bidirectional LSTM with Time Distributed(Best performance)\n",
    "- LSTM with Time Distributed\n",
    "- MLP\n",
    "- Bidirectional GRU with Time Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.755018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.414853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-73.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.468590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.437002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.314013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.130581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  4125.000000\n",
       "mean     -0.755018\n",
       "std       7.414853\n",
       "min     -73.178917\n",
       "25%      -3.468590\n",
       "50%      -0.437002\n",
       "75%       2.314013\n",
       "max      96.130581"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ai_errors(predictions, observations, history = None) :\n",
    "    '''\n",
    "    PURPOSE: Provide descriptive statistics on the predicted output versus the observed measurments\n",
    "    METHOD:  Take the errors of the predictions and answers and then calculate standard descriptive statistics\n",
    "    INPUT:   predictions - 2D array of predictions of observed output\n",
    "             observations - 2D array measurements of observed output\n",
    "             history - Keras history model for displaying model loss, default is None if not available\n",
    "    OUTPUT:\n",
    "    '''\n",
    "    errors = []\n",
    "    for i in range(len(predictions)) :\n",
    "        for j in range(len(predictions[i])) :\n",
    "            # Calculate errors\n",
    "            error = predictions[i][j] - observations[i][j]\n",
    "            errors.append(error)\n",
    "    \n",
    "    # Display history and erros\n",
    "    plt.figure(1)\n",
    "    plt.hist(errors, bins = 50)\n",
    "    plt.title('error histogram')\n",
    "    plt.xlabel('error')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame(errors)\n",
    "\n",
    "# Predict values\n",
    "wind_predictions = model_wind.predict(X_test)\n",
    "lat_predictions = model_lat.predict(X_test)\n",
    "long_predictions = model_long.predict(X_test)\n",
    "\n",
    "# Scale back our predictions\n",
    "# Wind\n",
    "wind_predictions_scaled = [scaler.inverse_transform([[0,0,winds[0],0,0,0,0,0,0,0,0] for winds in prediction])\n",
    "                           for prediction in wind_predictions]\n",
    "y_wind_test_scaled = [scaler.inverse_transform([[0,0,winds[0],0,0,0,0,0,0,0,0] for winds in observation])\n",
    "                      for observation in y_test_wind]\n",
    "# Latitude\n",
    "lat_predictions_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0,0] for lat in prediction])\n",
    "                          for prediction in lat_predictions]\n",
    "y_lat_test_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0,0] for lat in observation])\n",
    "                     for observation in y_test_lat]\n",
    "# Longitude\n",
    "long_predictions_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0,0] for long in prediction])\n",
    "                           for prediction in long_predictions]\n",
    "y_long_test_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0,0] for long in observation])\n",
    "                      for observation in y_test_long]\n",
    "\n",
    "# Record wind predictions and observations\n",
    "print(\"Wind\")\n",
    "wind_predictions = [[pred[2] for pred in hurricanes_pred] for hurricanes_pred in wind_predictions_scaled]\n",
    "wind_observations = [[obsrv[2] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_wind_test_scaled]\n",
    "\n",
    "# Present Errors\n",
    "ai_errors(wind_predictions, wind_observations, model_wind_history).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3Xl4FeXZx/HvfU529l0IIKCAoCAqoKhtqdQN92oVrW21tthWq92s8rZaaxdbu9nFavXV1re1WgRRqlgsFpcqKqsom0RACAiEQAIhZL/fP2aIh5CNkJOT5Pw+15UrZ2aemXNPDuSXZ55ZzN0REREBiCS6ABERaT0UCiIiUk2hICIi1RQKIiJSTaEgIiLVFAoiIlJNoSDSSGb2FzP7cSPbbjCzTx3udkRamkJBRESqKRRERKSaQkHalfCwzS1mttzM9prZw2bWx8yeN7M9ZjbPzLrFtL/QzFaYWYGZvWRmI2KWnWBmS8L1/gFk1Hiv881sWbju62Y2uok1f9nMcsxsp5nNNrN+4Xwzs9+Y2XYzKwz36bhw2WQzWxnWttnMvtOkH5hIDQoFaY8uBc4EhgEXAM8D/wP0JPg3fxOAmQ0DHge+AfQC5gD/NLM0M0sDngb+CnQHngy3S7juicAjwPVAD+BPwGwzSz+UQs3sDOBu4HKgL/AB8ES4+Czg4+F+dAWuAPLDZQ8D17t7J+A44D+H8r4idVEoSHv0e3ff5u6bgVeBN919qbuXArOAE8J2VwDPufu/3b0c+CWQCZwKnAKkAve6e7m7zwAWxrzHl4E/ufub7l7p7o8CpeF6h+KzwCPuviSsbxowwcwGAeVAJ+AYwNx9lbt/GK5XDow0s87uvsvdlxzi+4rUSqEg7dG2mNf7apnuGL7uR/CXOQDuXgVsArLDZZv9wDtGfhDz+kjg2+GhowIzKwAGhOsdipo1FBH0BrLd/T/AH4D7gG1m9qCZdQ6bXgpMBj4ws5fNbMIhvq9IrRQKksy2EPxyB4Jj+AS/2DcDHwLZ4bz9Bsa83gT8xN27xnxlufvjh1lDB4LDUZsB3P137n4ScCzBYaRbwvkL3f0ioDfBYa7ph/i+IrVSKEgymw6cZ2aTzCwV+DbBIaDXgQVABXCTmaWY2aeB8THrPgR8xcxODgeEO5jZeWbW6RBr+DtwrZmNCccjfkpwuGuDmY0Lt58K7AVKgMpwzOOzZtYlPOy1G6g8jJ+DSDWFgiQtd18DXA38HthBMCh9gbuXuXsZ8GngGmAXwfjDUzHrLiIYV/hDuDwnbHuoNbwI3A7MJOidHAVMCRd3JgifXQSHmPIJxj0APgdsMLPdwFfC/RA5bKaH7IiIyH7qKYiISDWFgoiIVFMoiIhItbiGgpmdY2Zrwkv4b6tl+UAzm29mS8NL+CfHsx4REalf3AaazSwKvEdwu4FcgqtBr3T3lTFtHgSWuvv9ZjYSmOPug+rbbs+ePX3QoHqbiIhIDYsXL97h7r0aapcSxxrGAznuvg7AzJ4ALgJWxrRxgtPuALoQXMhTr0GDBrFo0aJmLlVEpH0zsw8abhXfUMgmuOpzv1zg5Bpt7gReMLOvAx2AWh9KIiIiLSOeYwpWy7yax6quBP7i7v0J7uPyVzM7qCYzm2pmi8xsUV5eXhxKFRERiG8o5BLcR2a//hx8eOg6wnu2uPsCgvvV96y5IXd/0N3HuvvYXr0aPCQmIiJNFM/DRwuBoWY2mODmXlOAq2q02QhMAv4SPtwkAzjkrkB5eTm5ubmUlJQcZsmtW0ZGBv379yc1NTXRpYhIOxW3UHD3CjO7EZgLRAnuGb/CzO4CFrn7bIIbkD1kZt8kOLR0jTfhdKjc3Fw6derEoEGDOPCmlu2Hu5Ofn09ubi6DBw9OdDki0k7Fs6eAu88heJpV7Lw7Yl6vBE473PcpKSlp14EAYGb06NEDjamISDy1myua23Mg7JcM+ygiidVuQqEhe0sr2FpYQpXuCisiUqekCYXisgq27ykhHplQUFDAH//4x0Neb/LkyRQUFDR/QSIiTZQ0oRBPdYVCZWX9D8OaM2cOXbt2jVdZIiKHLK4Dza3L/uPxTu3X1TXdbbfdxvvvv8+YMWNITU2lY8eO9O3bl2XLlrFy5UouvvhiNm3aRElJCTfffDNTp04FPrplR1FREeeeey6nn346r7/+OtnZ2TzzzDNkZmY2a50iIg1pd6Hww3+uYOWW3QfNL6+soqyiig7ph77LI/t15gcXHFvn8p/97Ge8++67LFu2jJdeeonzzjuPd999t/rU0UceeYTu3buzb98+xo0bx6WXXkqPHj0O2MbatWt5/PHHeeihh7j88suZOXMmV1+tJyyKSMtqd6HQkObvJxxs/PjxB1xL8Lvf/Y5Zs2YBsGnTJtauXXtQKAwePJgxY8YAcNJJJ7Fhw4Y4VykicrB2Fwp1/UW/o6iULQX7GNm3MynR+A6ldOjQofr1Sy+9xLx581iwYAFZWVlMnDix1iuv09PTq19Ho1H27dsX1xpFRGqjgeZm0KlTJ/bs2VPrssLCQrp160ZWVharV6/mjTfeaOHqREQar931FBKhR48enHbaaRx33HFkZmbSp0+f6mXnnHMODzzwAKNHj2b48OGccsopCaxURKR+cXvyWryMHTvWaz5kZ9WqVYwYMaLe9fKLStlcsI8RfTuTGufDR/HUmH0VEanJzBa7+9iG2rXd344iItLsFAoiIlIt+UKhbR0tExFpUckTCuHFCcoEEZG6JU0o6KbTIiINS5pQOPDeRyIiUpskCoX4aeqtswHuvfdeiouLm7kiEZGmiWsomNk5ZrbGzHLM7LZalv/GzJaFX++ZWdwfLhCPfoJCQUTai7hd0WxmUeA+4EwgF1hoZrPD5zID4O7fjGn/deCEuNUTrw1z4K2zzzzzTHr37s306dMpLS3lkksu4Yc//CF79+7l8ssvJzc3l8rKSm6//Xa2bdvGli1b+OQnP0nPnj2ZP39+HKsUEWlYPG9zMR7Icfd1AGb2BHARsLKO9lcCPzjsd33+Ntj6zkGzO1ZVMaS8itS0KBzqs46PGAXn/qzOxbG3zn7hhReYMWMGb731Fu7OhRdeyCuvvEJeXh79+vXjueeeA4J7InXp0oVf//rXzJ8/n549ex5aTSIicRDPw0fZwKaY6dxw3kHM7EhgMPCfONbTIl544QVeeOEFTjjhBE488URWr17N2rVrGTVqFPPmzePWW2/l1VdfpUuXLokuVUTkIPHsKdT253hdh/SnADPcvdbnV5rZVGAqwMCBA+t/1zr+ot9bXMbGncUM69OJjNRo/ds4DO7OtGnTuP766w9atnjxYubMmcO0adM466yzuOOOO+JWh4hIU8Szp5ALDIiZ7g9sqaPtFODxujbk7g+6+1h3H9urV69mLLF5xN46++yzz+aRRx6hqKgIgM2bN7N9+3a2bNlCVlYWV199Nd/5zndYsmTJQeuKiCRaPHsKC4GhZjYY2Ezwi/+qmo3MbDjQDVgQx1riKvbW2eeeey5XXXUVEyZMAKBjx4787W9/Iycnh1tuuYVIJEJqair3338/AFOnTuXcc8+lb9++GmgWkYSL662zzWwycC8QBR5x95+Y2V3AInefHba5E8hw94NOWa1NU2+dXdBCh4/iTbfOFpGmaOyts+P6kB13nwPMqTHvjhrTd8azhv10PbOISMOS54pmpYKISIPaTSg0fBis7adCW3tKnoi0Pe0iFDIyMsjPz2/XvzTdnfz8fDIyMhJdioi0Y3EdU2gp/fv3Jzc3l7y8vDrb7CuvJL+oDN+VTlpK28zCjIwM+vfvn+gyRKQdaxehkJqayuDBg+ttM2/lNr48exGzbzyNEf27tlBlIiJtS9v8k7kJIuGetuMjTCIihy1pQsHCgeYqpYKISJ2SJhT0jGYRkYYlTShEwttlq6MgIlK3pAmF6qsUlAoiInVKmlCo7ikkuA4RkdYsaUJh/8PWqqoUCyIidUmeUAi/KxJEROqWPKGggWYRkQYlUSgE3zXQLCJSt6QJBQ00i4g0LGlCoXqgWT0FEZE6JU8ohN+VCSIidYtrKJjZOWa2xsxyzKzWZzCb2eVmttLMVpjZ3+NYC6DDRyIi9YnbrbPNLArcB5wJ5AILzWy2u6+MaTMUmAac5u67zKx3/OoJvuvwkYhI3eLZUxgP5Lj7OncvA54ALqrR5svAfe6+C8Ddt8ermIjpjngiIg2JZyhkA5tipnPDebGGAcPM7DUze8PMzolXMfvHFNRTEBGpWzyfvGa1zKv5GzkFGApMBPoDr5rZce5ecMCGzKYCUwEGDhzYtGKqr1No0uoiIkkhnj2FXGBAzHR/YEstbZ5x93J3Xw+sIQiJA7j7g+4+1t3H9urVq0nF6DoFEZGGxTMUFgJDzWywmaUBU4DZNdo8DXwSwMx6EhxOWhfHmnT4SESkHnELBXevAG4E5gKrgOnuvsLM7jKzC8Nmc4F8M1sJzAducff8eNSjh+yIiDQsnmMKuPscYE6NeXfEvHbgW+FXXOneRyIiDUueK5p1RqqISIOSJhR0+EhEpGFJEwq6TkFEpGHJEwphT0GhICJSt6QJhZSIQkFEpCFJEwqpKcGullVUJbgSEZHWK2lCodPqJ3kubRoVZSWJLkVEpNVKmlBILSvk2MgHVJXtS3QpIiKtVtKEQjQtC0ChICJSj6QJhZSMIBQoL05sISIirVjShEIk7Cl4mUJBRKQuSRMKpIY9hQodPhIRqUvyhEJKRvC9XKEgIlKX5AmFsKdg6imIiNQpiUIhE4CIegoiInVKnlCIpgHglWUJLkREpPVKnlCIBLvqXpngQkREWq/kCQWLBt8rFQoiInWJayiY2TlmtsbMcszstlqWX2NmeWa2LPz6UtyKiYShoJ6CiEid4vaMZjOLAvcBZwK5wEIzm+3uK2s0/Ye73xivOj4qaH8o6C6pIiJ1iWdPYTyQ4+7r3L0MeAK4KI7vV7/9PYUq9RREROoSz1DIBjbFTOeG82q61MyWm9kMMxsQt2pMh49ERBoSz1CwWubVfOzZP4FB7j4amAc8WuuGzKaa2SIzW5SXl9e0asKzj0w9BRGROsUzFHKB2L/8+wNbYhu4e767l4aTDwEn1bYhd3/Q3ce6+9hevXo1rZpIMHxi6imIiNQpnqGwEBhqZoPNLA2YAsyObWBmfWMmLwRWxa0aHT4SEWlQ3M4+cvcKM7sRmAtEgUfcfYWZ3QUscvfZwE1mdiFQAewErolXPfsHmq1KZx+JiNQlbqEA4O5zgDk15t0R83oaMC2eNVRTT0FEpEHJc0Xz/p6CQkFEpE7JEwpmVGG6eE1EpB7JEwqAE1FPQUSkHkkVClUWwdRTEBGpU3KFAlH1FERE6pFcoWBRIgoFEZE6JVUouGlMQUSkPkkVClVEdfaRiEg9kioU3CJEUCiIiNQl6UJBh49EROqWXKFAVKekiojUI7lCIRIBr8S95mMdREQEkiwULBJcp7C3TIeQRERqk1ShQDSdNCrYtbcs0ZWIiLRKjQoFM7vZzDpb4GEzW2JmZ8W7uGaXmkkmpexUKIiI1KqxPYUvuvtu4CygF3At8LO4VRUnlpZFppVRuK880aWIiLRKjQ0FC79PBv7s7m/HzGs7UjPJoJSyCp2BJCJSm8aGwmIze4EgFOaaWSdoe1eBWVoHMimjrLLNlS4i0iIaGwrXAbcB49y9GEglOIRULzM7x8zWmFmOmd1WT7vLzMzNbGwj62ma1CyyKKW0QmcfiYjUprGhMAFY4+4FZnY18H2gsL4VzCwK3AecC4wErjSzkbW06wTcBLx5KIU3RSQtiwwrpbRcPQURkdo0NhTuB4rN7Hjgu8AHwP81sM54IMfd17l7GfAEcFEt7X4E3AOUNLKWJoukZZJJGaUaUxARqVVjQ6HCg8uALwJ+6+6/BTo1sE42sClmOjecV83MTgAGuPuzjazjsETTO5JJKaXlFS3xdiIibU5KI9vtMbNpwOeAj4WHhlIbWKe2s5Oq7y9hZhHgN8A1Db25mU0FpgIMHDiwkSUfLJqeRdScyvK4d0pERNqkxvYUrgBKCa5X2ErwF/8vGlgnFxgQM90f2BIz3Qk4DnjJzDYApwCzaxtsdvcH3X2su4/t1atXI0s+WCQtC4Cq0uImb0NEpD1rVCiEQfAY0MXMzgdK3L2hMYWFwFAzG2xmacAUYHbMNgvdvae7D3L3QcAbwIXuvqgpO9IYtj8UyvfF6y1ERNq0xt7m4nLgLeAzwOXAm2Z2WX3ruHsFcCMwF1gFTHf3FWZ2l5ldeHhlN1Fqh6C20r0JeXsRkdausWMK3yO4RmE7gJn1AuYBM+pbyd3nAHNqzLujjrYTG1lL06VmBt8rdPhIRKQ2jR1TiOwPhFD+IazbeuwPhTIdPhIRqU1jewr/MrO5wOPh9BXU6AG0CanBmIJpTEFEpFaNCgV3v8XMLgVOIzjV9EF3nxXXyuIhJR0AryxNcCEiIq1TY3sKuPtMYGYca4m/MBSo0HUKIiK1qTcUzGwPMRecxS4C3N07x6WqeEnJAMAq1FMQEalNvaHg7g3dyqJtCXsKuTsKcHfM2t4jIURE4qntnUF0OMKeQhrlvLhqewONRUSST5KFQtBTSKecDfm6gE1EpKbkCoXoR6GQv7cswcWIiLQ+SRYKqYDRLa2Swn3lia5GRKTVSa5QMAOcL/lMXsvZkehqRERaneQKhRgf5heyfY+uVxARiZV8oXDJgwAMtG1sKVAoiIjESr5Q6Bg8pKcbRWwt1D2QRERiJV8oZHQFoIvtZfseXdksIhIrCUOhCwBd2EtBsc5AEhGJlXyhkNkNgF+lPcCuYl2rICISK/lCIewpAOzaoyewiYjEimsomNk5ZrbGzHLM7LZaln/FzN4xs2Vm9l8zGxnPegCIROGi+wBYsWolxWUVcX9LEZG2Im6hYGZR4D7gXGAkcGUtv/T/7u6j3H0McA/w63jVc4BOfQHoXpHHm+t2tshbioi0BfHsKYwHctx9nbuXAU8AF8U2cPfdMZMdqP3ZDc2vcz8A/pH+I7botFQRkWrxDIVsYFPMdG447wBmdoOZvU/QU7gpjvV8pPtR1S9///wySsorW+RtRURau3iGQm1PsDmoJ+Du97n7UcCtwPdr3ZDZVDNbZGaL8vLyDr+ylDS4+H4A0krz+c289w5/myIi7UA8QyEXGBAz3R/YUk/7J4CLa1vg7g+6+1h3H9urV6/mqa5DbwB6UcAzS7dQUVnVPNsVEWnD4hkKC4GhZjbYzNKAKcDs2AZmNjRm8jxgbRzrOVCnIwCYMjzK1t0lfP/pd1vsrUVEWqu4hYK7VwA3AnOBVcB0d19hZneZ2YVhsxvNbIWZLQO+BXwhXvUcpPsQAD6z4Q5G9cngqaWbKdQVziKS5FLiuXF3nwPMqTHvjpjXN8fz/euVlgXdBsOu9fyz8NNcX/UNZr89gs9NGJSwkkREEi35rmiOdePC6pe/SH+Yu55dwfRFm+pZQUSkfUvuUIimwg1vwegpdPY9HFW1ke/OWM7NTyylqqplLpkQEWlNkjsUAHoNh7N+BBh/PmUrAM8s28LUvy5KbF0iIgmgUADo2BsGnkLf1Y/y2ldHADBv1Xb++FIOhfs0+CwiyUOhsN9p34CyYrL/eQXPXNaFtGiEe/61huN/+AJfenQhv5y7hr2lunmeiLRv5t62jp2PHTvWFy2K06GdlbNh1lcgrQMFn/0XC/Kz+OpjS6oXd++QxrfPGsZV4wdiVtsF2yIirZOZLXb3sQ22UyjUkLcG/vdMSOsAA09h3xk/5I28DK79y8KDmt5y9nCG9OzAuaP6xq8eEZFmoFA4HBteg6emwu5cGHAyTLyNvC6jeXt7JV/6v4Pfe9ygbnTNSuMnlxxHp/RUUqJGalRH5kSk9VAoNId3ZsCs66GqIniM55jPUlC0j1kdPkNeeQbz1xWRu6uYPSUHjzX8dsoYJg7rTZes1JapVUSkHgqF5lJSCLkLYe73YMda8JjbbPcZBUdPorxjP1ZtLeKvi7ayoGokud47bOB8MrKMSedfydWnHnXAZsu2raGgLErvAUe33L6ISNJSKDS3qqqgx5C3Gpb/AywC7/8HttV+I71NVb3obbtItwp+VX4Zv6+8hL9cO56Jw8PAuDN4VnT57bt0qElE4k6h0FL27Qp6EwUbYfl0WP9y8LqG3Z7F18u/zvvej0tPPppvLjsPgK2fnskRoz/V0lWLSJJRKCTSrg9g9xbIz4GqCsrm/Zi0kh11Ns+fuowe/Qa3YIEikmwUCq3NvgJKX3+AyOu/JbWy+KDFqyc+xDHjJkFm1+DQlK6DEJFmpFBo7SrKWLnkVVb+814ui75y8PLL/gzHfbrl6xKRdqmxoaARzkRJSWPk+EmM+frjbDn7wYOXz7iW/E2rW74uEUlqCoUEO7p3R/pNuAJu28jaY29mu3etXtbj4ZPZ/tStUL4vmLF9Fcz/Kcy/G9Y8n6CKRaQ9i+uT1+QQZHRh6Gfu4uLtZzN0y9P8IjXoPfRe/gALVr3NKWPHYQt+d+A6d+yESDQBxYpIexXXnoKZnWNma8wsx8xuq2X5t8xspZktN7MXzezIeNbTFsz86qn87Ef3MP38dzm/9McsrhrKhPIFBwcCkPv3GxJQoYi0Z3ELBTOLAvcB5wIjgSvNbGSNZkuBse4+GpgB3BOvetqKaMSIRozPnNSfu2/4PPuuepoHKs4HYFHVMO4pv7y6bf+cx/HnvpOoUkWkHYrb2UdmNgG4093PDqenAbj73XW0PwH4g7ufVt92283ZR4dgR1EpWwr2MXfFVvL2lDJ90SZmpt3JSZG1HzX6RNgR63QEjL02MYWKSKvV2LOP4jmmkA1sipnOBU6up/11QK2jp2Y2FZgKMHDgwOaqr83o2TGdnh3TGd2/K4X7ytm2u5RrNv6En1f+ksnRt4JGL//soxWyusPQsyA1MzEFi0ibFc9QqO3qq1q7JWZ2NTAW+ERty939QeBBCHoKzVVgW9QlM5VHvzgegNN/uI+Xy47nmykzOMJ2fdRo+ueD75c+DKMuS0CVItJWxTMUcoEBMdP9gS01G5nZp4DvAZ9w99I41tPu/HvaBZRVnMftT1/F6nfeorcVMDX6LB+PvhM0mHkd9DgK+p2Q2EJFpM2I55hCCvAeMAnYDCwErnL3FTFtTiAYYD7H3dfWuqEaknFMoTHcnTtnr+DRBR/Qnd0syfjKRwtTMiD7pOA51DvWwLGXQJf+iStWRFpcq7jNhZlNBu4FosAj7v4TM7sLWOTus81sHjAK+DBcZaO7X1jfNhUKDfverHeY9eZ7jIus4Z7UP9HHCg5u9NkZMPTMli9ORBKiVYRCPCgUGubuPP7WJv5nVnAYaUJkBY+n/eTghl99Hfoc28LViUgi6N5HSczMuOrkgay/ezL3XDqanb1OYVDJ37mg9Mc8Vzme3R6elXT/qbBtZWKLFZFWRaHQjpkZl48bwNxvfpznbjqdd3wIN5R/g/Glf2ROZXAGE/dPgCdjrmt47tvBU+GWP5mYokUkoRQKSeLYfl1Y9P1P8evLj6d/7x58rfxmvlT27WDhiqeCEKgsh4X/G8x76kuw9LHEFSwiCaExhSSUX1TKrKWbeWXtDnavXcDT6XfU3fj2HRBNbbniRCQuNKYgderRMZ0vfWwI//fF8dz0hSmcXPIHCj2r9sY/6glzvwdlBz8tTkTaH4VCkjvjmD7cfc1ZnFx6H8eWPMwXym5lq3c7sNGCP8B9J0NFWWKKFJEWo1AQzjimD5NGDeKYI/uxImscZ5X+nMtK7+BvFZM+alS4Ef7768QVKSItQmMKcpDn3/mQ3764lqy0KBs2bjzw6uiTroHjLoNBp4PVdnsrEWmNdPGaNIu7n19Fx9fv4evRpw6Y75c+jB37aYiosynSFmigWZrFtHNHcONdj/DE5Hc4quSvzK0M/k3ZzOuomvFFqKpKcIUi0pwUCtIgM+OKcQO44YzhXF/+LX5b8WkAIitnUfrsLbA3/8AVFv0Ztq9KQKUicrh0+EgOydpte5i1JJfHXl7Od1Km87mUeQBU9R9H5IrHICUdfh4+alvXOIi0GhpTkLgqLC7ndy++R+6C6ZwcWc2U6Hyy7MDHYaw7436GfPwqKC2C9I4JqlREQGMKEmddslK5/YJjufWbt/DykG9za/mXD2qT9do98NLP4e5s2LkuAVWKyKFST0EOW1WVs2NvKY/PX8rNS87h7xWf5KqU+Qe02dt9JB1uWpCgCkVEPQVpMZGI0btTBjddcApPX7iCZ/p/l3nZNxzQpsPOlaybeQdUlLH96e+x8N4pVK79D7z0M/hweYIqF5Ga1FOQuKiqcq7/6yL2lFZwBw8xcsvMOts6hl18Pxw9CTK6BIPVItKsNNAsrUbFvj089Ph0Oq17jqtTXqy3bVX2ON4f8jmOPuPzmK6YFmk2reLwkZmdY2ZrzCzHzG6rZfnHzWyJmVWY2WXxrEUSJyWzE1/94nUcN/V/ubrDAwwu+RuvVR5LlRvrq/oc0DayeSFDX70J+2FX3n/prwmqWCR5xa2nYGZR4D3gTCAXWAhc6e4rY9oMAjoD3wFmu/uMhrarnkLbt2brHgb1zKKopIL8olL2/fETHB+p/eykzRnDWHvKT5l4/LBg/OH0b0BGV+jUp9b2IlK7xvYUUuJYw3ggx93XhQU9AVwEVIeCu28Il+leCUlk+BGdAEjvGKVHx3RKbl/Ed2csouidZxl9yiTOX/Y1+ldtBiC75D2yX7oMXgpXfvvveEoGlbdtJiUlhcKnvsXGlCMZdeHNidkZkXYmnqGQDWyKmc4FTm7KhsxsKjAVYODAgYdfmbQqGalR7rnyZHzKeMwMP2cRf/7pV3im9KRanwpnFSWk/LgHH5z6U45c/jCjgLKBfUl59uuU3byKjE7dW34nRNqJeI4p1DZK2KRjVe7+oLuPdfexvXr1OsyypLXaP7BsaVlc84NH+f0tX6bwWxu5PP2PFHiHg9of+fr/VL9Oe/rLRCpKyPjVYJjxRch/v8XqFmlP4tlTyAUGxEz3B7bE8f2kHTEzBnQPHhE6fdpnofRCXlqRyzenL+Mo28IZ0WV8LWU2r6efzqml/z1w5XdnwrszqcoeS6SsCI6bpt88AAAPP0lEQVS9BE75GmxZCqV7YPi5EIkmYK9EWr94DjSnEAw0TwI2Eww0X+XuK2pp+xfgWQ00yyHbV0Dp89/nvg192b0zj6nRZ+hnOxtcbecxV9L9tOtg7v+wLTWbPUeeydETP9sCBYskRqu4TsHMJgP3AlHgEXf/iZndBSxy99lmNg6YBXQDSoCt7n5sfdtUKEhd3J231u+kcHchuTOmMTqyjo3em54U8vHoO+z1dJZXHcWE6Mq6N3L8lTDxNnj9D7DwIap6Didywb1B72PSD4IL64rzYc4tMGQinHQtRFNgRw506Q+pGS21uyKHpFWEQjwoFKQx3J1VH+4hKy3KzCW5/OE/73FC3wy+NfkEfvz4PCaVvsgtqdOb581O/1bw/OpjPw3n/QpeuB16Hg17tsLZd8OWJZC3BkZepLvFSsIoFETq8Myyzdw6czm3nH0MJWUVdM+A3s9/mY9FlvNq1WgmRZfG782/9gZkdoOKEsjsDr84Gs79OYy9Nli+ZxusfznodexcFzwLu8tAPfZUDptCQaQe7n7AbTQu/9MC3lq/kyvGDmBHfh4dUiOsyq/Adr5PP8unn+XzxejzHB05+FyJPO/MK1WjuTT634OWHZKjPwU58w6en9Yp6IF0OgIKc2HAyVC4CXa8B+OnwtblkBb2QLoPAd0eRGqhUBBpJqPunMuekgquHD+ArllpjOzbmeKyCtbl7eGtDQUs3VjAp0b0Zu3a1VzLbF6pGs3KqiO5MmU+N6c8lYCCL4fKUjj1Jsg+CTa9GdyJ9vgrYN8uKMoLAuaNP0JqJmSPhaemwujLYcINsOG/MOYqPTWvnVEoiDSTbbtL2LSzmLGDar8orqC4jI7pKaREI0x5cAFvrNvJ8D6duOTEbJZtLODVtXnsLaukM0VUEeGESA4lnsbIyAds965s8l70skJG2Ea+m/oPLi39AZdE/8sesvhqyj9beG9rOPvu4FDXkE9A52zY+k4QLJvegpO+APsKYO0L4FVwxvchkgpVFcGAfG09lt1bgt7Ok9fAxfcH242lp/TFjUJBJAFKyispLquke4e0A+bvKSmnY3oK63bs5c11O3l7UwHZ3TJ5dvkW3ttWROeMFPp1zeS9rYV84bQh/Pm1DQCkUc5Q20wqFWzzboyJ5LCgaiSfi/6bIjI5JbKKbNtBBRGKPJP5VWMYH1nDq1WjuKrHWkbuPsxDWk3V9chgXGRfQXA79EgUyoth8+ID2x0xCq54DPZ8COtehpd+CqM+Ewzav/VgcHhszRxYGt4cMa0TjLgAeg2H4ZOh59Bg7KXbYCjeEfR80jt9tP2cebB5CfQfB4M/UfvYTPm+8LCdBWeWHXM+ZHSGqsrgbLKyYkjLOryfx5Zl0ONo8MpgH8xa/DCfQkGkDdqYX0x2t0yKSirITIuSEjH+tWIrxw/oSmWl8/r7O3g7t5DH39pIWjRCWWVV9ffaORGcKozjbD07vAufjv6XpytP4/qUf7KHLBZXDWO3Z7HYh5FBGV9J+SfH2gbe92wmR96A7BPJ3rsSeh/DpsJKBuX9p0V/Js3OIkHwbFwA0TTIz2ncep+6E7ofBalZ0H0wVJTC9pUw9Mwg+Mr3wfJ/QLdB8M6TQc+q5zBYMQtWPwsWDUKhz3Gw7V244Hew/hX48O1ge5N/EYRSp77QuV/wnmV7Ycda6HNsELBpWZB28NX9jdpthYJI+7d/wHxdXhGzlm7mhk8eTUl5JQXF5fxm3ntkpkZZsWU372wuBCBiUBXzXz4rLUpxWSWfGtGH0opKXl27gwlDerBxZzGbC/bV9o4Mtq2s976Mt1UA9M50Jpa/wj3lV3Bt+nwuSl9I7uAreNlOYkz523yyyzb+wvms+bCQ84pmsP3I83l/6ct84H34fOelnFrycrDpMVez7ujPM2TGWcF014FQsDF410hq8DCmbkdS2n0YGWufi9ePtGnSO0Pp7ubbXmpW0LM6gMGFv4MTP9+kTSoURKSau1PlEI0EhyzKKqp4eulmLjqhH+kp0eo27sHjVauqnO8/8y6LNuwku2sm89fkHRQozek7Zw3jz69tIH9vGf27ZfKxob1Y/MFOyiudKcOj/Pa17RTz0YWBY4/sxs0j99K1/3CWv59LccYRnJSdTs76DxiU3Zfx6+5jX+chvOXHsIYjSY8a/VJ287HM9UQrikmtLAn+gj/5elZ1/QTRrcsZFt1CqaeQ9vajWNF2OGI06/udz5G5zxApLw5+Sad1CP7qP2IUpHeBHkfBkkeDM8c6Z0NJAWx8E46fEvRIdm+G5f+grMcILKMzvmcraalpkL/20H9Ioz4DE6cF79kECgURiYu8PaVkpEYwMzbmF9OtQyo524uY886HXHPqYF5as50Pdhbzxvv59OmcwYJ1+WSkRpgybiAzF+cy4ageHNO3M58Y1pN/r9zOAy9/dPNCM8hKjbK3rDKu+zBmQFe6ZaXSs2M6Ty7OPWBZatS4/uNH8eraPN7ODXpYk47pzdA+nRh+REcuPD6bsooqSsor+WBnMcf370JZZRXpKVHKK6uImvGrf69h9Yd7OPXonnTNTOXbT75dvf3Jo46gp+9i/OiRpESMIzPLOKZjEVawEfbugBHnB9/XvQRHnRGcZly4Keg5HQaFgoi0Cbm7iqmodPL3lnHiwK58kF9MUWkF63fsJSViHNO3M9ldM1m6cRfdOqRxRJcM8ovKeC1nB99/+l0ApowbwPodexnRtzMb8vfyynt5jBvUndRohInDe7FtdwkPvbo+wXtav48P68XEYb04fkBXtu8u4dSje/Lu5kLufn4VI/t2Zufecm6eNJRR/bs0afsKBRGRGO5OaUUV23eXsresgpztRYzo24niskqO6JJBaXkVr7+/g8tOGsDqrbsZ0D2Lzbv2sWxTARVVzkOvrONjQ3uSu2sfL7+XB8Dgnh1Yv2Nvre83edQRZKREMTM6pkf514qtbNtdCkDXrFQKissPqf7UqPHLzxzPRWOym7T/CgURkRaSX1RKt6w0IpG6TzMtr6wiJWJ8WFhCv66ZQBBU5ZXOwg07WfLBLvaUVrB9dwlFpZXsLilndHYXrjp5IM8s28Inj+nNmAFdm1yjQkFERKo1NhR0ly0REammUBARkWoKBRERqaZQEBGRagoFERGpplAQEZFqCgUREammUBARkWpt7uI1M8sDPmji6j2BHc1YTlugfU4O2ufkcDj7fKS792qoUZsLhcNhZosac0Vfe6J9Tg7a5+TQEvusw0ciIlJNoSAiItWSLRQeTHQBCaB9Tg7a5+QQ931OqjEFERGpX7L1FEREpB4KBRERqZY0oWBm55jZGjPLMbPbEl1PczGzAWY238xWmdkKM7s5nN/dzP5tZmvD793C+WZmvwt/DsvN7MTE7kHTmFnUzJaa2bPh9GAzezPc33+YWVo4Pz2czgmXD0pk3U1lZl3NbIaZrQ4/6wlJ8Bl/M/w3/a6ZPW5mGe3xczazR8xsu5m9GzPvkD9bM/tC2H6tmX2hqfUkRSiYWRS4DzgXGAlcaWYjE1tVs6kAvu3uI4BTgBvCfbsNeNHdhwIvhtMQ/AyGhl9TgftbvuRmcTOwKmb658Bvwv3dBVwXzr8O2OXuRwO/Cdu1Rb8F/uXuxwDHE+x7u/2MzSwbuAkY6+7HAVFgCu3zc/4LcE6NeYf02ZpZd+AHwMnAeOAH+4PkkLl7u/8CJgBzY6anAdMSXVec9vUZ4ExgDdA3nNcXWBO+/hNwZUz76nZt5QvoH/5HOQN4FjCCqzxTan7ewFxgQvg6JWxnid6HQ9zfzsD6mnW38884G9gEdA8/t2eBs9vr5wwMAt5t6mcLXAn8KWb+Ae0O5Sspegp89A9sv9xwXrsSdplPAN4E+rj7hwDh995hs/bws7gX+C5QFU73AArcvSKcjt2n6v0NlxeG7duSIUAe8OfwkNn/mlkH2vFn7O6bgV8CG4EPCT63xbTvzznWoX62zfaZJ0soWC3z2tW5uGbWEZgJfMPdd9fXtJZ5beZnYWbnA9vdfXHs7FqaeiOWtRUpwInA/e5+ArCXjw4n1KbN73N46OMiYDDQD+hAcOikpvb0OTdGXfvZbPufLKGQCwyIme4PbElQLc3OzFIJAuExd38qnL3NzPqGy/sC28P5bf1ncRpwoZltAJ4gOIR0L9DVzFLCNrH7VL2/4fIuwM6WLLgZ5AK57v5mOD2DICTa62cM8ClgvbvnuXs58BRwKu37c451qJ9ts33myRIKC4Gh4ZkLaQQDVrMTXFOzMDMDHgZWufuvYxbNBvafgfAFgrGG/fM/H57FcApQuL+b2ha4+zR37+/ugwg+x/+4+2eB+cBlYbOa+7v/53BZ2L5N/QXp7luBTWY2PJw1CVhJO/2MQxuBU8wsK/w3vn+f2+3nXMOhfrZzgbPMrFvYyzornHfoEj3A0oIDOZOB94D3ge8lup5m3K/TCbqJy4Fl4ddkguOpLwJrw+/dw/ZGcCbW+8A7BGd3JHw/mrjvE4Fnw9dDgLeAHOBJID2cnxFO54TLhyS67ibu6xhgUfg5Pw10a++fMfBDYDXwLvBXIL09fs7A4wTjJuUEf/Ff15TPFvhiuP85wLVNrUe3uRARkWrJcvhIREQaQaEgIiLVFAoiIlJNoSAiItUUCiIiUk2hINKCzGzi/ju7irRGCgUREammUBCphZldbWZvmdkyM/tT+PyGIjP7lZktMbMXzaxX2HaMmb0R3t9+Vsy97482s3lm9na4zlHh5jvGPBvhsfCKXZFWQaEgUoOZjQCuAE5z9zFAJfBZgpuyLXH3E4GXCe5fD/B/wK3uPprgKtP98x8D7nP34wnu27P/VhMnAN8geLbHEIL7OYm0CikNNxFJOpOAk4CF4R/xmQQ3JKsC/hG2+RvwlJl1Abq6+8vh/EeBJ82sE5Dt7rMA3L0EINzeW+6eG04vI7iX/n/jv1siDVMoiBzMgEfdfdoBM81ur9GuvnvE1HdIqDTmdSX6fyitiA4fiRzsReAyM+sN1c/LPZLg/8v+O3ReBfzX3QuBXWb2sXD+54CXPXimRa6ZXRxuI93Mslp0L0SaQH+hiNTg7ivN7PvAC2YWIbh75Q0ED7c51swWEzzZ64pwlS8AD4S/9NcB14bzPwf8yczuCrfxmRbcDZEm0V1SRRrJzIrcvWOi6xCJJx0+EhGRauopiIhINfUURESkmkJBRESqKRRERKSaQkFERKopFEREpNr/A/KHnPD2ePr6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.176181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.206441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-23.217871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.545974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.141917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.265006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.609077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  4125.000000\n",
       "mean     -0.176181\n",
       "std       1.206441\n",
       "min     -23.217871\n",
       "25%      -0.545974\n",
       "50%      -0.141917\n",
       "75%       0.265006\n",
       "max       8.609077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Lat\")\n",
    "lat_predictions = [[pred[0] for pred in hurricanes_pred] for hurricanes_pred in lat_predictions_scaled]\n",
    "lat_observations = [[obsrv[0] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_lat_test_scaled]\n",
    "ai_errors(lat_predictions, lat_observations, model_lat_history).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.283128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.986305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-20.484958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.614819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.300115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.184537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.931866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  4125.000000\n",
       "mean      0.283128\n",
       "std       1.986305\n",
       "min     -20.484958\n",
       "25%      -0.614819\n",
       "50%       0.300115\n",
       "75%       1.184537\n",
       "max      24.931866"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Long\")\n",
    "long_predictions = [[pred[1] for pred in hurricanes_pred] for hurricanes_pred in long_predictions_scaled]\n",
    "long_observations = [[obsrv[1] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_long_test_scaled]\n",
    "ai_errors(long_predictions, long_observations, model_long_history).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation & Benchmarks<a id=\"Benchmarks\"></a>\n",
    "\n",
    "The machine learning neural network will use 2 main methods of applied evaluation. The first will be evaluated compared to the other models that predict Atlantic hurricanes. The forecast errors have been loaded into each hurricane object corresponding to their forecast model; both the OFCL (official track, or the truth) and the BCD5 (model using multivariate regression). The BCD5 model is \"the CLP5 (track) and DSF5 (intensity) models merged\" that uses the best track as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************\n",
      "[{'entry_id': '',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-25 00:00:00'),\n",
      "  'lat': 28.0,\n",
      "  'long': 94.8,\n",
      "  'max_wind': 80.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 0, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-25 06:00:00'),\n",
      "  'lat': 28.0,\n",
      "  'long': 95.4,\n",
      "  'max_wind': 80.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 1, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-25 12:00:00'),\n",
      "  'lat': 28.0,\n",
      "  'long': 96.0,\n",
      "  'max_wind': 80.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 2, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-25 18:00:00'),\n",
      "  'lat': 28.1,\n",
      "  'long': 96.5,\n",
      "  'max_wind': 80.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 3, dtype: object},\n",
      " {'entry_id': 'L',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-25 21:00:00'),\n",
      "  'lat': 28.2,\n",
      "  'long': 96.8,\n",
      "  'max_wind': 80.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 4, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'HU',\n",
      "  'entry_time': Timestamp('1851-06-26 00:00:00'),\n",
      "  'lat': 28.2,\n",
      "  'long': 97.0,\n",
      "  'max_wind': 70.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 5, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-26 06:00:00'),\n",
      "  'lat': 28.3,\n",
      "  'long': 97.6,\n",
      "  'max_wind': 60.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 6, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-26 12:00:00'),\n",
      "  'lat': 28.4,\n",
      "  'long': 98.3,\n",
      "  'max_wind': 60.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 7, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-26 18:00:00'),\n",
      "  'lat': 28.6,\n",
      "  'long': 98.9,\n",
      "  'max_wind': 50.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 8, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-27 00:00:00'),\n",
      "  'lat': 29.0,\n",
      "  'long': 99.4,\n",
      "  'max_wind': 50.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 9, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-27 06:00:00'),\n",
      "  'lat': 29.5,\n",
      "  'long': 99.8,\n",
      "  'max_wind': 40.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 10, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-27 12:00:00'),\n",
      "  'lat': 30.0,\n",
      "  'long': 100.0,\n",
      "  'max_wind': 40.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 11, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-27 18:00:00'),\n",
      "  'lat': 30.5,\n",
      "  'long': 100.1,\n",
      "  'max_wind': 40.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 12, dtype: object},\n",
      " {'entry_id': '',\n",
      "  'entry_status': 'TS',\n",
      "  'entry_time': Timestamp('1851-06-28 00:00:00'),\n",
      "  'lat': 31.0,\n",
      "  'long': 100.2,\n",
      "  'max_wind': 40.0,\n",
      "  'min_pressure': None,\n",
      "  'wind_radii': 34kt_ne    None\n",
      "34kt_se    None\n",
      "34kt_sw    None\n",
      "34kt_nw    None\n",
      "50kt_ne    None\n",
      "50kt_se    None\n",
      "50kt_sw    None\n",
      "50kt_nw    None\n",
      "64kt_ne    None\n",
      "64kt_se    None\n",
      "64kt_sw    None\n",
      "64kt_nw    None\n",
      "Name: 13, dtype: object}]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b7afdaf75f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     inputs = [scaler.transform([np.array(list(feature_extraction(entries[index], entries[index - 1]).values()))\n\u001b[1;32m     11\u001b[0m                                 for index in range(start_index, start_index + 5)])\n\u001b[0;32m---> 12\u001b[0;31m                 for start_index in range(1, len(entries) - 5)]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-b7afdaf75f75>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     inputs = [scaler.transform([np.array(list(feature_extraction(entries[index], entries[index - 1]).values()))\n\u001b[1;32m     11\u001b[0m                                 for index in range(start_index, start_index + 5)])\n\u001b[0;32m---> 12\u001b[0;31m                 for start_index in range(1, len(entries) - 5)]\n\u001b[0m",
      "\u001b[0;32m/home/feste/1/ha28180/anaconda3/envs/synrad/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_scaling\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/feste/1/ha28180/anaconda3/envs/synrad/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_check_array\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;34m\"\"\"Makes sure centering is not enabled for sparse matrices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m-> 1026\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/feste/1/ha28180/anaconda3/envs/synrad/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/feste/1/ha28180/anaconda3/envs/synrad/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Filter storms that have more than 6 entries. We need at least 6 to calculate 5 speed vectors\n",
    "storms_filter = [storm for storm in hurricanes.values() if len(storm.entries) > 6]\n",
    "\n",
    "# Create hurricane forecast and track predictions\n",
    "for storm in storms_filter :\n",
    "    # Create inputs to ai. ai requires scaled data as input\n",
    "    entries = [entry[1] for entry in sorted(storm.entries.items())] # Extracts data from data structure\n",
    "    print(\"*******************************************************************************************\")\n",
    "    pprint(entries)\n",
    "    inputs = [scaler.transform([np.array(list(feature_extraction(entries[index], entries[index - 1]).values()))\n",
    "                                for index in range(start_index, start_index + 5)])\n",
    "                for start_index in range(1, len(entries) - 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:synrad]",
   "language": "python",
   "name": "conda-env-synrad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
